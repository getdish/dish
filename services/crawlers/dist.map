{
  "version": 3,
  "sources": ["src/index.ts", "src/ci/CI.ts", "src/self/Self.ts", "src/constants.ts", "src/photo-helpers.ts", "src/scrape-helpers.ts", "src/doordash/DoorDash.ts", "src/canonical-restaurant.ts", "src/google/GoogleGeocoder.ts", "src/google/UpdateSearchEndpoint.ts", "src/google/GooglePuppeteerJob.ts", "src/Puppeteer.ts", "src/utils.ts", "src/grubhub/GrubHub.ts", "src/infatuation/Infatuation.ts", "src/michelin/Michelin.ts", "src/tripadvisor/Tripadvisor.ts", "src/ubereats/UberEats.ts", "src/ubereats/categories.ts", "src/yelp/Yelp.ts", "src/yelp/fix_address_bug.ts", "src/self/ALL_SOURCES.ts", "src/self/GPT3.ts", "src/self/getSummary.ts", "src/self/remove_404_images.ts", "src/self/RestaurantBaseScore.ts", "src/self/RestaurantRatings.ts", "src/self/RestaurantTagScores.ts", "src/self/Tagging.ts", "src/self/update_all_geocoder_ids.ts", "src/google/GooglePuppeteer.ts", "src/google/GoogleReviewAPI.ts", "src/google_images/GoogleImages.ts"],
  "sourcesContent": ["import '@dish/helpers/polyfill'\nimport '@dish/helpers/polyfill-node'\n\nexport { CI } from './ci/CI'\nexport { Self } from './self/Self'\nexport { UberEats } from './ubereats/UberEats'\nexport { Yelp } from './yelp/Yelp'\nexport { Infatuation as Infatuation } from './infatuation/Infatuation'\nexport { Michelin } from './michelin/Michelin'\nexport { Tripadvisor } from './tripadvisor/Tripadvisor'\nexport { GooglePuppeteer } from './google/GooglePuppeteer'\nexport { GoogleReviewAPI } from './google/GoogleReviewAPI'\nexport { GoogleImages } from './google_images/GoogleImages'\nexport { DoorDash } from './doordash/DoorDash'\nexport { GrubHub } from './grubhub/GrubHub'\n", "import '@dish/common'\n\nimport { WorkerJob } from '@dish/worker'\nimport { JobOptions, QueueOptions } from 'bull'\n\nexport class CI extends WorkerJob {\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 1,\n      duration: 100,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  doIt(message: string) {\n    console.log('CI worker job ran with message: ' + message)\n  }\n}\n", "import '@dish/common'\n\nimport { sentryMessage } from '@dish/common'\nimport {\n  MenuItem,\n  PhotoXref,\n  RestaurantWithId,\n  globalTagId,\n  menuItemsUpsertMerge,\n  restaurantUpdate,\n  restaurantUpsertManyTags,\n  tagFindOne,\n  tagUpsert,\n} from '@dish/graph'\nimport { Database } from '@dish/helpers-node'\nimport { DEBUG_LEVEL, WorkerJob } from '@dish/worker'\nimport { JobOptions, QueueOptions } from 'bull'\nimport { Base64 } from 'js-base64'\nimport _ from 'lodash'\nimport moment from 'moment'\n\nimport { DISH_DEBUG } from '../constants'\nimport {\n  DoorDashScrapeData,\n  GoogleReviewScrapeData,\n  GoogleScrapeData,\n  InfatuationScrapeData,\n  TripAdvisorScrapeData,\n  UberEatsScrapeData,\n} from '../fixtures/fixtures'\nimport {\n  bestPhotosForRestaurant,\n  bestPhotosForRestaurantTags,\n  photoUpsert,\n  uploadHeroImage,\n} from '../photo-helpers'\nimport {\n  Scrape,\n  latestScrapeForRestaurant,\n  scrapeGetAllDistinct,\n  scrapeGetData,\n  scrapeUpdateGeocoderID,\n} from '../scrape-helpers'\nimport { Tripadvisor } from '../tripadvisor/Tripadvisor'\nimport {\n  googlePermalink,\n  restaurantCountForCity,\n  restaurantFindIDBatchForCity,\n  restaurantFindOneWithTagsSQL,\n  roughSizeOfObject,\n} from '../utils'\nimport { YELP_DOMAIN, YelpScrape, yelpAPIMobile } from '../yelp/Yelp'\nimport { ALL_SOURCES } from './ALL_SOURCES'\nimport { GPT3 } from './GPT3'\nimport { checkMaybeDeletePhoto, remove404Images } from './remove_404_images'\nimport { RestaurantBaseScore } from './RestaurantBaseScore'\nimport { RestaurantRatings } from './RestaurantRatings'\nimport { RestaurantTagScores } from './RestaurantTagScores'\nimport { GEM_UIID, Tagging } from './Tagging'\nimport { updateAllRestaurantGeocoderIDs, updateGeocoderID } from './update_all_geocoder_ids'\n\nprocess.on('unhandledRejection', (reason, _) => {\n  console.log('unhandled rejection', reason)\n  process.exit(1)\n})\n\nconst weekdays = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'] as const\ntype Day = typeof weekdays[number]\n\nconst toPostgresTime = (day: Day, time: string) => {\n  const CALIFORNIAN_TZ = '-07'\n  const doftw = weekdays.indexOf(day) + 1\n  const mDate = moment(`1996 01 ${doftw} ${time}`, 'YYYY MM D hh:mmA')\n  const timestamp = mDate.format(`YYYY-MM-DD HH:mm:ss${CALIFORNIAN_TZ}`)\n  return timestamp\n}\n\nconst IS_FULL_RUN = !process.env.ONLY_FUNC\n\nexport class Self extends WorkerJob {\n  yelp: YelpScrape | null = null\n  ubereats: Scrape<UberEatsScrapeData> | null = null\n  infatuation: Scrape<InfatuationScrapeData> | null = null\n  michelin: Scrape | null = null\n  tripadvisor: Scrape<TripAdvisorScrapeData> | null = null\n  doordash: Scrape<DoorDashScrapeData> | null = null\n  grubhub: Scrape | null = null\n  google: Scrape<GoogleScrapeData> | null = null\n  google_review_api: Scrape<GoogleReviewScrapeData> | null = null\n  available_sources: string[] = []\n\n  main_db!: Database\n  restaurant!: RestaurantWithId\n  tagging: Tagging\n  restaurant_ratings: RestaurantRatings\n  restaurant_base_score: RestaurantBaseScore\n  restaurant_tag_scores: RestaurantTagScores\n  gpt3: GPT3\n  menu_items: MenuItem[] = []\n  _job_identifier_restaurant_id!: string\n  _high_ram_message_sent = false\n\n  _debugRamIntervalFunction!: number\n\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 10,\n      duration: 5000,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 2,\n  }\n\n  get logName() {\n    return `Self - ${this.restaurant?.name || '...'}`\n  }\n\n  constructor() {\n    super()\n    this.tagging = new Tagging(this)\n    this.restaurant_ratings = new RestaurantRatings(this)\n    this.restaurant_base_score = new RestaurantBaseScore(this)\n    this.restaurant_tag_scores = new RestaurantTagScores(this)\n    this.gpt3 = new GPT3(this)\n  }\n\n  async allForCity(city: string) {\n    const PER_PAGE = 30\n    let previous_id = globalTagId\n    const total = await restaurantCountForCity(city)\n    let count = 0\n    while (true) {\n      const results = await restaurantFindIDBatchForCity(PER_PAGE, previous_id, city)\n      if (results.length == 0) {\n        break\n      }\n      await Promise.all(\n        results.map(async (result) => {\n          // avoid a ton of jobs by checking for scrapes first\n          const anyScrape = await Promise.all(\n            ALL_SOURCES.map(async (source) => {\n              return await latestScrapeForRestaurant(result, source)\n            })\n          )\n          if (anyScrape.some(Boolean)) {\n            await this.runOnWorker('mergeAll', [result.id])\n          }\n        })\n      )\n      count += results.length\n      const progress = (count / total) * 100\n      await this.job.progress(progress)\n      previous_id = results[results.length - 1].id\n    }\n  }\n\n  async mergeAll(id: string) {\n    this._job_identifier_restaurant_id = id\n    const restaurant = await restaurantFindOneWithTagsSQL(id)\n    this.log('`restaurant.tag` bytes: ' + roughSizeOfObject(restaurant?.tags))\n    if (!restaurant) {\n      sentryMessage('SELF CRAWLER restaurantFindOneWithTags() null', {\n        data: {\n          mergeAllID: id,\n        },\n      })\n      process.exit(1)\n    }\n    if (restaurant) {\n      await this.preMerge(restaurant)\n      const async_steps = [\n        this.mergePhotos,\n        this.mergeImage,\n        this.mergeMainData,\n        this.addHours,\n        this.doTags,\n        this.addPriceTags,\n        this.findPhotosForTags,\n        this.getUberDishes,\n        this.getDoorDashDishes,\n        this.getGrubHubDishes,\n        this.scanCorpus,\n        this.addReviewHeadlines,\n        // this.generateSummary,\n      ]\n      for (const async_func of async_steps) {\n        if (\n          IS_FULL_RUN ||\n          process.env.ONLY_FUNC == async_func.name ||\n          async_func.name == 'mergeMainData'\n        ) {\n          this.log('running step', async_func.name)\n          await this._runFailableFunction(async_func)\n        }\n      }\n      await this.postMerge()\n      this.log('done with restaurant', id)\n    }\n  }\n\n  async getScrapeData() {\n    let at_least_one = false\n    for (const source of ALL_SOURCES) {\n      const scrape = await latestScrapeForRestaurant(this.restaurant, source)\n      if (scrape) {\n        at_least_one = true\n        if (DISH_DEBUG > 1) {\n          this.log(`Found scrape for ${source} with data`, scrape?.data)\n        }\n      }\n      this[source] = scrape\n    }\n    if (!at_least_one) {\n      throw new Error('No scrapes found for restaurant')\n    }\n  }\n\n  async mergeMainData() {\n    const steps = [\n      this.mergeName,\n      this.mergeTelephone,\n      this.mergeAddress,\n      this.addWebsite,\n      this.addSourceOgIds,\n      this.addSources,\n      this.noteAvailableSources,\n      this.checkIfClosed,\n      this.addPriceRange,\n      this.getRatingFactors,\n    ]\n    for (const step of steps) {\n      if (IS_FULL_RUN || process.env.ONLY_FUNC == step.name) {\n        this.log('running step', step.name)\n        await this._runFailableFunction(step)\n      }\n    }\n  }\n\n  async seed() {\n    // Some strange conflict or duplication or something weird happens\n    // if we don't check first. Then is it really an upsert?\n    const gem = await tagFindOne({ id: GEM_UIID })\n    if (gem) {\n      return\n    }\n    await tagUpsert([\n      {\n        name: 'Gem',\n        slug: 'lenses__gems',\n        alternates: ['notable'],\n        type: 'lense',\n        id: GEM_UIID,\n      },\n      {\n        name: 'Unique',\n        slug: 'lenses__unique',\n        type: 'lense',\n      },\n    ])\n  }\n\n  async preMerge(restaurant: RestaurantWithId) {\n    await this.seed()\n    this.main_db = Database.main_db\n    this._debugDaemon()\n    this.restaurant = restaurant\n    this.log('Merging: ' + this.restaurant.name)\n    this.resetTimer()\n    this.log('Fetching scrape data')\n    await this.getScrapeData()\n    this.noteAvailableSources()\n  }\n\n  async postMerge() {\n    this.resetTimer()\n    if (!this.restaurant.name || this.restaurant.name == '') {\n      sentryMessage('SELF CRAWLER: restaurant has no name', {\n        data: {\n          restaurant: this.restaurant.id,\n        },\n      })\n      return\n    }\n    await this._runFailableFunction(this.finishTagsEtc)\n    const async_steps = [this.oldestReview, this.finalScores]\n    for (const async_func of async_steps) {\n      this.log('running postMerge step', async_func.name)\n      if (IS_FULL_RUN || process.env.ONLY_FUNC == async_func.name) {\n        await this._runFailableFunction(async_func)\n      }\n    }\n    this.log('merging final restaurant')\n    await restaurantUpdate(this.restaurant)\n    clearInterval(this._debugRamIntervalFunction)\n    this.log(`Merged: ${this.restaurant.name}`)\n  }\n\n  async finishTagsEtc() {\n    this.log('Finishing tags...')\n    await restaurantUpdate(this.restaurant, { keys: ['__typename'] })\n    this.tagging.deDepulicateTags()\n    this.log('Updating rankings...')\n    await this.tagging.updateTagRankings()\n    this.log('Upsert tags...')\n    await restaurantUpsertManyTags(this.restaurant, this.tagging.restaurant_tags, {\n      select: () => ({}),\n      keys: ['__typename'],\n    })\n    this.log('Menu items merge...')\n    if (this.menu_items.length != 0) {\n      await menuItemsUpsertMerge(this.menu_items)\n    }\n  }\n\n  async finalScores() {\n    this.log('Final scores calculation...')\n    await this.restaurant_tag_scores.calculateScores()\n    await this.restaurant_base_score.calculateScore()\n  }\n\n  noteAvailableSources() {\n    this.available_sources = Object.keys(this.restaurant.sources || {})\n  }\n\n  async doTags() {\n    await this.tagging.main()\n  }\n\n  async addPriceTags() {\n    if (!this.restaurant.price_range?.includes('$')) return\n    let word: string = ''\n    switch (this.restaurant.price_range) {\n      case '$':\n        word = 'low'\n        break\n      case '$$':\n        word = 'mid'\n        break\n      case '$$$':\n        word = 'high'\n        break\n      case '$$$$':\n        word = 'higher'\n        break\n      case '$$$$$':\n        word = 'highest'\n        break\n    }\n    if (word != '') {\n      await this.tagging.addSimpleTags(['price-' + word])\n    }\n  }\n\n  async findPhotosForTags() {\n    const all = await this.tagging.findPhotosForTags()\n    await photoUpsert(all)\n    for (const tag of this.tagging.restaurant_tags) {\n      const most_aesthetic = await bestPhotosForRestaurantTags(this.restaurant.id, tag.tag_id)\n      tag.photos = most_aesthetic.map((p) => p.photo.url)\n    }\n  }\n\n  async scanCorpus() {\n    await this.tagging.scanCorpus()\n  }\n\n  merge(strings: string[]) {\n    const filledIn = strings.filter((x) => x?.length > 0)\n    let overlaps: string[] = []\n    for (let pair of Self.allPairs(filledIn)) {\n      const overlap = Self.findOverlap(pair[0], pair[1])\n      if (overlap) {\n        overlaps.push(overlap)\n      }\n    }\n    const shortest_string = Self.shortestString(filledIn)\n    const shortest_overlap = Self.shortestString(overlaps)\n    if (shortest_overlap.length) {\n      return shortest_overlap\n    } else {\n      if (shortest_string.length === 0) {\n        return null\n      }\n      return shortest_string\n    }\n  }\n\n  mergeName() {\n    const names = [\n      scrapeGetData(this.yelp, (x) => x.json.name),\n      scrapeGetData(this.ubereats, (x) => x.main.title),\n      scrapeGetData(this.infatuation, (x) => x.data_from_search_list_item.name),\n      scrapeGetData(this.michelin, (x) => x.main.name),\n      scrapeGetData(this.grubhub, (x) => x.main.name),\n      scrapeGetData(this.doordash, (x) => x.main.title),\n      Tripadvisor.cleanName(scrapeGetData(this.tripadvisor, (x) => x.overview.name)),\n    ]\n    const name = this.merge(names)\n    if (name) {\n      this.restaurant.name = name\n    }\n    if (DISH_DEBUG) {\n      this.log('found names', names, 'chose', name)\n      if (!name) {\n        console.log('no name?', '\\n', this.yelp?.data)\n      }\n    }\n  }\n\n  mergeTelephone() {\n    this.restaurant.telephone = this.merge([\n      scrapeGetData(this.yelp, (x) => x.json.telephone),\n      scrapeGetData(this.ubereats, (x) => x.main.phoneNumber),\n      scrapeGetData(this.infatuation, (x) => x.data_from_search_list_item.phone_number),\n      scrapeGetData(this.tripadvisor, (x) => x.overview.contact.phone),\n      scrapeGetData(this.google, (x) => x.telephone),\n    ])\n  }\n\n  mergeAddress() {\n    const addresses = [\n      scrapeGetData(\n        this.yelp,\n        (x) =>\n          [\n            x.json.address.streetAddress,\n            x.json.address.addressLocality,\n            x.json.address.addressRegion,\n            x.json.address.postalCode,\n            // x.json.address.addressCountry,\n          ]\n            .filter(Boolean)\n            .join(', '),\n        ['']\n      ),\n      scrapeGetData(this.ubereats, (x) => x.main.location.address),\n      scrapeGetData(this.infatuation, (x) => x.data_from_search_list_item.street),\n      scrapeGetData(this.michelin, (x) => x.main.title),\n      scrapeGetData(this.tripadvisor, (x) => x.overview.contact.address),\n      scrapeGetData(this.doordash, (x) => x.main.location.address),\n    ]\n    this.restaurant.address = this.merge(addresses)\n    if (DISH_DEBUG) {\n      this.log('found addresses', addresses, 'chose', this.restaurant.address)\n    }\n  }\n\n  addWebsite() {\n    let website = scrapeGetData(this.tripadvisor, (x) => x.overview.contact.website)\n    website = Base64.decode(website)\n    const parts = website.split('_')\n    parts.shift()\n    parts.pop()\n    this.restaurant.website = parts.join('_')\n\n    if (!this.restaurant.website) {\n      this.restaurant.website = 'https://' + scrapeGetData(this.google, (x) => x.website)\n    }\n  }\n\n  addPriceRange() {\n    this.restaurant.price_range = scrapeGetData(this.google, (x) => x.pricing)\n    if (!this.restaurant.price_range?.includes('$')) {\n      const text = scrapeGetData(\n        this.tripadvisor,\n        (x) => x?.overview?.detailCard?.tagTexts?.priceRange?.tags[0]?.tagValue\n      )\n      if (text.includes('Low')) this.restaurant.price_range = '$'\n      if (text.includes('Mid')) this.restaurant.price_range = '$$'\n      if (text.includes('High')) this.restaurant.price_range = '$$$'\n    }\n\n    if (!this.restaurant.price_range?.includes('$')) {\n      this.restaurant.price_range = scrapeGetData(\n        this.yelp,\n        (x) => x?.data_from_search_list_item?.priceRange\n      )\n    }\n  }\n\n  async addHours() {\n    this.restaurant.hours = scrapeGetData(\n      this.yelp,\n      (x) => x.dynamic?.legacyProps?.props?.moreInfoProps?.bizInfo?.bizHours,\n      []\n    )\n\n    const dayRange = this.restaurant.hours\n\n    // flatten\n    const dayData = dayRange.flatMap((dr: any) => {\n      if (dr.formattedDate.includes('-')) {\n        // explode from range Mon-Wed into individual days Mon, Tue, Wed\n        const [start, end] = dr.formattedDate.split('-')\n        const startI = weekdays.indexOf(start as any)\n        let endI = weekdays.indexOf(end as any)\n        if (endI < startI) {\n          endI = startI + endI\n        }\n        const days: Day[] = []\n        for (let i = startI; i <= endI; i++) {\n          days.push(weekdays[i % weekdays.length])\n        }\n        return days.map((day) => ({\n          formattedDate: day as Day,\n          formattedTime: dr.formattedTime,\n        }))\n      }\n      return {\n        formattedDate: dr.formattedDate as Day,\n        formattedTime: dr.formattedTime,\n      }\n    })\n\n    const records: string[] = []\n    for (const day of dayData) {\n      const times = day.formattedTime.split(' - ')\n      if (!times || !times.length) continue\n      let [openTime, closeTime] = times.map((x: any) => x.replace(' ', '').trim().toLowerCase())\n      const openDay = day.formattedDate\n      let closeDay = day.formattedDate\n      // if closes in the next day, move the close day up one\n      const closesInMorningFromPM = openTime.includes('pm') && closeTime.includes('am')\n      const closesInMorningFromAM =\n        openTime.includes('am') &&\n        closeTime.includes('am') &&\n        // basically if its 8:00am - 11:00am, its closing in the same day\n        // but if its 8:00am - 2:00am, its closing the next morning\n        // both are am and openTime > closeTime\n        +openTime.split(':')[0] > +closeTime.split(':')[0]\n\n      if (closesInMorningFromAM || closesInMorningFromPM) {\n        const curIndex = weekdays.indexOf(closeDay)\n        closeDay = weekdays[(curIndex + 1) % weekdays.length]\n      }\n\n      const open = toPostgresTime(openDay, openTime)\n      const close = toPostgresTime(closeDay, closeTime)\n\n      if ([open, close].some((x) => x === 'Invalid date')) {\n        // prettier-ignore\n        console.log('\u26A0\uFE0F WARN: Invalid date parsed', { open, openDay, openTime, close, closeDay, closeTime })\n        console.log('   ...', { hours: this.restaurant.hours, dayData })\n        continue\n      }\n\n      records.push(`('${this.restaurant.id}'::UUID, timestamp '${open}', timestamp '${close}')`)\n    }\n\n    if (records.length == 0) {\n      return {\n        count: 0,\n        records,\n      }\n    }\n\n    const query = `\n        BEGIN TRANSACTION;\n        DELETE FROM opening_hours\n          WHERE restaurant_id = '${this.restaurant.id}'::UUID;\n        INSERT INTO opening_hours(restaurant_id, hours)\n          SELECT id, hours\n          FROM  (\n             VALUES ${records.join(',')}\n             ) t(id, f, t), f_opening_hours_hours(f, t) hours;\n        END TRANSACTION;\n      `\n\n    try {\n      const result = await this.main_db.query(query)\n      return {\n        count: result[2].rowCount,\n        records,\n      }\n    } catch (err) {\n      console.error('Error setting hours', err.message, err.stack)\n      console.log('Hours records:', records.join(','))\n    }\n  }\n\n  async oldestReview() {\n    const query = `\n      SELECT MIN(authored_at) oldest_review\n      FROM review\n        WHERE restaurant_id = '${this.restaurant.id}'\n      ORDER BY oldest_review DESC\n    `\n    const result = await this.main_db.query(query)\n    const oldest_review = result.rows[0].oldest_review\n    this.restaurant.oldest_review_date = oldest_review\n  }\n\n  // The `id_from_source` field is the source-specific identifier for a restaurant.\n  // Therefore how does say Google or Yelp identify a restaurant? They'll have some sort of\n  // internal UUID in their databases. This is what we are noting here. Though we also\n  // note the ID in the scrape database, it is possible, though quite undesired, that a\n  // source ID will change over time.\n  addSourceOgIds() {\n    this.restaurant.og_source_ids = {\n      ...(this.restaurant.og_source_ids || null),\n    }\n    const og_og = _.cloneDeep(this.restaurant.og_source_ids)\n    const sources = [\n      this.tripadvisor,\n      this.michelin,\n      this.infatuation,\n      this.yelp,\n      this.doordash,\n      this.grubhub,\n      this.ubereats,\n      this.google_review_api,\n    ]\n    for (const source of sources) {\n      if (source) {\n        this.restaurant.og_source_ids[source.source] = source.id_from_source\n      }\n    }\n    this.checkForSourceIDChange(og_og)\n  }\n\n  checkForSourceIDChange(og_og: string[]) {\n    if (og_og == null) return\n    let is_change_detected = false\n    for (const [key, og_id] of Object.entries(og_og)) {\n      const newish_id = this.restaurant.og_source_ids[key]\n      if (og_id != newish_id) {\n        is_change_detected = true\n      }\n    }\n    if (!is_change_detected) return\n    this.handleRestaurantSourceIDChange(og_og)\n  }\n\n  handleRestaurantSourceIDChange(og_og: string[]) {\n    const message = 'Change in restaurant source ID'\n    const data = {\n      restaurant_id: this.restaurant.id,\n      og_source_ids: og_og,\n      new_source_ids: this.restaurant.og_source_ids,\n    }\n    this.log(message)\n    sentryMessage(message, { data })\n  }\n\n  addSources() {\n    let url: string\n    let path: string\n    let parts: string[]\n\n    this.restaurant.sources = {\n      ...this.restaurant.sources,\n    } as Record<string, { url: string; rating: number }>\n\n    const { rating, ratings } = this.restaurant_ratings.getRatings()\n\n    this.restaurant.rating = rating\n\n    path = scrapeGetData(this.tripadvisor, (x) => x.overview.links.warUrl)\n    if (path != '') {\n      parts = path.split('-')\n      parts.shift()\n      url = 'https://www.tripadvisor.com/' + parts.join('-')\n      this.restaurant.sources.tripadvisor = {\n        url,\n        rating: ratings?.tripadvisor,\n      }\n    }\n\n    path = scrapeGetData(this.yelp, (x) => x.data_from_search_list_item.businessUrl)\n    if (path != '') {\n      this.restaurant.sources.yelp = {\n        url: 'https://www.yelp.com' + path,\n        rating: ratings?.yelp,\n      }\n    }\n\n    path = scrapeGetData(this.infatuation, (x) => x.data_from_search_list_item.post.review_link)\n    if (path != '') {\n      this.restaurant.sources.infatuation = {\n        url: 'https://www.theinfatuation.com' + path,\n        rating: ratings?.infatuation,\n      }\n    }\n\n    path = scrapeGetData(this.michelin, (x) => x.main.url)\n    if (path != '') {\n      this.restaurant.sources.michelin = {\n        url: 'https://guide.michelin.com' + path,\n        rating: ratings?.michelin,\n      }\n    }\n\n    let json_ue = scrapeGetData(this.ubereats, (x) => x.main.metaJson, {})\n    if (typeof json_ue === 'string') {\n      try {\n        json_ue = JSON.parse(json_ue)\n      } catch (err) {\n        console.log('error parsing uber', err)\n      }\n    }\n    if (json_ue['@id']) {\n      this.restaurant.sources.ubereats = {\n        url: json_ue['@id'],\n        rating: ratings?.ubereats,\n      }\n    }\n\n    let json_dd = scrapeGetData(this.doordash, (x) => x.storeMenuSeo, {})\n    if (json_dd['id']) {\n      this.restaurant.sources.doordash = {\n        url: json_dd['id'].split('?')[0],\n        rating: ratings?.doordash,\n      }\n    }\n\n    const gh_id = scrapeGetData(this.grubhub, (x) => x.main.id)\n    if (gh_id) {\n      this.restaurant.sources.grubhub = {\n        url: 'https://www.grubhub.com/restaurant/' + gh_id,\n        rating: ratings?.grubhub,\n      }\n    }\n\n    if (!this.google_review_api) return\n    this.log('addSources getGoogleSource')\n    const id = this.google_review_api.id_from_source\n    const lon = this.restaurant.location.coordinates[0]\n    const lat = this.restaurant.location.coordinates[1]\n    const source = googlePermalink(id, lat, lon)\n    // @ts-ignore\n    this.restaurant.sources.google = {\n      url: source,\n      rating: ratings?.google,\n    }\n  }\n\n  async checkIfClosed() {\n    this.log('Checking closed status')\n    let url = this.restaurant.sources?.yelp?.url\n    if (!url) {\n      this.log('Cannot check if closed, no Yelp source')\n      return\n    }\n    url = url.replace(YELP_DOMAIN, '')\n    const SIGNATURE = 'Yelpers report this location has closed'\n    const html = await yelpAPIMobile.getText(url)\n    if (html.includes(SIGNATURE)) {\n      this.restaurant.is_out_of_business = true\n      this.log('Restaurant is out of business')\n    } else {\n      this.log('Restaurant is in business')\n    }\n  }\n\n  async mergeImage() {\n    let hero = ''\n    // top to bottom is least preferred hero to most preferred\n    const yelps = scrapeGetData(\n      this.yelp,\n      (x) =>\n        x.json.image?.replace('348s.jpg', '1000s.jpg') ??\n        console.error('no image! we could get from dynamic', x.json)\n    )\n    if (yelps) {\n      hero = yelps\n    }\n    const googles = scrapeGetData(this.google, (x) => x.hero_image)\n    if (googles) {\n      hero = googles\n    }\n    const infatuations = scrapeGetData(\n      this.infatuation,\n      (x) => x.data_from_search_list_item.post.venue_image\n    )\n    if (infatuations) {\n      hero = infatuations\n    }\n    const michelins = scrapeGetData(this.michelin, (x) => x.main.image)\n    if (michelins) {\n      hero = michelins\n    }\n    if (hero != '') {\n      const uploaded = await uploadHeroImage(hero, this.restaurant.id)\n      if (uploaded) {\n        this.restaurant.image = uploaded\n      }\n    } else {\n      this.log('No hero image')\n    }\n  }\n\n  async getUberDishes() {\n    if (!this.ubereats?.id) {\n      return\n    }\n    // @ts-ignore\n    const raw_dishes = this.ubereats?.data?.dishes\n    for (const data of raw_dishes) {\n      if (data.title) {\n        this.menu_items.push({\n          restaurant_id: this.restaurant.id,\n          name: data.title,\n          description: data.description,\n          price: data.price,\n          image: data.imageUrl,\n        } as MenuItem)\n      }\n    }\n  }\n\n  async getDoorDashDishes() {\n    if (!this.doordash?.id) {\n      return\n    }\n    // @ts-ignore\n    const categories = this.doordash?.data?.menus.currentMenu.menuCategories\n    for (const category of categories) {\n      for (const data of category.items) {\n        if (data.name) {\n          this.menu_items.push({\n            restaurant_id: this.restaurant.id,\n            name: data.name,\n            description: data.description,\n            price: data.price,\n            image: data.imageUrl,\n          } as MenuItem)\n        }\n      }\n    }\n  }\n\n  async getGrubHubDishes() {\n    if (!this.grubhub?.id) return\n    const categories = scrapeGetData(this.grubhub, (x) => x.main.menu_category_list)\n    for (const category of categories) {\n      for (const data of category.menu_item_list) {\n        if (data.name) {\n          this.menu_items.push({\n            restaurant_id: this.restaurant.id,\n            name: data.name,\n            description: data.description,\n            price: data.price.amount,\n          } as MenuItem)\n        }\n      }\n    }\n  }\n\n  async mergePhotos() {\n    let urls: string[] = [\n      ...scrapeGetData(this.tripadvisor, (x) => x.photos, []),\n      ...this._getGooglePhotos(),\n      ...this._getYelpPhotos(this.yelp?.data),\n    ]\n    let photos: PhotoXref[] = urls.map((url) => {\n      return {\n        restaurant_id: this.restaurant.id,\n        photo: {\n          url,\n        },\n      } as PhotoXref\n    })\n    this.log(`mergePhotos ${photos.length} photos`)\n    await photoUpsert(photos)\n    const most_aesthetic = (await bestPhotosForRestaurant(this.restaurant.id)) || []\n    this.restaurant.photos = most_aesthetic.map((p) => p.photo?.url)\n  }\n\n  _getYelpPhotos(data: any) {\n    if (!data) return []\n    return this.getPaginatedDataNumberedKeys(data, 'photos')?.map((i) => i.url)\n  }\n\n  _getGooglePhotos() {\n    let urls: string[] = []\n    if (!this.google_review_api) return []\n    const reviews = scrapeGetData(this.google_review_api, (x) => x.reviews)\n    if (!reviews) return []\n    for (const review of reviews) {\n      urls = [...urls, ...review.photos]\n    }\n    return urls\n  }\n\n  getPaginatedData<A extends any>(data: { [key: string]: A[] } | null): A[] {\n    if (!data) return []\n    return Object.keys(data).flatMap((key) => data[key])\n  }\n\n  getPaginatedDataNumberedKeys(data: any, type: 'photos' | 'reviews') {\n    let items: any[] = []\n    let page = 0\n    let key: string | undefined\n    if (!data) {\n      return []\n    }\n    while (true) {\n      const base = type + 'p' + page\n      const variations = [base, base.replace('reviews', 'review')]\n      key = variations.find((i) => data.hasOwnProperty(i))\n      if (key) {\n        items = items.concat(data[key])\n      } else {\n        // Allow scrapers to start their pages on both 0 and 1\n        if (page > 0) {\n          break\n        }\n      }\n      page++\n    }\n    return items\n  }\n\n  getRatingFactors() {\n    const factors = scrapeGetData(this.tripadvisor, (x) => x.overview.rating.ratingQuestions, [])\n    this.restaurant.rating_factors = {\n      food: (factors.find((i) => i.name == 'Food')?.rating ?? 0) / 10,\n      service: (factors.find((i) => i.name == 'Service')?.rating ?? 0) / 10,\n      value: (factors.find((i) => i.name == 'Value')?.rating ?? 0) / 10,\n      ambience: (factors.find((i) => i.name == 'Atmosphere')?.rating ?? 0) / 10,\n    }\n  }\n\n  async addReviewHeadlines() {\n    const id = this.restaurant.id\n    const result = await this.main_db.query(`\n      SELECT DISTINCT(sentence), naive_sentiment FROM restaurant\n        JOIN review ON review.restaurant_id = restaurant.id\n        JOIN review_tag_sentence rts ON rts.review_id = review.id\n      WHERE restaurant.id = '${id}'\n      ORDER BY naive_sentiment DESC\n      LIMIT 5\n    `)\n    this.restaurant.headlines = result.rows\n  }\n\n  async updateAllGeocoderIDs() {\n    await updateAllRestaurantGeocoderIDs(this)\n  }\n\n  async updateAllDistinctScrapeGeocoderIDs() {\n    const all = await scrapeGetAllDistinct()\n    for (const scrape of all) {\n      await this.runOnWorker('updateScrapeGeocoderID', [scrape.scrape_id])\n    }\n  }\n\n  async updateScrapeGeocoderID(scrape_id: string) {\n    await scrapeUpdateGeocoderID(scrape_id)\n  }\n\n  async updateGeocoderID(restaurant: RestaurantWithId) {\n    await updateGeocoderID(restaurant)\n  }\n\n  async remove404Images() {\n    await remove404Images(this)\n  }\n\n  async checkMaybeDeletePhoto(photo_id: string, url: string) {\n    await checkMaybeDeletePhoto(photo_id, url)\n  }\n\n  async generateSummary() {\n    if (process.env.NODE_ENV === 'test') {\n      return\n    }\n    if (!this.restaurant.scrape_metadata?.gpt_summary_updated_at) {\n      await this.gpt3.generateGPT3Summary()\n      this.restaurant.scrape_metadata = {\n        ...this.restaurant.scrape_metadata,\n        gpt_summary_updated_at: Date.now(),\n      }\n      try {\n        await restaurantUpdate(this.restaurant)\n      } catch (err) {\n        console.log('error generateSummary', err.message, err.stack)\n        console.log('err restaurant', this.restaurant)\n      }\n    }\n  }\n\n  async generateGPT3Summary(id: string) {\n    this._job_identifier_restaurant_id = id\n    const restaurant = await restaurantFindOneWithTagsSQL(id)\n    if (restaurant) {\n      this.main_db = Database.main_db\n      this.restaurant = restaurant\n      await this.gpt3.generateGPT3Summary()\n      await restaurantUpdate(this.restaurant)\n    }\n  }\n\n  private static shortestString(arr: string[]) {\n    arr = arr.filter((el) => {\n      return el != null && el != ''\n    })\n    if (arr.length) {\n      return arr.reduce((a, b) => (a.length <= b.length ? a : b))\n    } else {\n      return ''\n    }\n  }\n\n  private static allPairs(arr: string[]) {\n    return arr.map((v, i) => arr.slice(i + 1).map((w) => [v, w])).flat()\n  }\n\n  private static findOverlap(a: string, b: string) {\n    if (a.includes(b)) {\n      return b\n    }\n    if (b.includes(a)) {\n      return a\n    }\n    return null\n  }\n\n  _debugDaemon() {\n    const fn = () => {\n      this._checkRAM()\n      this._checkNulls()\n    }\n    // @ts-ignore\n    this._debugRamIntervalFunction = setInterval(fn, 10000)\n  }\n\n  _checkRAM(marker?: string) {\n    if (DEBUG_LEVEL < 2) {\n      return\n    }\n    const ram_value = Math.round(process.memoryUsage().heapUsed / 1024 / 1024)\n    const ram = ram_value + 'Mb'\n    const limit = 5000\n    if (ram_value > limit && !this._high_ram_message_sent) {\n      sentryMessage(`Worker RAM over ${limit}Mb`, {\n        data: {\n          ram,\n          restaurant: this.restaurant,\n        },\n      })\n      this._high_ram_message_sent = true\n    }\n    marker = marker ? `(${marker})` : ''\n    this.log(`Worker RAM usage ${marker}: ${ram}`)\n  }\n\n  _checkNulls() {\n    if (!this.restaurant || !this.restaurant.slug || !this.restaurant.name) {\n      sentryMessage('Self crawl null data', {\n        data: {\n          restaurant_id: this._job_identifier_restaurant_id,\n        },\n      })\n      process.exit(1)\n    }\n  }\n}\n", "export const DISH_DEBUG = +(process.env.DISH_DEBUG || '0')\n", "import '@dish/helpers/polyfill-node'\nimport '@dish/common'\n\nimport * as crypto from 'crypto'\nimport { basename } from 'path'\n\nimport { sleep } from '@dish/async'\nimport { sentryException, sentryMessage } from '@dish/common'\nimport {\n  DISH_API_ENDPOINT,\n  PhotoBase,\n  PhotoXref,\n  ZeroUUID,\n  createQueryHelpersFor,\n  deleteByIDs,\n  globalTagId,\n  order_by,\n  photo_constraint,\n  photo_xref,\n  photo_xref_constraint,\n  photo_xref_select_column,\n  query,\n  resolvedWithFields,\n  uuid,\n} from '@dish/graph'\nimport { isPresent } from '@dish/helpers'\nimport { Database } from '@dish/helpers-node'\nimport FormData from 'form-data'\nimport { selectFields } from 'gqty'\nimport { chunk, clone, difference, uniqBy } from 'lodash'\n\nimport { DISH_DEBUG } from './constants'\n\ntype ImageQualityResponse = { mean_score_prediction: number; image_id: string }[]\n\nexport let __uploadToDOSpaces__count = 0\nexport let __assessNewPhotos__count = 0\n\nconst PhotoBaseQueryHelpers = createQueryHelpersFor<PhotoBase>('photo')\nconst PhotoXrefQueryHelpers = createQueryHelpersFor<PhotoXref>('photo_xref')\nconst photoBaseUpsert = PhotoBaseQueryHelpers.upsert\n\nexport const photoXrefUpsert = PhotoXrefQueryHelpers.upsert\nexport const photoXrefDelete = PhotoXrefQueryHelpers.delete\nexport const photoXrefFindAll = PhotoXrefQueryHelpers.findAll\n\nconst selectBasePhotoXrefFields = {\n  select: (v: photo_xref[]) => {\n    return v.map((p) => {\n      return {\n        ...selectFields(p, '*', 2),\n        photo: {\n          ...selectFields(p.photo),\n        },\n      }\n    })\n  },\n}\n\nexport const DO_BASE = 'https://dish-images.sfo2.digitaloceanspaces.com/'\n\nexport async function photoUpsert(photosOg: Partial<PhotoXref>[]) {\n  if (photosOg.length == 0) return []\n  let photos = await ensureValidPhotos(normalizePhotos(photosOg))\n  if (!photos) {\n    return []\n  }\n  photos = ensurePhotosAreUniqueKeyAble(photos)\n  photos = uniqBy(photos, (el) => [el.tag_id, el.restaurant_id, el.photo?.url].join())\n  photos = archiveURLInOrigin(photos)\n  const upserted = await photoXrefUpsert(\n    photos,\n    photo_xref_constraint.photos_xref_photos_id_restaurant_id_tag_id_key,\n    selectBasePhotoXrefFields\n  )\n  const updated = await postUpsert(photos)\n  if (!updated) {\n    return []\n  }\n  if (updated.length > 0) {\n    return updated\n  } else {\n    return upserted.map((px) => px.photo)\n  }\n}\n\nfunction archiveURLInOrigin(photos: Partial<PhotoXref>[]) {\n  photos.forEach((p) => {\n    if (!p.photo || !p.photo.url) throw 'Photo must have URL'\n    p.photo.origin = clone(p.photo?.url)\n    delete p.photo.url\n  })\n  return photos\n}\n\nfunction ensurePhotosAreUniqueKeyAble(photos: Partial<PhotoXref>[]) {\n  if (photos[0].restaurant_id && !photos[0].tag_id) {\n    photos.map((p) => (p.tag_id = ZeroUUID))\n  }\n  if (photos[0].tag_id && !photos[0].restaurant_id) {\n    photos.map((p) => (p.restaurant_id = ZeroUUID))\n  }\n  return photos\n}\n\n// ensure they are valid image urls otherwise other steps fail\nasync function ensureValidPhotos(photosOg: Partial<PhotoXref>[]) {\n  if (process.env.SKIP_PHOTO_ANALYZE) {\n    console.log('skipping photo validity check')\n    return\n  }\n  console.log(`Downloading ${photosOg.length} to check validity`)\n  const valid = (\n    await Promise.all(\n      photosOg.map(async (photo) => {\n        return (await isValidPhoto(photo.photo?.url)) ? photo : null\n      })\n    )\n  ).filter(isPresent)\n\n  const invalids = difference(photosOg, valid)\n  if (invalids.length) {\n    // prettier-ignore\n    console.warn(`Warning! some urls aren't valid, deleting: ${invalids.map((x) => x.photo?.url ?? '').join(', ')}`)\n    for (const invalid of invalids) {\n      if (invalid.id) {\n        await photoXrefDelete({ id: invalid.id })\n      }\n    }\n  }\n  console.log('All photos checked for validity')\n  return valid\n}\n\n// TODO Handle TCP error. Therefore, don't delete a photo if there's a TCP error\nasync function isValidPhoto(url?: string | null) {\n  if (!url) return false\n  try {\n    const res = await fetch(url)\n    if (res.status >= 300) return false\n    const contentType = res.headers.get('content-type')\n    return contentType?.startsWith('image/')\n  } catch (e) {\n    console.error(`Unexpected error validating image: ${url}`, e)\n    return false\n  }\n}\n\nfunction normalizePhotos(photos: Partial<PhotoXref>[]) {\n  let next = [...photos]\n  if (next[0].restaurant_id && !next[0].tag_id) {\n    next.map((p) => (p.tag_id = ZeroUUID))\n  }\n  if (next[0].tag_id && !next[0].restaurant_id) {\n    next.map((p) => (p.restaurant_id = ZeroUUID))\n  }\n  next = uniqBy(next, (el) => [el.tag_id, el.restaurant_id, el.photo?.url].join())\n  return next.map((p) => {\n    if (!p.photo || !p.photo.url) {\n      throw new Error('Photo must have URL')\n    }\n    p.photo.origin = p.photo?.url\n    return p\n  })\n}\n\nasync function postUpsert(photos: Partial<PhotoXref>[]) {\n  await uploadToDO(photos)\n  const updated = await updatePhotoQualityAndCategories(photos)\n  return updated\n}\n\nexport async function uploadToDO(photos: Partial<PhotoXref>[]) {\n  const not_uploaded = await findNotUploadedPhotos(photos)\n  if (not_uploaded.length == 0) return\n  const uploaded = await uploadToDOSpaces(not_uploaded)\n  const updated = uploaded.map((p: any) => {\n    if (!p.photo) throw new Error('uploadToDO() No photo!?')\n    return {\n      id: p.photo.id,\n      url: DO_BASE + p.photo_id,\n    } as PhotoBase\n  })\n  await photoBaseUpsert(updated, photo_constraint.photos_pkey)\n}\n\nexport async function updatePhotoQualityAndCategories(photos: Partial<PhotoXref>[]) {\n  if (process.env.SKIP_PHOTO_ANALYZE) {\n    console.log('skipping photo analyze')\n    return\n  }\n  const unassessed_photos = await findUnassessedPhotos(photos)\n  const result = await assessNewPhotos(unassessed_photos)\n  if (!result) {\n    return unassessed_photos.map((url) => {\n      return { url }\n    })\n  } else {\n    return result\n  }\n}\n\nasync function findNotUploadedRestaurantPhotos(restaurant_id: uuid): Promise<PhotoXref[]> {\n  const photos = await resolvedWithFields(() => {\n    const d = query.photo_xref({\n      where: {\n        _or: [\n          {\n            restaurant_id: {\n              _eq: restaurant_id,\n            },\n            photo: {\n              url: {\n                _nlike: '%digitalocean%',\n              },\n            },\n          },\n          {\n            restaurant_id: {\n              _eq: restaurant_id,\n            },\n            photo: {\n              url: {\n                _is_null: true,\n              },\n            },\n          },\n        ],\n      },\n      distinct_on: [photo_xref_select_column.photo_id],\n    })\n\n    return d\n  }, selectBasePhotoXrefFields)\n  return photos\n}\n\nexport async function findNotUploadedTagPhotos(tag_id: uuid): Promise<PhotoXref[]> {\n  const photos = await resolvedWithFields(\n    () =>\n      query.photo_xref({\n        where: {\n          _or: [\n            {\n              tag_id: {\n                _eq: tag_id,\n              },\n              photo: {\n                url: {\n                  _nlike: '%digitalocean%',\n                },\n              },\n            },\n            {\n              tag_id: {\n                _eq: tag_id,\n              },\n              photo: {\n                url: {\n                  _is_null: true,\n                },\n              },\n            },\n          ],\n        },\n        distinct_on: [photo_xref_select_column.photo_id],\n      }),\n    selectBasePhotoXrefFields\n  )\n  return photos\n}\n\nasync function unassessedPhotosForRestaurant(restaurant_id: uuid): Promise<PhotoXref[]> {\n  const photos = await resolvedWithFields(\n    () =>\n      query.photo_xref({\n        where: {\n          restaurant_id: {\n            _eq: restaurant_id,\n          },\n          photo: {\n            quality: {\n              _is_null: true,\n            },\n          },\n        },\n        distinct_on: [photo_xref_select_column.photo_id],\n      }),\n    selectBasePhotoXrefFields\n  )\n  return photos\n}\n\nasync function unassessedPhotosForTag(tag_id: uuid): Promise<PhotoXref[]> {\n  const photos = await resolvedWithFields(\n    () =>\n      query.photo_xref({\n        where: {\n          tag_id: {\n            _eq: tag_id,\n          },\n          photo: {\n            quality: {\n              _is_null: true,\n            },\n          },\n        },\n        distinct_on: [photo_xref_select_column.photo_id],\n      }),\n    selectBasePhotoXrefFields\n  )\n  return photos\n}\n\nasync function unassessedPhotosForRestaurantTag(restaurant_id: uuid): Promise<PhotoXref[]> {\n  const photos = await resolvedWithFields(\n    () =>\n      query.photo_xref({\n        where: {\n          restaurant_id: {\n            _eq: restaurant_id,\n          },\n          tag_id: {\n            _neq: ZeroUUID,\n          },\n          photo: {\n            quality: {\n              _is_null: true,\n            },\n          },\n        },\n        distinct_on: [photo_xref_select_column.photo_id],\n      }),\n    {\n      select: (v: photo_xref[]) => {\n        return v.map((p) => {\n          const d = {\n            ...selectFields(p, '*', 2),\n          }\n          return d\n        })\n      },\n    }\n  )\n\n  return photos\n}\n\nexport async function bestPhotosForRestaurant(restaurant_id: uuid): Promise<PhotoXref[]> {\n  const TOP_FRACTION_CUTOFF = process.env.NODE_ENV == 'test' ? 1 : 0.2\n  const result = await Database.one_query_on_main(`\n    SELECT json_agg(j1) FROM (\n      SELECT * FROM (\n        SELECT\n          *,\n          (\n            SELECT json_agg(j2) FROM (\n              SELECT * FROM photo WHERE photo.id = photo_id LIMIT 1\n            ) j2\n          )->>0 AS photo,\n          percent_rank() OVER (ORDER BY photo.quality DESC NULLS LAST) AS rank_by_percent\n          FROM photo_xref\n          JOIN photo ON photo_xref.photo_id = photo.id\n            WHERE photo_xref.restaurant_id = '${restaurant_id}'\n      ) s\n      WHERE rank_by_percent <= ${TOP_FRACTION_CUTOFF}\n      ORDER by random()\n      LIMIT 50\n    ) j1;\n  `)\n  const agg = result.rows[0].json_agg ?? []\n  const photos = agg.map((p: any) => {\n    p.photo = JSON.parse(p.photo)\n    return p\n  })\n  return photos\n}\n\nexport async function bestPhotosForTag(tag_id: uuid): Promise<PhotoXref[]> {\n  const photos = await resolvedWithFields(\n    () =>\n      query.photo_xref({\n        where: {\n          tag_id: {\n            _eq: tag_id,\n          },\n        },\n        order_by: [\n          {\n            photo: {\n              quality: order_by.desc,\n            },\n          },\n        ],\n        limit: 10,\n      }),\n    selectBasePhotoXrefFields\n  )\n  return uniqBy(photos, (p) => p.photo_id)\n}\n\nexport async function bestPhotosForRestaurantTags(\n  restaurant_id: uuid,\n  tag_id: uuid\n): Promise<PhotoXref[]> {\n  const photos = await resolvedWithFields(\n    () =>\n      query.photo_xref({\n        where: {\n          _and: [\n            {\n              restaurant_id: {\n                _eq: restaurant_id,\n              },\n            },\n            {\n              tag_id: {\n                _eq: tag_id,\n              },\n            },\n          ],\n        },\n        order_by: [\n          {\n            photo: {\n              quality: order_by.desc,\n            },\n          },\n        ],\n        limit: 10,\n      }),\n    selectBasePhotoXrefFields\n  )\n  return uniqBy(photos, (p) => p.photo_id)\n}\n\nconst IMAGE_QUALITY_API_BATCH_SIZE = 10\n\nasync function assessNewPhotos(unassessed_photos: string[]) {\n  let assessed: Partial<PhotoBase>[] = []\n  if (unassessed_photos.length == 0) return\n  __assessNewPhotos__count += 1\n  for (const batch of chunk(unassessed_photos, IMAGE_QUALITY_API_BATCH_SIZE)) {\n    assessed.push(...(await assessPhoto(batch)))\n  }\n  const photos = await photoBaseUpsert(assessed, photo_constraint.photo_url_key)\n  return photos\n}\n\nasync function assessPhoto(urls: string[]) {\n  const MAX_RETRIES = 3\n  let retries = 0\n  while (true) {\n    try {\n      return await assessPhotoWithoutRetries(urls)\n    } catch (error) {\n      console.log(error.message, 'on urls', urls, error.stack)\n      if (!error.message.includes('json')) {\n        throw error\n      }\n      retries += 1\n      if (retries > MAX_RETRIES) {\n        sentryMessage(MAX_RETRIES + ' failed attempts requesting image quality', { data: urls })\n        return []\n      }\n      console.log('Retrying Image Quality API')\n      await sleep(1000 * retries)\n    }\n  }\n}\n\n// gets quality + categories\nasync function assessPhotoWithoutRetries(urls: string[]) {\n  if (DISH_DEBUG) {\n    // prettier-ignore\n    console.log('Fetching Image Quality API batch...', urls.length, 'first:', urls[0])\n  }\n\n  const [imageQualities, imageCategories, _] = await Promise.all([\n    getImageQuality(urls),\n    getImageCategory(urls),\n    getImageSimilarity(urls),\n  ])\n\n  const res: Partial<PhotoBase>[] = []\n  for (const url of urls) {\n    const id = crypto.createHash('md5').update(url).digest('hex')\n    const quality = imageQualities.find((r) => id == r.image_id)?.mean_score_prediction\n    const categories = imageCategories.find((x) => x.url === url)?.categories\n    if (process.env.DISH_DEBUG) {\n      console.log('got image categories', categories?.map((x) => x.label).join(','))\n    }\n    if (!quality || !categories) {\n      console.warn('No result found!')\n      continue\n    }\n    res.push({\n      url,\n      quality,\n      categories,\n    })\n  }\n  return res\n}\n\nasync function getImageSimilarity(urls: string[]) {\n  // TODO\n  // use imghash + fast-levenshtein\n  for (const _ of urls) {\n  }\n}\n\nasync function getImageCategory(\n  urls: string[]\n): Promise<{ url: string; categories: { label: string; probability: number }[] }[]> {\n  const IMAGE_CATEGORY_API = `${process.env.IMAGE_RECOGNIZE_ENDPOINT}/recognize`\n  return await Promise.all(\n    urls.map(async (url) => {\n      const data = await fetch(url).then((res) => res.arrayBuffer())\n      const formdata = new FormData()\n      const parsedUrl = new URL(url)\n      const filename = basename(parsedUrl.pathname)\n      formdata.append('image', data, filename)\n      const response: any = await fetch(IMAGE_CATEGORY_API, {\n        method: 'POST',\n        body: formdata,\n      }).then((res) => res.json())\n      return {\n        categories: (response as any).labels,\n        url,\n      }\n    })\n  )\n  // serially to not overload the memory of image-recognize\n  // const res: { categories: any; url: string }[] = []\n  // for (const url of urls) {\n\n  // }\n  // return res\n}\n\nasync function getImageQuality(urls: string[]): Promise<ImageQualityResponse> {\n  const IMAGE_QUALITY_API = `${process.env.IMAGE_QUALITY_ENDPOINT}/prediction`\n  const qualityResponse: any = await fetch(IMAGE_QUALITY_API, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify(urls),\n  })\n  return (await qualityResponse.json()) as ImageQualityResponse\n}\n\nfunction proxyYelpCDN(photo: string) {\n  if (typeof process.env.YELP_CDN_AWS_PROXY === undefined) {\n    throw Error('SELF CRAWLER: Yelp AWS CDN proxy not set')\n  }\n  return photo.replace(\n    'https://s3-media0.fl.yelpcdn.com/',\n    //@ts-ignore\n    process.env.YELP_CDN_AWS_PROXY\n  )\n}\n\nasync function findUnassessedPhotos(photos: Partial<PhotoXref>[]): Promise<string[]> {\n  let unassessed: PhotoXref[] = []\n  const firstPhoto = photos[0]\n  if (!firstPhoto) {\n    console.log('none unassessed')\n    return []\n  }\n  if (firstPhoto.restaurant_id != ZeroUUID && firstPhoto.tag_id == ZeroUUID) {\n    unassessed = await unassessedPhotosForRestaurant(firstPhoto.restaurant_id)\n  }\n  if (firstPhoto.restaurant_id != ZeroUUID && firstPhoto.tag_id != ZeroUUID) {\n    unassessed = [\n      //\n      ...unassessed,\n      ...(await unassessedPhotosForRestaurantTag(firstPhoto.restaurant_id)),\n    ]\n  }\n  if (firstPhoto.tag_id != ZeroUUID && firstPhoto.restaurant_id == ZeroUUID) {\n    unassessed = [\n      //\n      ...unassessed,\n      ...(await unassessedPhotosForTag(firstPhoto.tag_id)),\n    ]\n  }\n\n  // nate:\n  // filter and delete invalid urls here as well in case we have old urls from previous scrapes that are no longer valid\n  // the other filter/delete only handles the current scrape\n  // tombh:\n  // but all these should be already uploaded to DO, so if a photo here is invalid, then either\n  // DO is broken or the previous validations let something slip through?\n  // so i feel like this could be removed. but it must be solving some problem, so i'll wait\n  // and see\n  // const validPhotos = (\n  //   await Promise.all(\n  //     unassessed.map(async (x) => {\n  //       if (await isValidPhoto(x.photo.url)) return x\n  //       await photoXrefDelete(x)\n  //       return null\n  //     })\n  //   )\n  // ).filter(isPresent)\n\n  return unassessed\n    .filter((p) => {\n      if (!p.photo?.url) {\n        console.error('findUnassessedPhotos(): Photo.url NOT NULL violation')\n        return false\n      }\n      return true\n    })\n    .map((p) => p.photo.url!)\n}\n\nasync function findNotUploadedPhotos(photos: Partial<PhotoXref>[]) {\n  let not_uploaded: PhotoXref[] = []\n  if (!photos[0]) {\n    console.log('no photos')\n    return not_uploaded\n  }\n  if (photos[0].restaurant_id != ZeroUUID && photos[0].tag_id == ZeroUUID) {\n    not_uploaded = await findNotUploadedRestaurantPhotos(photos[0].restaurant_id)\n  }\n  if (photos[0].restaurant_id != ZeroUUID && photos[0].tag_id != ZeroUUID) {\n    not_uploaded = await findNotUploadedRestaurantPhotos(photos[0].restaurant_id)\n  }\n  if (photos[0].tag_id != ZeroUUID && photos[0].restaurant_id == ZeroUUID) {\n    not_uploaded = await findNotUploadedTagPhotos(photos[0].tag_id)\n  }\n  return not_uploaded\n}\n\nasync function uploadToDOSpaces(photos: PhotoXref[]) {\n  __uploadToDOSpaces__count += 1\n  const DO_SPACES_UPLOAD_BATCH_SIZE = 50\n  let uploaded: PhotoXref[] = []\n  for (const batch of chunk(photos, DO_SPACES_UPLOAD_BATCH_SIZE)) {\n    uploaded.push(...(await uploadToDOSpacesBatch(batch)))\n  }\n  return uploaded\n}\n\nasync function uploadToDOSpacesBatch(photos: PhotoXref[]) {\n  console.log('Uploading images to DO Spaces...')\n  let failed_ids = await Promise.all(\n    photos.map(async (p) => {\n      if (!p.photo || !p.photo.origin) {\n        console.error('DO UPLOADER: Photo must have URL: ' + p)\n        return p.photo?.id\n      }\n      return sendToDO(p.photo.origin, p.photo.id)\n    })\n  )\n  failed_ids = failed_ids.filter(Boolean)\n  await deleteByIDs('photo', failed_ids)\n  const uploaded = photos.filter((p) => {\n    return !failed_ids.includes(p.id)\n  })\n  console.log(`... ${uploaded.length} (${failed_ids.length} failed) images uploaded DO Spaces.`)\n  return uploaded\n}\n\nexport async function sendToDO(url: string, id: string) {\n  url = proxyYelpCDN(url)\n  let response: Response\n  try {\n    response = await fetch(url, { method: 'HEAD' })\n  } catch (e) {\n    sentryMessage('Failed downloading image HEAD', { data: url })\n    return id\n  }\n  const mime_type = response.headers.get('content-type')\n  while (true) {\n    let retries = 1\n    const result = await doImageUpload(url, id, mime_type || 'application/json')\n    const status = result.status\n    if (status < 300) {\n      // success\n      return\n    }\n    if (status > 299 && status != 408) {\n      return id\n    }\n    if (status == 408) retries += 1\n    if (retries > 10) {\n      sentryException(new Error('DO Spaces PUT Rate Limit'), {\n        data: {\n          url: url,\n          id: id,\n        },\n      })\n      return id\n    }\n  }\n}\n\nasync function doImageUpload(url: string, id: uuid, content_type: string) {\n  const uploadUrl = `${DISH_API_ENDPOINT}/imageUpload`\n  try {\n    const result = await fetch(uploadUrl, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        photo_id: id,\n        photo_url: url,\n        content_type,\n      }),\n    })\n    console.log('imageUpload response: ', result.status, await result.text(), url)\n    return result\n  } catch (err) {\n    console.log('Failed uploading to ', uploadUrl)\n    throw err\n  }\n}\n\nexport async function findHeroImage(restaurant_id: uuid) {\n  return await PhotoXrefQueryHelpers.findOne(\n    {\n      restaurant_id,\n      type: 'hero',\n    },\n    selectBasePhotoXrefFields\n  )\n}\n\nexport async function uploadHeroImage(url: string, restaurant_id: uuid) {\n  const result = await photoUpsert([\n    {\n      restaurant_id,\n      tag_id: globalTagId,\n      type: 'hero',\n      photo: { url } as PhotoBase,\n    },\n  ])\n  if (!result) {\n    throw new Error(\"Hero image didn't upload\")\n  }\n  return result[0].url\n}\n", "import { RestaurantWithId, ZeroUUID, ensureJSONSyntax, restaurantFindOne } from '@dish/graph'\nimport { scrape_db } from '@dish/helpers-node'\nimport { clone } from 'lodash'\n\nimport { DoorDash } from './doordash/DoorDash'\nimport { GoogleGeocoder } from './google/GoogleGeocoder'\nimport { GrubHub } from './grubhub/GrubHub'\nimport { Infatuation } from './infatuation/Infatuation'\nimport { Michelin } from './michelin/Michelin'\nimport { Tripadvisor } from './tripadvisor/Tripadvisor'\nimport { UberEats } from './ubereats/UberEats'\nimport { Yelp } from './yelp/Yelp'\n\ntype LatLon = {\n  lon: number\n  lat: number\n}\n\nexport type Scrape<D extends ScrapeData = ScrapeData> = {\n  id?: string\n  time?: Date\n  restaurant_id: string\n  location: LatLon\n  source: string\n  id_from_source: string\n  data: D\n}\n\nexport type ScrapeData = { [key: string]: ScrapeData | any }\n\nexport function scrapeGetData<\n  S extends Scrape = Scrape,\n  Select extends Function = (s: S['data']) => any\n>(\n  scrape: S | null,\n  select: Select,\n  defaultValue: any = ''\n): Select extends (s: S['data']) => infer Res ? Res : any {\n  if (!scrape) {\n    return defaultValue\n  }\n  return clone(select(scrape.data) ?? defaultValue)\n}\n\nexport async function scrapeFindOneBySourceID(source: string, id: string, allow_not_found = false) {\n  const result = await scrape_db.query(`\n  SELECT *, st_asgeojson(location) as location\n  FROM scrape\n    WHERE source = '${source}'\n    AND id_from_source = '${id}'\n    AND restaurant_id != '${ZeroUUID}'\n  ORDER BY time DESC\n  LIMIT 1;\n`)\n  if (result.rows.length == 0) {\n    if (allow_not_found) {\n      return null\n    } else {\n      throw new Error('Scrape not found: ' + id)\n    }\n  }\n  result.rows[0].location = parseLocation(result.rows[0].location)\n  return result.rows[0] as Scrape\n}\n\nexport async function scrapeFindOneByUUID(id: string) {\n  const result = await scrape_db.query(`\n    SELECT *, st_asgeojson(location) as location\n    FROM scrape\n      WHERE id = '${id}'\n  `)\n  result.rows[0].location = parseLocation(result.rows[0].location)\n  return result.rows[0] as Scrape\n}\n\nfunction parseLocation(json: string) {\n  const location = JSON.parse(json)\n  return {\n    lon: location.coordinates[0],\n    lat: location.coordinates[1],\n  }\n}\n\nexport async function latestScrapeForRestaurant(restaurant: RestaurantWithId, source: string) {\n  const result = await scrape_db.query(`\n    SELECT *\n    FROM scrape\n      WHERE restaurant_id = '${restaurant.id}'\n      AND source = '${source}'\n    ORDER BY time DESC\n    LIMIT 1;\n  `)\n  if (result.rows.length == 0) {\n    if (process.env.NODE_ENV !== 'test') {\n      console.debug(`No scrapes found for ${source}: ` + restaurant.name)\n    }\n    return null\n  } else {\n    if (process.env.NODE_ENV !== 'test') {\n      console.log(`${source} scrape found for: ` + restaurant.name)\n    }\n    return result.rows[0] as Scrape\n  }\n}\n\nexport async function removeScrapeForRestaurant(restaurant: RestaurantWithId, source: string) {\n  console.log('Removing scrape for', restaurant.id)\n  await scrape_db.query(`\n    DELETE\n    FROM scrape\n      WHERE restaurant_id = '${restaurant.id}'\n      AND source = '${source}';\n  `)\n}\n\nexport async function scrapeInsert(scrape: Scrape) {\n  try {\n    const data = JSON.stringify(ensureJSONSyntax(scrape.data)).replace(/'/g, `''`)\n    const result = await scrape_db.query(`\n      INSERT INTO scrape (\n        time,\n        source,\n        id_from_source,\n        data,\n        restaurant_id,\n        location\n      ) VALUES (\n        NOW(),\n        '${scrape.source}',\n        '${scrape.id_from_source}',\n        '${data}'::jsonb,\n        '${scrape.restaurant_id}',\n        ST_GeomFromText('POINT(\n          ${scrape.location.lon} ${scrape.location.lat}\n        )', 4326)\n      )\n      RETURNING id;\n    `)\n    const res = result.rows[0].id as string\n    return res\n  } catch (err) {\n    console.error(`Error inserting scrape`, err)\n  }\n}\n\nexport async function scrapeUpdateBasic(scrape: Scrape) {\n  console.log(`Updating scrape ${scrape.id} to point to restaurant ${scrape.restaurant_id}`)\n  const result = await scrape_db.query(`\n    UPDATE scrape SET\n      restaurant_id = '${scrape.restaurant_id}',\n      location = ST_GeomFromText('POINT(\n        ${scrape.location.lon} ${scrape.location.lat}\n      )', 4326)\n    WHERE id = '${scrape.id}';\n  `)\n  return result.rows[0]\n}\n\nexport async function scrapeUpdateAllRestaurantIDs(\n  source: string,\n  id_from_source: string,\n  restaurant_id: string | null\n) {\n  restaurant_id = restaurant_id == null ? `NULL` : `'${restaurant_id}'`\n  await scrape_db.query(`\n    UPDATE scrape SET\n      restaurant_id = ${restaurant_id}\n    WHERE source = '${source}'\n      AND id_from_source = '${id_from_source}'\n  `)\n}\n\n// NB this does not deep merge, eg;\n// ```\n// select '{\"a\": {\"s1\": 1}}'::jsonb || '{\"a\": {\"s2\": 2}}'::jsonb\n// -- {\"a\": {\"s2\": 2}}\n// ```\n// It only merges the top-level keys:\n// // ```\n// select '{\"a\": {\"s1\": 1}}'::jsonb || '{\"b\": {\"s2\": 2}}'::jsonb\n// -- {\"a\": {\"s1\": 1}, \"b\": {\"s2\": 2}}\n// ```\nexport async function scrapeMergeData(id: string, data: ScrapeData) {\n  data = ensureJSONSyntax(data)\n  const stringified = JSON.stringify(data).replace(/'/g, `''`)\n  const result = await scrape_db.query(`\n    UPDATE scrape\n      SET data = data || '${stringified}'\n      WHERE id = '${id}'\n    RETURNING *;\n  `)\n  return result.rows[0]\n}\n\nexport async function deleteAllScrapesBySourceID(id: string) {\n  await scrape_db.query(`\n    DELETE FROM scrape WHERE id_from_source = '${id}';\n  `)\n}\n\nexport async function deleteAllTestScrapes() {\n  await scrape_db.query(`\n    DELETE FROM scrape WHERE id_from_source LIKE 'test%';\n  `)\n}\n\nexport async function scrapeGetAllDistinct() {\n  const result = await scrape_db.query(`SELECT scrape_id FROM distinct_sources`)\n  return result.rows\n}\n\nexport async function scrapeUpdateGeocoderID(scrape_id: string) {\n  const result = await scrape_db.query(\n    `\n      SELECT *, st_asgeojson(location) as location\n      FROM scrape WHERE id = '${scrape_id}'\n    `\n  )\n  let scrape = result.rows[0]\n  scrape.location = JSON.parse(scrape.location)\n  let deets: any\n  switch (scrape.source) {\n    case 'doordash':\n      deets = DoorDash.getNameAndAddress(scrape)\n      break\n    case 'google':\n      //deets = Google.getNameAndAddress(scrape)\n      break\n    case 'grubhub':\n      deets = GrubHub.getNameAndAddress(scrape)\n      break\n    case 'infatuation':\n      deets = Infatuation.getNameAndAddress(scrape)\n      break\n    case 'michelin':\n      deets = Michelin.getNameAndAddress(scrape)\n      break\n    case 'tripadvisor':\n      deets = Tripadvisor.getNameAndAddress(scrape)\n      break\n    case 'ubereats':\n      deets = UberEats.getNameAndAddress(scrape)\n      break\n    case 'yelp':\n      deets = Yelp.getNameAndAddress(scrape)\n      break\n    default:\n      break\n  }\n  const geocoder = new GoogleGeocoder()\n  const lon = scrape.location.coordinates[0]\n  const lat = scrape.location.coordinates[1]\n  const query = deets.name + ',' + deets.address\n  const google_id = await geocoder.searchForID(query, lat, lon)\n  if (google_id) {\n    const restaurant = await restaurantFindOne({ geocoder_id: google_id })\n    if (restaurant) {\n      console.log('SCRAPE GEOCODES', deets.name, scrape.restaurant_id, restaurant.id)\n      scrape.restaurant_id = restaurant.id\n      await scrapeUpdateAllRestaurantIDs(scrape.source, scrape.id_from_source, restaurant.id)\n    }\n  } else {\n    console.log('SCRAPE GEOCODES', deets.name, scrape.restaurant_id, null)\n    await scrapeUpdateAllRestaurantIDs(scrape.source, scrape.id_from_source, null)\n  }\n}\n", "import '@dish/common'\n\nimport { WorkerJob } from '@dish/worker'\nimport axios_base from 'axios'\nimport { JobOptions, QueueOptions } from 'bull'\nimport * as _ from 'lodash'\n\nimport { restaurantSaveCanonical } from '../canonical-restaurant'\nimport { ScrapeData, scrapeInsert } from '../scrape-helpers'\nimport { aroundCoords, geocode } from '../utils'\n\ntype BasicStore = {\n  id: string\n  lat: number\n  lng: number\n}\n\nconst DOORDASH_DOMAIN = process.env.DOORDASH_GRAPHQL_AWS_PROXY || 'https://www.doordash.com/'\n\nconst axios = axios_base.create({\n  baseURL: DOORDASH_DOMAIN + 'graphql',\n  headers: {\n    common: {\n      'Content-Type': 'application/json',\n    },\n  },\n})\n\nexport class DoorDash extends WorkerJob {\n  cookie: string = ''\n  // I assume the reasoning for the map view size for a delivery service is,\n  // what is the minimum radius that a restaurant will deliver to?\n  public MAPVIEW_SIZE = 2000\n  public SEARCH_RADIUS_MULTIPLIER = 5\n\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 5,\n      duration: 500,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  async allForCity(city_name: string) {\n    let stores: { [id: string]: BasicStore } = {}\n    console.log('Starting DoorDash crawler. Using domain: ' + DOORDASH_DOMAIN)\n    const coords = await geocode(city_name)\n    const region_coords = _.shuffle(\n      aroundCoords(coords[0], coords[1], this.MAPVIEW_SIZE, this.SEARCH_RADIUS_MULTIPLIER)\n    )\n    for (const coords of region_coords) {\n      const new_stores = await this.search(coords[0], coords[1])\n      for (const id of Object.keys(new_stores)) {\n        stores[id] = new_stores[id]\n      }\n      if (process.env.RUN_WITHOUT_WORKER == 'true') {\n        if (Object.keys(stores).length > 0) break\n      }\n    }\n    console.log(`DoorDash ${Object.keys(stores).length} store IDs found for ${city_name}`)\n    for (const id of Object.keys(stores)) {\n      await this.runOnWorker('getStore', [stores[id]])\n    }\n  }\n\n  async getCookie() {\n    const response = await axios.post('?operation=bootstrap', {\n      operationName: 'viewstate',\n      variables: {},\n      query: 'query viewstate {viewstate {id experiments __typename}}',\n    })\n    const dd_guest_id = response.headers['set-cookie'].find((c) => c.includes('dd_guest_id'))\n    this.cookie = dd_guest_id.split(';')[0].split('=')[1]\n  }\n\n  async graphRequest(graphql: any) {\n    if (!this.cookie || this.cookie == '') {\n      await this.getCookie()\n    }\n    console.log('GRAPH POST', DOORDASH_DOMAIN + 'graphql', this.cookie, graphql)\n    const response = await axios.post('/', graphql, {\n      headers: {\n        Cookie: 'dd_guest_id=' + this.cookie,\n      },\n    })\n    return response.data.data\n  }\n\n  async search(lat: number, lng: number, name?: string) {\n    let is_more = true\n    let stores: { [id: string]: BasicStore } = {}\n    let page = 0\n    console.log(`DoorDash searching at: ${lat}, ${lng}`)\n    while (is_more) {\n      const response = await this.graphRequest(this._searchGQL(lat, lng, page))\n      const results = response.storeSearch.stores\n      console.log('DOORDASH: search found ' + results.length + ' stores')\n      if (results.length > 0) {\n        for (const store of results) {\n          if (!name || store.name?.includes(name)) {\n            stores[store.id] = {\n              id: store.id,\n              lat: store.location.lat,\n              lng: store.location.lng,\n            }\n          }\n        }\n        page += 1\n      } else {\n        is_more = false\n      }\n    }\n    return stores\n  }\n\n  async getStore(store: BasicStore) {\n    const gql = this._getStoreGQL(store.id)\n    const response = await this.graphRequest(gql)\n    const main = response.storeInformation\n    this.log('DoorDash: saving \"' + main.name + '\"')\n    const id_from_source = main.id\n    const restaurant_id = await restaurantSaveCanonical(\n      'doordash',\n      id_from_source,\n      store.lng,\n      store.lat,\n      main.name,\n      main.address.printableAddress\n    )\n    const id = await scrapeInsert({\n      source: 'doordash',\n      restaurant_id,\n      id_from_source,\n      location: {\n        lon: store.lng,\n        lat: store.lat,\n      },\n      data: {\n        main,\n        menus: response.storeMenus,\n        storeMenuSeo: response.storeMenuSeo,\n      },\n    })\n    return id\n  }\n\n  static getNameAndAddress(scrape: ScrapeData) {\n    return {\n      name: scrape.data.main.name,\n      address: scrape.data.main.address.printableAddress,\n    }\n  }\n\n  _searchGQL(lat: number, lng: number, page: number = 0) {\n    const PER_PAGE = 500\n    const offset = page * PER_PAGE\n    return {\n      operationName: 'storeSearch',\n      variables: {\n        searchLat: lat,\n        searchLng: lng,\n        offset: offset,\n        limit: PER_PAGE,\n        query: null,\n      },\n      query: `query storeSearch(\n          $offset: Int!,\n          $limit: Int!,\n          $order: [String!],\n          $searchQuery: String,\n          $filterQuery: String,\n          $categoryQueryId: ID,\n          $searchLat: Float,\n          $searchLng: Float\n        ) {\n          storeSearch(\n            offset: $offset,\n            limit: $limit,\n            order: $order,\n            searchQuery: $searchQuery,\n            filterQuery: $filterQuery,\n            categoryQueryId: $categoryQueryId,\n            searchLat: $searchLat,\n            searchLng: $searchLng\n        ) {\n          numStores\n          stores {\n            id\n            name\n            description\n            averageRating\n            numRatings\n            priceRange\n            featuredCategoryDescription\n            deliveryFee\n            extraSosDeliveryFee\n            displayDeliveryFee\n            headerImgUrl\n            url\n            menus {\n              popularItems {\n                imgUrl\n              }\n            }\n            status {\n              unavailableReason\n            }\n            location {\n              lat\n              lng\n            }\n          }\n          storeItems {\n            id\n            name\n            price\n            imageUrl\n            store {\n              name\n              url\n              id\n            }\n          }\n        }\n      }`,\n    }\n  }\n\n  _getStoreGQL(id: string) {\n    return {\n      operationName: 'menu',\n      variables: {\n        storeId: id,\n        locale: 'en-US',\n        ddffWebHomepageCmsBanner: true,\n        isStorePageFeedMigration: false,\n      },\n      query: `query\n        menu(\n          $storeId: ID!,\n          $menuId: ID,\n          $ddffWebHomepageCmsBanner: Boolean,\n          $locale: String,\n          $isStorePageFeedMigration: Boolean!\n        ) {\n          ... @skip(if: $isStorePageFeedMigration) {\n            storeInformation(storeId: $storeId) {\n              id\n              name\n              isGoodForGroupOrders\n              offersPickup\n              offersDelivery\n              deliveryFee\n              sosDeliveryFee\n              numRatings\n              averageRating\n              shouldShowStoreLogo\n              isActive\n              isConsumerSubscriptionEligible\n              coverImgUrl\n              coverSquareImgUrl\n              businessHeaderImgUrl\n              distanceFromConsumer\n              distanceFromConsumerInMeters\n              providesExternalCourierTracking\n              fulfillsOwnDeliveries\n              isInDemandTest\n              isDeliverableToConsumerAddress\n              business {\n                id\n                name\n                link\n              }\n              businessVertical\n              address {\n                street\n                printableAddress\n                city\n                state\n                country\n                cityLink\n              }\n              status {\n                asapAvailable\n                asapMinutesRange\n              }\n              storeDisclaimers {\n                id\n                disclaimerDetailsLink\n                disclaimerLinkSubstring\n                disclaimerText\n                displayTreatment\n              }\n            }\n            storeMenus(storeId: $storeId, menuId: $menuId) {\n              allMenus {\n                id\n                name\n                subtitle\n                isBusinessEnabled\n                timesOpen\n              }\n              currentMenu {\n                id\n                timesOpen\n                hoursToOrderInAdvance\n                isCatering\n                minOrderSize\n                menuCategories {\n                  ...StoreMenuCategoryFragment\n                  items {\n                    ...StoreMenuListItemFragment\n                  }\n                }\n              }\n            }\n          }\n          storeCrossLinks(storeId: $storeId) {\n            trendingStores {\n              ...StoreCrossLinkItemFragment\n            }\n            trendingCategories {\n              ...StoreCrossLinkItemFragment\n            }\n            topCuisinesNearMe {\n              ...StoreCrossLinkItemFragment\n            }\n            nearbyCities {\n              ...StoreCrossLinkItemFragment\n            }\n          }\n          storeMenuSeo(storeId: $storeId, menuId: $menuId)\n          consumerCmsDetails(\n            placement: \"store\",\n            storeId: $storeId,\n            ddffWebHomepageCmsBanner: $ddffWebHomepageCmsBanner,\n            locale: $locale\n          ) {\n            banner {\n              isActive\n              campaignId\n              promoCode\n              description {\n                copy\n                color\n              }\n              modal {\n                description\n                label\n                terms\n              }\n              url\n              backgroundColor\n              desktopImage\n              mobileImage\n              opensModal\n              action\n              label {\n                copy\n                color\n              }\n            }\n          }\n        }\n        fragment StoreMenuCategoryFragment on StoreMenuCategory {\n          id\n          subtitle\n          title\n        }\n        fragment StoreMenuListItemFragment on StoreMenuListItem {\n          id\n          description\n          isTempDeactivated\n          price\n          imageUrl\n          name\n        }\n        fragment StoreCrossLinkItemFragment on StoreCrossLinkItem {\n          name\n          url\n        }`,\n    }\n  }\n}\n", "import { RestaurantWithId, ZeroUUID, restaurantFindOne, restaurantUpsert } from '@dish/graph'\n\nimport { GoogleGeocoder } from './google/GoogleGeocoder'\nimport { scrapeFindOneBySourceID } from './scrape-helpers'\n\n/**\n * On the logic of persisting the geocoder_id at this point rather than in a `BigJob`:\n *\n * There already existed a logic of adding the geocoder_ids in bulk through a worker job. But\n * after being away from the code for 6 months I was suddenly struck by the oddity of that approach.\n * It seems much more natural to be persisting the geocoder_id at the point when a canonical\n * restaurant is first created. There may be some non-obvious gotcha to this seemingly more intuitive\n * approach, so for now I will leave the `updateAllGeocoderIDs`` code.\n */\n\nexport async function restaurantSaveCanonical(\n  source: string,\n  id_from_source: string,\n  lon: number,\n  lat: number,\n  name: string,\n  address: string\n) {\n  const [restaurant_id, geocoder_id] = await findExistingCanonical(\n    source,\n    id_from_source,\n    lon,\n    lat,\n    name,\n    address\n  )\n  if (!/\\S/.test(address) || !address) {\n    throw new Error('Restaurant can only be saved with an address')\n  }\n  if (restaurant_id) {\n    return restaurant_id\n  }\n  const [restaurant] = await restaurantUpsert([\n    {\n      name,\n      address,\n      location: {\n        type: 'Point',\n        coordinates: [lon, lat],\n      },\n      geocoder_id,\n    },\n  ])\n  if (process.env.RUN_WITHOUT_WORKER != 'true') {\n    console.log('Created new canonical restaurant: ' + restaurant.id)\n  }\n  return restaurant.id\n}\n\nasync function findExistingCanonical(\n  source: string,\n  id_from_source: string,\n  lon: number,\n  lat: number,\n  name: string,\n  address: string\n): Promise<[string | undefined, string | undefined]> {\n  const scrape = await scrapeFindOneBySourceID(source, id_from_source, true)\n  let restaurant: RestaurantWithId | null\n  let google_id: string\n  if (scrape && scrape.restaurant_id !== ZeroUUID) {\n    restaurant = await restaurantFindOne({ id: scrape.restaurant_id })\n    if (restaurant && restaurant.geocoder_id) {\n      return [restaurant.id, undefined]\n    }\n  }\n  console.log('findExistingCanonical, no existing scrape or restaurant, geocoding...')\n  const [_restaurant, _google_id] = await geocodeRestaurant(name, address, lat, lon)\n  restaurant = _restaurant\n  google_id = _google_id\n  if (restaurant) {\n    console.log('found restaurant via geocoder_id', restaurant.id)\n    return [restaurant.id, undefined]\n  } else {\n    console.log('first ever scrape of ', name)\n    return [undefined, google_id]\n  }\n}\n\nexport async function geocodeRestaurant(name: string, address: string, lat: number, lon: number) {\n  if (!/\\S/.test(name) || !name) {\n    throw new Error('Geocoder must be given a name')\n  }\n  if (!/\\S/.test(address) || !address) {\n    throw new Error('Geocoder must be given an address')\n  }\n  const geocoder = new GoogleGeocoder()\n  const query = name + ', ' + address\n  const google_id = await geocoder.searchForID(query, lat, lon)\n  if (!google_id) {\n    throw new Error(`No google id ${query} ${lat} ${lon} for ${name}, ${address}`)\n  }\n  const restaurant = await restaurantFindOne({ geocoder_id: google_id })\n  return [restaurant, google_id]\n}\n", "import '@dish/common'\n\nimport { sleep } from '@dish/async'\nimport { settingFindOne } from '@dish/graph'\nimport { ProxiedRequests } from '@dish/worker'\nimport _ from 'lodash'\n\nimport { PLEASE, UpdateSearchEndpoint } from './UpdateSearchEndpoint'\n\nexport const GOOGLE_SEARCH_ENDPOINT_KEY = 'GOOGLE_SEARCH_ENDPOINT'\nexport const LON_TOKEN = '%LON%'\nexport const LAT_TOKEN = '%LAT%'\nexport const google_geocoder_id_regex = /(0x[a-f0-9]{13,16}:0x[a-f0-9]{13,16})/\n\nconst GOOGLE_DOMAIN = 'https://www.google.com'\nconst SEARCH_ENDPOINT_EXPIRED = 'GOOGLE GEOCODER: search endpoint expired'\nconst ID_NOT_FOUND = 'GOOGLE GEOCODER: ID not found'\nconst googleAPI = new ProxiedRequests(\n  GOOGLE_DOMAIN,\n  process.env.GOOGLE_AWS_PROXY || GOOGLE_DOMAIN,\n  {\n    headers: {\n      'X-My-X-Forwarded-For': 'www.google.com',\n    },\n  }\n)\n\nString.prototype.replaceAll = function (search, replacement) {\n  var target = this\n  return target.replace(new RegExp(search, 'g'), replacement)\n}\n\nexport class GoogleGeocoder {\n  query!: string\n  lon!: number\n  lat!: number\n  searchEndpoint!: string\n\n  async searchForID(query: string, lat: number, lon: number) {\n    let retries = 0\n    this.query = query\n    this.lat = lat\n    this.lon = lon\n    await this.getSearchEndpoint()\n    while (retries < 3) {\n      try {\n        return await this._searchForID()\n      } catch (e: any) {\n        if (e.message == ID_NOT_FOUND || e.message == SEARCH_ENDPOINT_EXPIRED) {\n          console.log(\n            `GOOGLE GEOCODER (retry ${retries}) failed for: \"${query}\". Error: ${e.message}`\n          )\n          retries++\n          await sleep(1000)\n          await this.getSearchEndpoint()\n        } else {\n          throw new Error(e)\n        }\n      }\n    }\n    const message = 'GOOGLE GEOCODER: retries failed getting ID for: ' + query\n    throw new Error(message)\n  }\n\n  private async getSearchEndpointSetting() {\n    const result = await settingFindOne({\n      key: GOOGLE_SEARCH_ENDPOINT_KEY,\n    })\n    return result?.value\n  }\n\n  private async getSearchEndpoint() {\n    this.searchEndpoint = await this.getSearchEndpointSetting()\n    if (typeof this.searchEndpoint !== 'string') {\n      const updater = new UpdateSearchEndpoint()\n      await updater.getNewSearchEndpoint()\n      this.searchEndpoint = await this.getSearchEndpointSetting()\n    }\n    if (typeof this.searchEndpoint !== 'string') {\n      throw new Error('GOOGLE_SEARCH_ENDPOINT not found in DB')\n    }\n  }\n\n  private formatSearchURL() {\n    const url = this.searchEndpoint\n    return (url.startsWith('/') ? url : `/${url}`)\n      .replaceAll(LON_TOKEN, this.lon.toString())\n      .replaceAll(LAT_TOKEN, this.lat.toString())\n      .replaceAll(PLEASE, encodeURIComponent(this.query))\n  }\n\n  private async _searchForID() {\n    const url = this.formatSearchURL()\n    const response = await googleAPI.getText(url, {\n      headers: { 'user-agent': 'PLEASE' },\n      skipBrowser: true,\n    })\n    if (this._hasSearchExpired(response)) {\n      throw new Error(SEARCH_ENDPOINT_EXPIRED)\n    }\n    // For example: 0x7b300695e1e94c7:0x1706843e5f6d1bd2\n    const matches = response.match(google_geocoder_id_regex)\n    if (matches) {\n      return matches[0]\n    } else {\n      console.error('response doesnt match', response.slice(0, 200) + '...')\n      throw new Error(ID_NOT_FOUND)\n    }\n  }\n\n  // Example of expired search:\n  // \"search?tbm=map&authuser=0&hl=en&gl=us&pb=!4m9!1m3!1d3285.0632427323467!2d%LON%!3d%LAT%!2m0!3m2!1i1366!2i800!4f13.1!7i20!10b1!12m8!1m1!18b1!2m3!5m1!6e2!20e3!10b1!16b1!19m4!2m3!1i360!2i120!4i8!20m57!2m2!1i203!2i100!3m2!2i4!5b1!6m6!1m2!1i86!2i86!1m2!1i408!2i240!7m42!1m3!1e1!2b0!3e3!1m3!1e2!2b1!3e2!1m3!1e2!2b0!3e3!1m3!1e3!2b0!3e3!1m3!1e8!2b0!3e3!1m3!1e3!2b1!3e2!1m3!1e9!2b1!3e2!1m3!1e10!2b0!3e3!1m3!1e10!2b1!3e2!1m3!1e10!2b0!3e4!2b1!4b1!9b0!22m6!1schwPX7CqB9H99AOy-r0o%3A1!2s1i%3A0%2Ct%3A11886%2Cp%3AchwPX7CqB9H99AOy-r0o%3A1!7e81!12e5!17schwPX7CqB9H99AOy-r0o%3A2!18e15!24m50!1m12!13m6!2b1!3b1!4b1!6i1!8b1!9b1!18m4!3b1!4b1!5b1!6b1!2b1!5m5!2b1!3b1!5b1!6b1!7b1!10m1!8e3!14m1!3b1!17b1!20m4!1e3!1e6!1e14!1e15!24b1!25b1!26b1!30m1!2b1!36b1!43b1!52b1!54m1!1b1!55b1!56m2!1b1!3b1!65m5!3m4!1m3!1m2!1i224!2i298!26m4!2m3!1i80!2i92!4i8!30m28!1m6!1m2!1i0!2i0!2m2!1i458!2i800!1m6!1m2!1i1316!2i0!2m2!1i1366!2i800!1m6!1m2!1i0!2i0!2m2!1i1366!2i20!1m6!1m2!1i0!2i780!2m2!1i1366!2i800!34m14!2b1!3b1!4b1!6b1!8m4!1b1!3b1!4b1!6b1!9b1!12b1!14b1!20b1!23b1!37m1!1e81!42b1!47m0!49m1!3b1!50m4!2e2!3m2!1b1!3b1!65m0&q=P%20LEASE&oq=P%20LEASE&gs_l=maps.3...158.237.1.246.5.1.0.0.0.0.0.0..0.0....0...1ac.1.64.maps..5.0.0....0.&tch=1&ech=1&psi=chwPX7CqB9H99AOy-r0o.1594825843774.1\"\n  _hasSearchExpired(result: string) {\n    const query_matches = result.match(/q=(.*?)\\\\u0026/)\n    if (!query_matches) return true\n    const google_formatted_query = query_matches[1]\n    const google_clean_query = decodeURIComponent(google_formatted_query)\n    const expected_query = encodeURIComponent(this.query)\n    if (\n      google_clean_query === this.query ||\n      google_clean_query === expected_query ||\n      google_formatted_query === expected_query\n    ) {\n      return false\n    }\n    const expected_query_2 = expected_query\n      .replaceAll('%20', '+')\n      .replaceAll('%2C', ',')\n      .replaceAll('%2F', '\\\\/')\n      .replaceAll('%3A', ':')\n      .replaceAll('%40', '@')\n      .replaceAll('%3B', ';')\n      .replaceAll('%24', '$')\n    if (\n      google_formatted_query != expected_query &&\n      google_formatted_query != expected_query_2 &&\n      google_clean_query != this.query\n    ) {\n      console.log(\n        `GOOGLE GEOCODER: possible search expiry, query mismatch:\n        Query:       \"${this.query}\"\n        Expected:     \"${expected_query}\"\n        GoogleClean: \"${google_clean_query}\"\n        Google:      \"${google_formatted_query}\"\n        Dish:        \"${expected_query}\"\n        Dish2:       \"${expected_query_2}\"\\n`,\n        'result: ',\n        result\n      )\n      return true\n    }\n    return false\n  }\n}\n\nexport function isGoogleGeocoderID(id: string) {\n  return id.match(google_geocoder_id_regex)\n}\n", "import { settingUpsert } from '@dish/graph'\nimport { JobOptions, QueueOptions } from 'bull'\nimport _ from 'lodash'\n\nimport { GOOGLE_SEARCH_ENDPOINT_KEY, LAT_TOKEN, LON_TOKEN } from './GoogleGeocoder'\nimport { GooglePuppeteerJob } from './GooglePuppeteerJob'\n\nconst sleep = (ms: number) => new Promise((res) => setTimeout(res, ms))\n\nexport const PLEASE = `PLEASE`\n\nString.prototype.replaceAll = function (search, replacement) {\n  var target = this\n  return target.replace(new RegExp(search, 'g'), replacement)\n}\n\nexport class UpdateSearchEndpoint extends GooglePuppeteerJob {\n  searchEndpoint!: string\n  lat!: number\n  lon!: number\n\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 1,\n      duration: 1000,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  constructor() {\n    super()\n    this.puppeteer.watch_requests_for = 'search?'\n  }\n\n  // We need a particular string in the API request that seems to be some\n  // kind of short-lived session token. To find this token we have to at least\n  // attempt to use the search box on a Google Maps page, and then listen for\n  // the relevant search API request.\n  async getNewSearchEndpoint() {\n    console.log('GOOGLE CRAWLER: getting new search endpoint')\n    await this.boot()\n    await this._catchSearchEndpoint()\n    this._templatiseSearchEndpoint()\n    console.log('insert setting', this.searchEndpoint)\n    await settingUpsert([\n      {\n        key: GOOGLE_SEARCH_ENDPOINT_KEY,\n        // TODO: FIX, FlatResolvedModel not working\n        value: this.searchEndpoint,\n      },\n    ])\n    console.log('GOOGLE CRAWLER: search endpoint successfully updated')\n  }\n\n  _templatiseSearchEndpoint() {\n    this.searchEndpoint = this.puppeteer.found_watched_request\n      .replaceAll('https://www.google.com/', '')\n      .replaceAll(this.lon.toString(), LON_TOKEN)\n      .replaceAll(this.lat.toString(), LAT_TOKEN)\n  }\n\n  jitter() {\n    const min = -0.01\n    const max = 0.01\n    return Math.random() * (max - min) + min\n  }\n\n  // This seems pointless, but it's the interaction that triggers the page into\n  // making the all-important search API request that contains the search token we\n  // can later reuse.\n  //\n  // The search token doesn't *seem* to be location dependent, but we randomise the\n  // lat/lon here just to hide ourselves from any Google automation.\n  async _theBrokenSearchBoxInteraction() {\n    this.lat = 37.7749 + this.jitter()\n    this.lon = -122.4194 + this.jitter()\n    const url = this.GOOGLE_DOMAIN + `/maps/@${this.lat},${this.lon},17z/`\n    const page = this.puppeteer.page\n    console.log('_theBrokenSearchBoxInteraction', url)\n    await page.goto(url)\n    await sleep(Math.random() * 100)\n    await page.focus('#searchboxinput')\n    console.log('searching')\n    await sleep(Math.random() * 100)\n    await page.keyboard.type(PLEASE)\n    await sleep(Math.random() * 100)\n    await page.keyboard.press('Enter')\n  }\n\n  async _catchSearchEndpoint() {\n    let retries = 0\n    while (retries < 4) {\n      await this._theBrokenSearchBoxInteraction()\n      await this._waitForSearchAPIRequest()\n      if (this.puppeteer.found_watched_request) {\n        break\n      } else {\n        await this.puppeteer.page.reload()\n        retries++\n      }\n    }\n    if (!this.puppeteer.found_watched_request) {\n      throw new Error('Google search API not seen after ' + retries + ' tries')\n    }\n  }\n\n  async _waitForSearchAPIRequest() {\n    let count = 0\n    while (!this.puppeteer.found_watched_request) {\n      await sleep(80)\n      count++\n      if (count > 500) break\n    }\n  }\n}\n", "import '@dish/common'\n\nimport { WorkerJob } from '@dish/worker'\nimport _ from 'lodash'\n\nimport { Puppeteer } from '../Puppeteer'\n\nexport class GooglePuppeteerJob extends WorkerJob {\n  GOOGLE_DOMAIN = 'https://www.google.com'\n  puppeteer: Puppeteer\n  booted = false\n\n  constructor() {\n    super()\n    this.puppeteer = new Puppeteer(this.GOOGLE_DOMAIN, process.env.GOOGLE_AWS_PROXY)\n  }\n\n  async boot() {\n    await this.puppeteer.boot()\n    this.booted = true\n  }\n}\n", "import '@dish/common'\n\nimport { exec } from 'child_process'\n\nimport { allSettledFirstFulfilled } from '@dish/helpers'\nimport ProxyChain from 'proxy-chain'\nimport { Browser, Page, Request } from 'puppeteer'\nimport puppeteer from 'puppeteer-extra'\nimport StealthPlugin from 'puppeteer-extra-plugin-stealth'\n\nconst execP = (cmd: string) =>\n  new Promise<string>((res, rej) => {\n    exec(cmd, (err, stdout) => (err ? rej(err) : res(stdout.trim())))\n  })\n\nconst stealth = StealthPlugin()\n// @ts-ignore\nstealth.onBrowser = () => {}\npuppeteer.use(stealth)\n\nconst USER_AGENT =\n  'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'\nconst proxy_host = process.env.LUMINATI_PROXY_HOST + ':' + process.env.LUMINATI_PROXY_PORT\nconst proxy_auth =\n  process.env.LUMINATI_PROXY_DATACENTRE_USER + ':' + process.env.LUMINATI_PROXY_DATACENTRE_PASSWORD\nconst PROXY = 'http://' + proxy_auth + '@' + proxy_host\n\nexport class Puppeteer {\n  total = 0\n  request_count = 0\n  blocked_count = 0\n  current_scroll = 0\n  page!: Page\n  browser!: Browser\n  aws_proxy: string\n  watch_requests_for!: string\n  found_watched_request!: string\n\n  constructor(public domain: string, _aws_proxy: string | undefined) {\n    if (typeof _aws_proxy == 'undefined') {\n      throw new Error('Puppeteer: No AWS proxy set')\n    } else {\n      this.aws_proxy = _aws_proxy\n      console.log('Using AWS proxy: ' + this.aws_proxy)\n    }\n  }\n\n  async boot() {\n    await this.startProxyServer()\n    await this.startBrowser()\n  }\n\n  async startBrowser() {\n    await this.startPuppeteer()\n    await this.interceptRequests()\n  }\n\n  async restartBrowser() {\n    console.log('PUPETEER: Restarting browser...')\n    await this.close()\n    await this.startBrowser()\n    console.log('PUPETEER: Browser restarted.')\n  }\n\n  async close() {\n    await this.browser.close()\n  }\n\n  async sleep(ms: number) {\n    return new Promise((res) => setTimeout(res, ms))\n  }\n\n  async startProxyServer() {\n    const server = new ProxyChain.Server({\n      port: 8000,\n      prepareRequestFunction: () => {\n        return {\n          upstreamProxyUrl: PROXY,\n        }\n      },\n    })\n\n    server.listen(() => {\n      console.log(`Proxy server is listening on port ${server.port}`)\n    })\n\n    // Emitted when HTTP connection is closed\n    server.on('connectionClosed', ({ stats }) => {\n      this.total = this.total + stats.srcTxBytes + stats.srcRxBytes\n    })\n\n    // Emitted when HTTP request fails\n    server.on('requestFailed', ({ request, error }) => {\n      console.log(`Request ${request.url} failed`)\n      console.error(error)\n    })\n  }\n\n  async startPuppeteer() {\n    const fireprox_host_sig = '*.execute-api.us-west-2.amazonaws.com'\n    const proxy_bypass = fireprox_host_sig\n    puppeteer.defaultArgs({\n      headless: false,\n      args: [\n        '--proxy-server=localhost:8000',\n        `--proxy-bypass-list=${proxy_bypass}`,\n        '--no-sandbox',\n      ],\n    })\n    const chromium = await allSettledFirstFulfilled<string>([\n      execP(`which xvfb-chromium`),\n      execP(`which chromium`),\n      execP(`which google-chrome`),\n      execP(`which google-chrome-stable`),\n      execP(`which chrome`),\n    ])\n    this.browser = await puppeteer.launch({\n      pipe: true,\n      ignoreDefaultArgs: ['--enable-automation'],\n      args: ['--no-sandbox'],\n      ...(chromium && {\n        executablePath: chromium,\n      }),\n    })\n    this.page = await this.browser.newPage()\n\n    this.page.on('error', (err) => {\n      console.log('Browser error: ', err)\n    })\n\n    this.page.on('pageerror', (pageerr) => {\n      console.log('Browser page error: ', pageerr)\n    })\n    await this.page.setViewport({ width: 1366, height: 800 })\n    await this.page.setUserAgent(USER_AGENT)\n  }\n\n  async interceptRequests() {\n    await this.page.setRequestInterception(true)\n    this.page.on('request', this._interceptRequests)\n  }\n\n  async stopInterceptingRequests() {\n    this.page.off('request', this._interceptRequests)\n    await this.page.setRequestInterception(false)\n  }\n\n  _logBlockCounts() {\n    console.log('Blocked: ' + this.blocked_count, 'Allowed: ' + this.request_count)\n  }\n\n  private _interceptRequests = async (request: Request) => {\n    this._waitForSpecificRequest(request)\n    const url = this._rewriteDomainsToAWS(request)\n    if (!url) {\n      this.blocked_count += 1\n      return\n    }\n    if (this._blockImage(request)) {\n      this.blocked_count += 1\n      return\n    }\n    this.request_count += 1\n    request.continue({ url })\n  }\n\n  _blockImage(request: Request) {\n    const blockable = [/\\.png/, /\\.gif/, /.jpg/, /.jpeg/, /k-no$/, /k-mo$/, /\\.woff/]\n    const is_image = blockable.some((e) => {\n      return e.test(request.url())\n    })\n    const is_needed_image = this._isGoogleUserContent(request)\n    if (is_image && !is_needed_image) {\n      request.abort()\n      return true\n    }\n    return false\n  }\n\n  _rewriteDomainsToAWS(request: Request) {\n    const is_main_domain = request.url().includes(this.domain)\n    const is_googleusercontent = this._isGoogleUserContent(request)\n    if (this._isRequestSensitiveToAWSProxy(request)) {\n      return request.url()\n    }\n    if (is_main_domain) {\n      const proxied_url = request.url().replace(this.domain, this.aws_proxy).replace('//', '/')\n      return proxied_url\n    } else if (is_googleusercontent) {\n      const proxied_url = request\n        .url()\n        .replace(/https:\\/\\/.*\\.com\\//, process.env.GOOGLE_USERCONTENT_AWS_PROXY || '')\n        .replace('//', '/')\n      return proxied_url\n    } else {\n      request.abort()\n      return false\n    }\n  }\n\n  _isRequestSensitiveToAWSProxy(request: Request) {\n    if (request.url().includes('authuser')) return true\n  }\n\n  _isGoogleUserContent(request: Request) {\n    return request.url().includes('googleusercontent.com')\n  }\n\n  _waitForSpecificRequest(request: Request) {\n    if (!this.watch_requests_for) return\n    if (request.url().includes(this.watch_requests_for)) {\n      console.log('found it!')\n      this.found_watched_request = request.url()\n    }\n  }\n\n  async getPage(url: string) {\n    await this.page.goto(url)\n    await this.screenshot()\n  }\n\n  async screenshot() {\n    await this.page.screenshot({ path: 'screenshot.jpg' })\n  }\n\n  async getCurrentHistoryURL() {\n    return await this.page.evaluate(() => window.location.href)\n  }\n\n  async waitForURLChange(url: string) {\n    console.log('Waiting for URL to change ...')\n    while ((await this.getCurrentHistoryURL()) == url) {\n      await this.sleep(100)\n    }\n    console.log('...URL changed')\n  }\n\n  async getElementText(selector: string) {\n    await this.page.waitForSelector(selector, {\n      // dont need long timeout here its already a loaded page\n      timeout: 4000,\n    })\n    const element = await this.page.$(selector)\n    return await this.page.evaluate((element) => element.textContent, element)\n  }\n\n  async scrollAllIntoView(selector: string) {\n    this.current_scroll = 0\n    let preCount = 0\n    await this.page.waitForSelector(selector)\n    let withinTimeout = true\n    while (withinTimeout) {\n      preCount = await this._countSelectors(selector)\n      console.log('scrolling to', selector, preCount)\n      await this._scrollIntoView(selector)\n      if (process.env.DISH_ENV == 'test' && preCount > 10) {\n        console.log('GOOGLE: Exiting scroll loop, in test')\n        break\n      }\n      withinTimeout = await this.waitForMoreElements(selector, preCount)\n    }\n  }\n\n  async waitForMoreElements(selector: string, preCount: number) {\n    const TIME_TO_WAIT_FOR_MORE_ELEMENTS = 30 * 1000\n    const delay = 200\n    let elapsed = 0\n    while (elapsed < TIME_TO_WAIT_FOR_MORE_ELEMENTS) {\n      const postCount = await this._countSelectors(selector)\n      if (postCount > preCount) return true\n      await this.sleep(delay)\n      elapsed = elapsed + delay\n    }\n    return false\n  }\n\n  async _scrollIntoView(selector: string) {\n    this.current_scroll = await this.page.evaluate(\n      async (selector, current_scroll) => {\n        async function sleep(ms: number) {\n          return new Promise((res) => setTimeout(res, ms))\n        }\n        const elements = document.querySelectorAll(selector)\n        for (let i = current_scroll; i < elements.length; i++) {\n          elements[i].scrollIntoView()\n          current_scroll += 1\n          await sleep(500)\n        }\n        return current_scroll\n      },\n      selector,\n      this.current_scroll\n    )\n  }\n\n  async _countSelectors(selector: string) {\n    return await this.page.evaluate((selector) => {\n      return document.querySelectorAll(selector).length\n    }, selector)\n  }\n}\n", "import '@dish/common'\n\nimport util from 'util'\n\nimport { Restaurant, settingGet, settingSet } from '@dish/graph'\nimport { Database } from '@dish/helpers-node'\nimport axios from 'axios'\nimport _ from 'lodash'\nimport moment, { Moment } from 'moment'\n\nimport { DISH_DEBUG } from './constants'\nimport { isGoogleGeocoderID } from './google/GoogleGeocoder'\n\nconst exec = util.promisify(require('child_process').exec)\n\nconst HEREMAPS_API_TOKEN = process.env.HEREMAPS_API_TOKEN\n\ntype Coord = [number, number]\n\nexport const CITY_LIST = [\n  'San Francisco, CA',\n  'Los Angeles, CA',\n  'San Jose, CA',\n  'Redwood City, CA',\n  'Fremont, CA',\n  'San Rafael, CA',\n  'Chicago, Illinois',\n  'Tuscon, Arizona',\n  'Istanbul, Turkey',\n]\n\nfunction getCityFlagOrEnv() {\n  if (process.env.CITY) return process.env.CITY\n  const i = process.argv.findIndex((x) => x === '--city')\n  if (i > 0) {\n    return process.argv\n      .slice(i + 1)\n      .join(' ')\n      .replaceAll('\"', '')\n      .replaceAll(\"'\", '')\n  }\n}\n\nexport function getCities() {\n  const specific = getCityFlagOrEnv()\n  return specific ? [specific] : CITY_LIST\n}\n\nexport function shiftLatLonByMetres(\n  lat: number,\n  lon: number,\n  diff_north: number,\n  diff_east: number\n): [number, number] {\n  const RADIUS = 6378137\n  const diff_lat = diff_north / RADIUS\n  const diff_lon = diff_east / (RADIUS * Math.cos((Math.PI * lat) / 180))\n\n  const latO = lat + diff_lat * (180 / Math.PI)\n  const lonO = lon + diff_lon * (180 / Math.PI)\n  return [latO, lonO]\n}\n\n// Returns an array of coords that fill an area. Think of it as a way\n// to fill a space with a number of equally spaced boxes. The number of\n// boxes is (chunk_factor + 1)^2\nexport function aroundCoords(lat: number, lon: number, chunk_size: number, chunk_factor: number) {\n  let coords: Coord[] = []\n  const edge = chunk_size * chunk_factor\n  for (let y = edge; y >= -edge; y = y - chunk_size) {\n    for (let x = -edge; x <= edge; x = x + chunk_size) {\n      coords.push(shiftLatLonByMetres(lat, lon, y, x))\n    }\n  }\n  return coords\n}\n\nexport function boundingBoxFromCenter(lat: number, lon: number, radius: number): [Coord, Coord] {\n  const top_right = shiftLatLonByMetres(lat, lon, radius, radius)\n  const bottom_left = shiftLatLonByMetres(lat, lon, -radius, -radius)\n  return [top_right, bottom_left]\n}\n\nexport async function geocode(address: string): Promise<Coord> {\n  let coordinates: Coord\n  const key = 'GEOCODER_CACHE'\n  const cache = await settingGet(key)\n  const address_as_key = address.toLowerCase().replace(/[\\W_]+/g, '_')\n  if (cache[address_as_key]) {\n    coordinates = cache[address_as_key]\n  } else {\n    coordinates = await _geocode_without_cache(address)\n    cache[address_as_key] = coordinates\n    console.log('Updating geocoder cache for: ' + address)\n    await settingSet(key, cache)\n  }\n  return coordinates\n}\n\nasync function _geocode_without_cache(address: string): Promise<Coord> {\n  const base = 'https://geocoder.ls.hereapi.com/6.2/geocode.json?apiKey='\n  const query = '&searchtext=' + encodeURI(address)\n  const url = base + HEREMAPS_API_TOKEN + query\n  const response = await axios.get(url)\n  const result = response.data.Response.View[0].Result[0]\n  const coords = result.Location.DisplayPosition\n  return [coords.Latitude, coords.Longitude]\n}\n\nfunction geoJSONPolygon(corners: Coord[]) {\n  return {\n    type: 'Feature',\n    properties: { prop0: 'value0' },\n    geometry: {\n      type: 'Polygon',\n      coordinates: [corners],\n    },\n  }\n}\n\nexport function aroundCoordsGeoJSON(lat: number, lon: number, radius: number, size: number) {\n  const coords = aroundCoords(lat, lon, radius, size)\n  let boxes: any[] = []\n  const offset = radius / 2\n  for (const centre of coords) {\n    const yc = centre[0]\n    const xc = centre[1]\n    const corners: Coord[] = []\n    const joined = _.reverse(shiftLatLonByMetres(yc, xc, -offset, -offset))\n    corners.push(joined)\n    corners.push(_.reverse(shiftLatLonByMetres(yc, xc, -offset, offset)))\n    corners.push(_.reverse(shiftLatLonByMetres(yc, xc, offset, offset)))\n    corners.push(_.reverse(shiftLatLonByMetres(yc, xc, offset, -offset)))\n    corners.push(joined)\n    boxes.push(geoJSONPolygon(corners))\n  }\n  return JSON.stringify({\n    type: 'FeatureCollection',\n    features: boxes,\n  })\n}\n\nexport function toDBDate(in_date: Date | string, format: string = '') {\n  let m: Moment\n  if (format == '') {\n    m = moment(in_date)\n  } else {\n    m = moment(in_date, format)\n  }\n  const out_date = m.format('YYYY-MM-DD') + 'T00:00:00.0+00:00'\n  return out_date\n}\n\nexport function googlePermalink(id: string, lat: number, lon: number) {\n  return (\n    `https://www.google.com/maps/place/` +\n    `@${lat},${lon},11z/data=!3m1!4b1!4m5!3m4!1s${id}!8m2!3d${lat}!4d${lon}`\n  )\n}\n\nexport async function restaurantFindIDBatchForCity(\n  size: number,\n  previous_id: string,\n  city: string,\n  radius = 0.5\n): Promise<Restaurant[]> {\n  const coords = await geocode(city)\n  const query = `\n    SELECT id FROM restaurant\n      WHERE ST_DWithin(\n        location,\n        ST_Makepoint(${coords[1]}, ${coords[0]}),\n        ${radius}\n      )\n      AND id > '${previous_id}'\n    ORDER BY id\n    LIMIT ${size}\n  `\n  const result = await Database.one_query_on_main(query)\n  return result.rows\n}\n\nexport async function restaurantCountForCity(city: string, radius = 0.5) {\n  const coords = await geocode(city)\n  const query = `\n    SELECT count(*) FROM restaurant\n      WHERE ST_DWithin(\n        location,\n        ST_Makepoint(${coords[1]}, ${coords[0]}),\n        ${radius}\n      )\n  `\n  const result = await Database.one_query_on_main(query)\n  return result.rows[0].count\n}\n\nexport async function restaurantFindBasicBatchForAll(\n  size: number,\n  previous_id: string,\n  extra_where = ''\n): Promise<Restaurant[]> {\n  const query = `\n    SELECT id, name, address, st_asgeojson(location) as location FROM restaurant\n      WHERE id > '${previous_id}'\n      ${extra_where}\n    ORDER BY id\n    LIMIT ${size}\n  `\n  const result = await Database.one_query_on_main(query)\n  return result.rows\n}\n\nexport async function batchIDsForAll(\n  table: string,\n  size: number,\n  previous_id: string,\n  extra_where = ''\n) {\n  const query = `\n    SELECT id FROM ${table}\n      WHERE id > '${previous_id}'\n      ${extra_where}\n    ORDER BY id\n    LIMIT ${size}\n  `\n  const result = await Database.one_query_on_main(query)\n  return result.rows.map((r) => r.id)\n}\n\nexport async function photoBatchForAll(size: number, previous_id: string, extra_where = '') {\n  const query = `\n    SELECT id, url FROM photo\n      WHERE id > '${previous_id}'\n      ${extra_where}\n    ORDER BY id\n    LIMIT ${size}\n  `\n  const result = await Database.one_query_on_main(query)\n  return result.rows\n}\n\nexport async function getTableCount(table: string, where = ''): Promise<number> {\n  const query = `SELECT count(id) FROM ${table} ${where}`\n  const result = await Database.one_query_on_main(query)\n  return parseInt(result.rows[0].count)\n}\n\nexport function isUUID(uuid: string) {\n  const regex = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-5][0-9a-f]{3}-[089ab][0-9a-f]{3}-[0-9a-f]{12}$/i\n  return uuid.match(regex)\n}\n\n// One-off behaviour when moving to using Google's geocoder IDs.\n// `geocoder_id` is unique, so just prefer the existing one and delete\n// the newly geocoded one.\n//\n// ALERT! Depends on a previous query where restaurants are queried\n// for having a geocoder_id of NULL\nexport async function restaurantDeleteOrUpdateByGeocoderID(\n  restaurant_id: string,\n  geocoder_id: string\n) {\n  if (!isUUID(restaurant_id) || !isGoogleGeocoderID(geocoder_id)) {\n    throw new Error('GOOGLE GEOCODER BATCH: Bad identifier')\n  }\n  const query = `\n  DO\n  $do$\n  BEGIN\n    IF EXISTS (\n      SELECT FROM restaurant\n        WHERE geocoder_id = '${geocoder_id}'\n        AND id != '${restaurant_id}'\n    ) THEN\n      DELETE FROM restaurant WHERE id = '${restaurant_id}';\n    ELSE\n      UPDATE restaurant SET geocoder_id = '${geocoder_id}'\n        WHERE id = '${restaurant_id}';\n    END IF;\n  END\n  $do$\n  `\n  await Database.one_query_on_main(query)\n}\n\nexport async function restaurantFindOneWithTagsSQL(restaurant_id: string) {\n  const query = `\n    SELECT json_agg(s) FROM (\n      SELECT\n        *,\n        st_asgeojson(location) AS location,\n        (\n          SELECT array_agg(rtags_subquery) FROM (\n            SELECT\n              *,\n              (\n                SELECT (json_agg(ts))->0 FROM (\n                  SELECT * FROM tag\n                  WHERE tag.id = restaurant_tag.tag_id\n                ) ts\n              ) as tag\n            FROM restaurant_tag\n            WHERE restaurant_tag.restaurant_id = restaurant.id\n          ) rtags_subquery\n        ) AS tags\n      FROM restaurant\n      WHERE restaurant.id = '${restaurant_id}'\n    ) s\n  `\n  const response = await Database.one_query_on_main(query)\n  const restaurant = response.rows[0].json_agg[0]\n  if (!restaurant.tags) {\n    restaurant.tags = []\n  }\n  restaurant.location = JSON.parse(restaurant.location)\n  return restaurant\n}\n\nexport function roughSizeOfObject(object) {\n  var objectList: any[] = []\n  var stack = [object]\n  var bytes = 0\n\n  while (stack.length) {\n    var value = stack.pop()\n\n    if (typeof value === 'boolean') {\n      bytes += 4\n    } else if (typeof value === 'string') {\n      bytes += value.length * 2\n    } else if (typeof value === 'number') {\n      bytes += 8\n    } else if (typeof value === 'object' && objectList.indexOf(value) === -1) {\n      objectList.push(value)\n\n      for (var i in value) {\n        stack.push(value[i])\n      }\n    }\n  }\n  return bytes\n}\n\nexport function decodeEntities(encodedString) {\n  var translate_re = /&(nbsp|amp|quot|lt|gt);/g\n  var translate = {\n    nbsp: ' ',\n    amp: '&',\n    quot: '\"',\n    lt: '<',\n    gt: '>',\n  }\n  return encodedString\n    .replace(translate_re, function (match, entity) {\n      return translate[entity]\n    })\n    .replace(/&#(\\d+);/gi, function (match, numStr) {\n      var num = parseInt(numStr, 10)\n      return String.fromCharCode(num)\n    })\n}\n\nexport async function curl_cli(url: string, args: string = '') {\n  const command = `curl '${url}' ${args}`\n  if (DISH_DEBUG >= 3) {\n    console.log(command)\n  }\n  const { stdout, stderr } = await exec(command, { maxBuffer: 1024 * 3000 })\n  return stdout\n}\n\n// I use this just for catching unexpected things in a loop. For instance I want to double\n// check some data in a long running task before letting the loop continue\nexport async function keypress() {\n  process.stdin.setRawMode(true)\n  return new Promise<void>((resolve) =>\n    process.stdin.once('data', () => {\n      process.stdin.setRawMode(false)\n      resolve()\n    })\n  )\n}\n", "import '@dish/common'\n\nimport { WorkerJob } from '@dish/worker'\nimport axios_base from 'axios'\nimport { JobOptions, QueueOptions } from 'bull'\nimport { shuffle } from 'lodash'\n\nimport { restaurantSaveCanonical } from '../canonical-restaurant'\nimport { ScrapeData, scrapeInsert } from '../scrape-helpers'\nimport { aroundCoords, geocode } from '../utils'\n\nconst GRUBHUB_DOMAIN = process.env.GRUBHUB_AWS_PROXY || 'https://api-gtm.grubhub.com/'\n\nconst axios = axios_base.create({\n  baseURL: GRUBHUB_DOMAIN,\n  headers: {\n    common: {\n      'Content-Type': 'application/json',\n    },\n  },\n})\n\nexport class GrubHub extends WorkerJob {\n  auth_token: string = ''\n  // I assume the reasoning for the map view size for a delivery service is,\n  // what is the minimum radius that a restaurant will deliver to?\n  public MAPVIEW_SIZE = 2000\n  public SEARCH_RADIUS_MULTIPLIER = 5\n\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 5,\n      duration: 300,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  async allForCity(city_name: string) {\n    console.log('Starting GrubHub crawler. Using domain: ' + GRUBHUB_DOMAIN)\n    let all: string[] = []\n    const coords = await geocode(city_name)\n    const region_coords = shuffle(\n      aroundCoords(coords[0], coords[1], this.MAPVIEW_SIZE, this.SEARCH_RADIUS_MULTIPLIER)\n    )\n    for (const coords of region_coords) {\n      const restaurants = await this.search(coords[0], coords[1])\n      const ids = restaurants.map((r) => r.restaurant_id)\n      all = [...all, ...ids]\n    }\n    console.log(`GRUBHUB: Found ${all.length} restaurants`)\n    for (const id of all) {\n      await this.runOnWorker('getRestaurant', [id])\n    }\n  }\n\n  async getAuthToken() {\n    const response = await axios.post('auth', {\n      brand: 'GRUBHUB',\n      client_id: 'beta_UmWlpstzQSFmocLy3h1UieYcVST',\n      scope: 'anonymous',\n    })\n    this.auth_token = response.data.session_handle.access_token\n  }\n\n  async apiRequest(path: string) {\n    if (!this.auth_token ?? this.auth_token == '') {\n      await this.getAuthToken()\n    }\n    const response = await axios.get(path, {\n      headers: {\n        Authorization: 'Bearer ' + this.auth_token,\n      },\n    })\n    return response.data\n  }\n\n  async search(lat: number, lng: number) {\n    let page = 1\n    let results: any[] = []\n    let all: any[] = []\n    while (page == 1 || results.length > 0) {\n      console.log(`DOORDASH: searching at ${lng}, ${lat}`)\n      let path = this._getSearchPath(lat, lng, page)\n      const response = await this.apiRequest(path)\n      const results = response.search_result.results\n      all = [...all, ...results]\n      page += 1\n    }\n    return all\n  }\n\n  async getRestaurant(id: string) {\n    const path = this._getRestaurantPath(id)\n    const response = await this.apiRequest(path)\n    const data = response.restaurant\n    const id_from_source = data.id\n    const lng = parseFloat(data.longitude)\n    const lat = parseFloat(data.latitude)\n    const restaurant_id = await restaurantSaveCanonical(\n      'grubhub',\n      id_from_source,\n      lng,\n      lat,\n      data.name,\n      data.address.street_address\n    )\n    await scrapeInsert({\n      source: 'grubhub',\n      restaurant_id,\n      id_from_source,\n      location: {\n        lon: lng,\n        lat: lat,\n      },\n      data: {\n        main: data,\n        reviews: await this.getReviews(data.id),\n      },\n    })\n    return data\n  }\n\n  static getNameAndAddress(scrape: ScrapeData) {\n    return {\n      name: scrape.data.main.name,\n      address: scrape.data.main.address.street_address,\n    }\n  }\n\n  async getReviews(id: string) {\n    let page = 1\n    let reviews: any[] = []\n    let all: any[] = []\n    while (page == 1 || reviews.length > 0) {\n      const path = this._getReviewsPath(id)\n      const response = await this.apiRequest(path)\n      const reviews = response.reviews.review\n      all = [...all, ...reviews]\n      page += 1\n    }\n    return all\n  }\n\n  _getRestaurantPath(id: string) {\n    return (\n      `restaurants/${id}?` +\n      `hideChoiceCategories=true&version=4&variationId=rtpFreeItems&orderType=standard` +\n      `&hideUnavailableMenuItems=true&hideMenuItems=false&includePromos=false` +\n      `&locationMode=delivery`\n    )\n  }\n\n  _getSearchPath(lat: number, lng: number, page: number = 1) {\n    return (\n      `restaurants/search?` +\n      `orderMethod=delivery&locationMode=DELIVERY` +\n      `&facetSet=umamiV2&pageSize=100&hideHateos=true&searchMetrics=true` +\n      `&location=POINT(${lng}%20${lat})` +\n      `&preciseLocation=true&geohash=9q8yy1z6xg4q` +\n      `&includeOffers=true&sortSetId=umamiv3&sponsoredSize=3` +\n      `&countOmittingTimes=true&pageNum=${page}`\n    )\n  }\n\n  _getReviewsPath(id: string, page: number = 1) {\n    const page_size = 100\n    return (\n      `ratings/search/restaurant/${id}` +\n      `?pageSize=${page_size}&pageNum=${page}&brand=GRUBHUB&` +\n      `facet=order_type%3Astandard&timeCreated_desc`\n    )\n  }\n}\n", "import '@dish/common'\n\nimport { WorkerJob } from '@dish/worker'\nimport axios_base from 'axios'\nimport { JobOptions, QueueOptions } from 'bull'\nimport _ from 'lodash'\n\nimport { restaurantSaveCanonical } from '../canonical-restaurant'\nimport { ScrapeData, scrapeInsert } from '../scrape-helpers'\nimport { aroundCoords, geocode } from '../utils'\n\nconst INFATUATION_DOMAIN = process.env.INFATUATION_PROXY || 'https://www.theinfatuation.com'\n\nconst axios = axios_base.create({\n  baseURL: INFATUATION_DOMAIN,\n  headers: {\n    common: {\n      'X-My-X-Forwarded-For': 'www.theinfatuation.com',\n    },\n  },\n})\n\nconst MAPVIEW_SIZE = 5000\n\nexport class Infatuation extends WorkerJob {\n  public longest_radius: number\n\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 5,\n      duration: 1000,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  constructor() {\n    super()\n    this.longest_radius = (MAPVIEW_SIZE * Math.sqrt(2)) / 2\n  }\n\n  async allForCity(city_name: string) {\n    console.log('Starting The Infatuation crawler. Using domain: ' + INFATUATION_DOMAIN)\n    const coords = await geocode(city_name)\n    const region_coords = _.shuffle(aroundCoords(coords[0], coords[1], MAPVIEW_SIZE, 5))\n    for (const box_center of region_coords) {\n      await this.runOnWorker('getRestaurants', [{ center: box_center }])\n    }\n  }\n\n  async getRestaurants({\n    start = 0,\n    center,\n    returnResults,\n  }: {\n    center: [number, number]\n    start?: number\n    returnResults?: boolean\n  }) {\n    const per_page = 40\n    const limit = 40\n    const path = '/api/v1/venues/search?'\n    const city = 'city=Boston' // Doesn't seem to do anything, but is still required\n    const latlon = `lat=${center[0]}&lng=${center[1]}`\n    const distance = `view_distance=${this.longest_radius}`\n    const pagination = `offset=${start}&limit=${limit}`\n    const base = 'sort_order=Highest%20Rated&category%5B%5D=RESTAURANT'\n    const query = [latlon, distance, pagination, base, city].join('&')\n    console.log('infatuation search GET', INFATUATION_DOMAIN + path + query)\n    const response = await axios.get(path + query)\n    const restaurants = response.data.data\n    if (returnResults) {\n      return restaurants\n    }\n    for (const restaurant of restaurants) {\n      await this.saveDataFromMapSearch(restaurant)\n    }\n    if (restaurants.length > 0) {\n      await this.runOnWorker('getRestaurants', [{ center, start: start + per_page }])\n    }\n  }\n\n  async saveDataFromMapSearch(data: ScrapeData) {\n    console.info('Infatuation: saving ' + data.name)\n    const id_from_source = data.id.toString()\n    const lon = data.geo_point.coordinates[0]\n    const lat = data.geo_point.coordinates[1]\n    const restaurant_id = await restaurantSaveCanonical(\n      'infatuation',\n      id_from_source,\n      lon,\n      lat,\n      data.name,\n      data.street\n    )\n    if (process.env.DEBUG) {\n      console.log('Infatuation data', data)\n    }\n    const id = await scrapeInsert({\n      source: 'infatuation',\n      restaurant_id,\n      id_from_source,\n      location: {\n        lon: lon,\n        lat: lat,\n      },\n      data: {\n        data_from_search_list_item: data,\n      },\n    })\n    return id\n  }\n\n  static getNameAndAddress(scrape: ScrapeData) {\n    return {\n      name: scrape.data.data_from_search_list_item.name,\n      address: scrape.data.data_from_search_list_item.street,\n    }\n  }\n}\n", "import '@dish/common'\n\nimport { sentryException } from '@dish/common'\nimport { WorkerJob } from '@dish/worker'\nimport axios_base from 'axios'\nimport { JobOptions, QueueOptions } from 'bull'\n\nimport { restaurantSaveCanonical } from '../canonical-restaurant'\nimport { ScrapeData, scrapeInsert } from '../scrape-helpers'\n\nconst MICHELIN_DOMAIN = process.env.MICHELIN_PROXY || 'https://8nvhrd7onv-dsn.algolia.net'\n\nconst axios = axios_base.create({\n  baseURL: MICHELIN_DOMAIN,\n  headers: {\n    common: {\n      'X-My-X-Forwarded-For': '8nvhrd7onv-dsn.algolia.net',\n    },\n  },\n})\n\nexport class Michelin extends WorkerJob {\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 5,\n      duration: 1000,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  constructor() {\n    super()\n    console.log('Starting Michelin crawler. Using domain: ' + MICHELIN_DOMAIN)\n  }\n\n  async all(page: number = 0, limit = Infinity, find?: string) {\n    const [uri, data] = this.buildRequest(page)\n    const response = await axios.post(uri as string, data)\n    const restaurants = response.data.results[0].hits as any[]\n    for (const [index, restaurant] of restaurants.entries()) {\n      if (index >= limit) {\n        break\n      }\n      try {\n        const { name } = await this.saveRestaurant(restaurant)\n        if (find && name === find) {\n          break\n        }\n      } catch (e) {\n        console.log('error crawling', e)\n        sentryException(e, {\n          data: [restaurant],\n          logger: this.log,\n        })\n      }\n    }\n    this.log('got', restaurants.length)\n    if (restaurants.length > 0 && process.env.NODE_ENV != 'test') {\n      await this.runOnWorker('all', [page + 1])\n    }\n  }\n\n  buildRequest(page: number) {\n    const algolia =\n      '/1/indexes/*/queries?x-algolia-agent=Algolia%20for%20JavaScript%20(3.35.1)' +\n      '%3B%20Browser%20(lite)%3B%20instantsearch.js%20(4.1.1)%3B%20JS%20Helper%20' +\n      '(3.0.0)&x-algolia-application-id=8NVHRD7ONV&x-algolia-api-key=' +\n      '71b3cff102a474b924dfcb9897cc6fa8'\n    const data = {\n      requests: [\n        {\n          indexName: 'prod-restaurants-en',\n          params:\n            `aroundLatLngViaIP=true&aroundRadius=all&filters=` +\n            `status%3APublished&hitsPerPage=40` +\n            `&attributesToRetrieve=%5B%22_geoloc%22%2C%22city_name%22%2C%22country_name` +\n            `%22%2C%22cuisine_type%22%2C%22guide_year%22%2C%22image%22%2C%22` +\n            `michelin_award%22%2C%22name%22%2C%22offers%22%2C%22offers_size` +\n            `%22%2C%22online_booking%22%2C%22other_urls%22%2C%22site_name%22%2C%22` +\n            `url%22%5D&maxValuesPerFacet=100&page=${page}&facets=%5B%22country_code%22%2C%22` +\n            `region_slug%22%2C%22city_slug%22%2C%22area_slug%22%2C%22michelin_award` +\n            `%22%2C%22offers%22%2C%22cuisine_slug%22%2C%22online_booking%22%2C%22` +\n            `rating%22%2C%22service_restriction%22%2C%22categories.lvl0%22%5D&tagFilters=`,\n        },\n      ],\n    }\n    return [MICHELIN_DOMAIN + algolia, data]\n  }\n\n  async saveRestaurant(data: ScrapeData) {\n    if (process.env.RUN_WITHOUT_WORKER != 'true') {\n      console.info('Michelin: saving ' + data.name)\n    }\n    const id_from_source = data.objectID\n    const lon = data._geoloc.lng\n    const lat = data._geoloc.lat\n\n    const restaurant_id = await restaurantSaveCanonical(\n      'michelin',\n      id_from_source,\n      lon,\n      lat,\n      data.name,\n      data._highlightResult.street.value\n    )\n    this.log('crawling ' + data.name + ' ' + id_from_source)\n    const id = await scrapeInsert({\n      source: 'michelin',\n      restaurant_id,\n      id_from_source,\n      location: {\n        lon: lon,\n        lat: lat,\n      },\n      data: {\n        main: data,\n      },\n    })\n\n    return { id, name: data.name }\n  }\n\n  static getNameAndAddress(scrape: ScrapeData) {\n    return {\n      name: scrape.data.main.name,\n      address: scrape.data.main._highlightResult.street.value,\n    }\n  }\n}\n", "import '@dish/common'\n\nimport { sleep } from '@dish/async'\nimport { sentryException } from '@dish/common'\nimport { restaurantFindOne, restaurantUpdate } from '@dish/graph'\nimport { ProxiedRequests, WorkerJob } from '@dish/worker'\nimport * as acorn from 'acorn'\nimport axios from 'axios'\nimport { JobOptions, QueueOptions } from 'bull'\nimport * as cheerio from 'cheerio'\nimport _ from 'lodash'\n\nimport { restaurantSaveCanonical } from '../canonical-restaurant'\nimport { DISH_DEBUG } from '../constants'\nimport { GoogleGeocoder } from '../google/GoogleGeocoder'\nimport { ScrapeData, scrapeInsert, scrapeMergeData } from '../scrape-helpers'\nimport { aroundCoords, curl_cli, decodeEntities, geocode } from '../utils'\n\nconst TRIPADVISOR_OG_DOMAIN = 'https://www.tripadvisor.com'\nconst TRIPADVISOR_AWS_DOMAIN = process.env.TRIPADVISOR_PROXY || ''\nconst AXIOS_HEADERS = {\n  'X-My-X-Forwarded-For': TRIPADVISOR_OG_DOMAIN,\n  'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:91.0) Gecko/20100101 Firefox/92.0',\n  'Accept-Language': 'en-GB,en;q=0.5',\n  'accept-encoding': 'deflate, gzip, zstd',\n}\n\nconst tripadvisorAPI = new ProxiedRequests(\n  TRIPADVISOR_OG_DOMAIN,\n  process.env.TRIPADVISOR_PROXY || '',\n  { timeout: null }\n)\n\nexport class Tripadvisor extends WorkerJob {\n  public scrape_id!: string\n  public MAPVIEW_SIZE = 1000\n  public SEARCH_RADIUS_MULTIPLIER = 10\n  public _TESTS__LIMIT_GEO_SEARCH = false\n  public detail_id!: string\n  public restaurant_name!: string\n\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 5,\n      duration: 1000,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  async allForCity(city_name: string) {\n    console.log('Starting Tripadvisor crawler. Using domain: ' + TRIPADVISOR_AWS_DOMAIN)\n    const coords = await geocode(city_name)\n    const region_coords = _.shuffle(\n      aroundCoords(coords[0], coords[1], this.MAPVIEW_SIZE, this.SEARCH_RADIUS_MULTIPLIER)\n    )\n    for (const coords of region_coords) {\n      await this.runOnWorker('getRestaurants', [coords[0], coords[1], 0])\n    }\n  }\n\n  async getRestaurants(lat: number, lon: number) {\n    const base =\n      '/GMapsLocationController?' +\n      'Action=update&from=Restaurants&g=1&mapProviderFeature=ta-maps-gmaps3&validDates=false' +\n      '&pinSel=v2&finalRequest=false&includeMeta=false&trackPageView=false'\n    const dimensions = `&mz=17&mw=${this.MAPVIEW_SIZE}&mh=${this.MAPVIEW_SIZE}`\n    const coords = `&mc=${lat},${lon}`\n    const uri = TRIPADVISOR_AWS_DOMAIN + base + dimensions + coords\n    const response = await axios.get(uri, { headers: AXIOS_HEADERS })\n\n    for (const data of response.data.restaurants) {\n      await this.runOnWorker('getRestaurant', [data.url])\n      if (this._TESTS__LIMIT_GEO_SEARCH) break\n    }\n  }\n\n  async getRestaurant(path: string) {\n    this.detail_id = this.extractDetailID(path)\n    const response = await tripadvisorAPI.get(path)\n    const html = await response.text()\n    let data = this._extractEmbeddedJSONData(html)\n    const scrape_id = await this.saveRestaurant(data)\n    if (!scrape_id) throw new Error(\"Tripadvisor crawler couldn't save restaurant\")\n    await this.savePhotos(scrape_id)\n    await this.saveReviews(path, scrape_id, 0, html)\n    this.log(`\"${this.restaurant_name}\" scrape complete`)\n  }\n\n  async saveRestaurant(data: ScrapeData) {\n    const overview = this._getOverview(data)\n    const menu = this._getMenu(data)\n    if (process.env.RUN_WITHOUT_WORKER != 'true') {\n      console.info('Tripadvisor: saving ' + overview.name)\n    }\n    const id_from_source = overview.detailId.toString()\n    const lon = overview.location.longitude\n    const lat = overview.location.latitude\n    const restaurant_name = Tripadvisor.cleanName(overview.name)\n    this.restaurant_name = restaurant_name\n    const restaurant_id = await restaurantSaveCanonical(\n      'tripadvisor',\n      id_from_source,\n      lon,\n      lat,\n      restaurant_name,\n      overview.contact.address\n    )\n    if (process.env.RUN_WITHOUT_WORKER == 'true') {\n      console.log('TRIPADVISOR: found canonical restaurant ID: ' + restaurant_id)\n    }\n    const id = await scrapeInsert({\n      source: 'tripadvisor',\n      restaurant_id,\n      id_from_source,\n      location: {\n        lon: lon,\n        lat: lat,\n      },\n      data: {\n        overview: overview,\n        menu: menu,\n      },\n    })\n    return id\n  }\n\n  static getNameAndAddress(scrape: ScrapeData) {\n    return {\n      name: Tripadvisor.cleanName(scrape.data.overview.name),\n      address: scrape.data.overview.contact.address,\n    }\n  }\n\n  async saveReviews(path: string, scrape_id: string, page: number, html: string = '') {\n    const response = await tripadvisorAPI.get(path)\n    html = await response.text()\n    const more = await this._persistReviewData(html, scrape_id, page, path)\n    if (more) {\n      page++\n      if (page == 1) {\n        path = path.replace('-Reviews-', `-Reviews-or${page * 10}-`)\n      } else {\n        path = path.replace(/-Reviews-or[0-9]*0-/, `-Reviews-or${page * 10}-`)\n      }\n      await this.runOnWorker('saveReviews', [path, scrape_id, page])\n    }\n  }\n\n  // I wrote this when it seemed Tripadvisor had fully detected and blocked our AWS proxy.\n  // But now it seems AWS works again, so leaving this here in case AWS gets blocked again.\n  // But then you'll definitely want to look into adding cookies to improve the success rate.\n  async curl_cli_retries(path: string, args: string = '') {\n    let html = ''\n    let tries = 0\n    const max_tries = 1000\n    const PROXY =\n      process.env.LUMINATI_PROXY_RESIDENTIAL_USER +\n      ':' +\n      process.env.LUMINATI_PROXY_RESIDENTIAL_PASSWORD +\n      '@' +\n      process.env.LUMINATI_PROXY_HOST +\n      ':' +\n      process.env.LUMINATI_PROXY_PORT\n    while (tries < max_tries) {\n      try {\n        html = await curl_cli(\n          TRIPADVISOR_OG_DOMAIN + path,\n          args + ' ' + ['--max-time 5', `--proxy 'https://${PROXY}'`].join(' ')\n        )\n      } catch (error: any) {\n        if (!error.message.includes('timed out')) {\n          throw new Error(error)\n        }\n      }\n      // TODO find a better a way of detecting success than counting chars!\n      if (html.length > 2000) {\n        return html\n      } else {\n        console.log(html)\n        this.log('HTML less than 2000 chars, retrying: ' + path)\n      }\n      tries += 1\n    }\n    throw new Error(`Couldn't get ${path} in ${max_tries}`)\n  }\n\n  async savePhotos(scrape_id: string) {\n    let page = 0\n    let photos: any[] = []\n    while (true) {\n      // TODO run on worker\n      const result = await this.parsePhotoPage(page)\n      if (!result) break\n      const batch = result\n      photos = [...photos, ...batch]\n      page++\n    }\n    const uris = photos.map((p) => p.url)\n    await scrapeMergeData(scrape_id, {\n      photos: uris, // field is kept for backwards compat\n      photos_with_captions: photos,\n    })\n  }\n\n  async parsePhotoPage(page = 0) {\n    if (DISH_DEBUG >= 2) {\n      this.log(`Fetching photo page ${page}`)\n    }\n    const path = this.buildGalleryURL(page)\n    const response = await axios.get(TRIPADVISOR_AWS_DOMAIN + path, {\n      headers: Object.assign(AXIOS_HEADERS, { 'X-Requested-With': 'XMLHttpRequest' }),\n    })\n    const html = response.data\n    const $ = cheerio.load(html)\n    const photos = $('.tinyThumb')\n    let parsed: any[] = []\n    const no_more_photos_sig = 'Oh, snap! We don&#39;t have any photos for'\n    if (html.includes(no_more_photos_sig)) {\n      return false\n    }\n    for (let i = 0; i < photos.length; i++) {\n      const photo = $(photos[i])\n      const url = $(photo).attr('data-bigurl')\n      let caption = $(photo).attr('data-captiontext')\n      if (caption) {\n        caption = decodeEntities(caption)\n      }\n      parsed.push({\n        url,\n        caption,\n      })\n    }\n    return parsed\n  }\n\n  buildGalleryURL(page = 0) {\n    let path = '/DynamicPlacementAjax?'\n    const offset = page * 50\n    const params = [\n      'detail=' + this.detail_id,\n      'albumViewMode=hero',\n      'placementRollUps=responsive-photo-viewer',\n      'metaReferer=Restaurant_Review',\n      'offset=' + offset,\n    ].join('&')\n    return path + params\n  }\n\n  extractDetailID(path: string) {\n    const re = new RegExp(/-d([0-9]*)-/)\n    let matches = re.exec(path)\n    if (!matches) throw \"Couldn't parse detail_id from Tripadvisor URL\"\n    const detail_id = matches[1]\n    return detail_id\n  }\n\n  static cleanName(name: string) {\n    let restaurant_name_parts = name.split(', ')\n    restaurant_name_parts.pop()\n    return restaurant_name_parts.join(', ')\n  }\n\n  private async _persistReviewData(html: string, scrape_id: string, page: number, path: string) {\n    if (process.env.DISH_ENV != 'production' && page > 2) {\n      this.log('stopping reviews early in non-production')\n      return false\n    }\n    const { more, data: review_data } = await this._extractReviews(html, path)\n    if (!review_data) return false\n    let scrape_data: ScrapeData = {}\n    scrape_data['reviewsp' + page] = review_data\n    await scrapeMergeData(scrape_id, scrape_data)\n    return more\n  }\n\n  private async _extractReviews(html: string, path: string) {\n    const full = await this.getFullReviews(html, path)\n    if (!full.data) {\n      return full\n    }\n    const updated_html = full.data\n    const $ = cheerio.load(updated_html)\n    const reviews = $('.reviewSelector')\n    let data: ScrapeData[] = []\n    for (let i = 0; i < reviews.length; i++) {\n      const review = $(reviews[i])\n      data.push({\n        // TODO: Get actual internal username\n        username: review.find('.memberInfoColumn .info_text').text(),\n        rating: this._getRatingFromClasses(review),\n        quote: review.find('.quote .noQuotes').text(),\n        text: review.find('.partial_entry').text(),\n        date: review.find('.ratingDate').attr('title'),\n      })\n    }\n    return { more: full.more, data: data }\n  }\n\n  private async getFullReviews(html: string, referer_path: string) {\n    let ids: string[] = []\n    const $ = cheerio.load(html)\n    const reviews = $('#REVIEWS .listContainer .review-container')\n    let more = false\n    for (let i = 0; i < reviews.length; i++) {\n      const review = $(reviews[i])\n      const id = review.find('.reviewSelector').attr('data-reviewid')\n      if (!id) continue\n      ids.push(id)\n    }\n    if (ids.length == 0) {\n      return { more: false, data: null }\n    }\n    const path = '/OverlayWidgetAjax?Mode=EXPANDED_HOTEL_REVIEWS_RESP&metaReferer='\n    const updated_html = await this.curlFullReviews(path, referer_path, ids)\n    // const updated_html = await this.playrightFullReviews(path, referer_path, ids)\n    try {\n      if (!$('.ui_pagination > a.next')!.attr('class')!.includes('disabled')) {\n        more = true\n      }\n    } catch (error: any) {\n      // TODO it seems this is only triggered when there are 0 reviews\n      sentryException(error)\n    }\n    return { more, data: updated_html }\n  }\n\n  private async curlFullReviews(path: string, referer_path: string, ids: string[]) {\n    const args = [\n      \"-H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/91.0'\",\n      \"-H 'Accept-Language: en-GB,en;q=0.5'\",\n      \"-H 'X-Requested-With: XMLHttpRequest'\",\n      '--compressed',\n      `-H 'Referer: ${TRIPADVISOR_OG_DOMAIN}${referer_path}'`,\n      `--data-raw 'reviews=${ids.join(',')}'`,\n    ].join(' ')\n    const html = await curl_cli(TRIPADVISOR_AWS_DOMAIN + path, args)\n    return html\n  }\n\n  // For some reason this can only resturn empty responses??\n  private async playrightFullReviews(url: string, referer_path: string, ids: string[]) {\n    const options = {\n      method: 'POST',\n      body: `reviews=${ids.join('%2C')}`,\n      timeout: null,\n      headers: {\n        ...AXIOS_HEADERS,\n        'X-Requested-With': 'XMLHttpRequest',\n        Referer: TRIPADVISOR_OG_DOMAIN + referer_path,\n      },\n    }\n    const response = await tripadvisorAPI.get(url, options)\n    const html = await response.text()\n    return html\n  }\n\n  private _getRatingFromClasses(review: any) {\n    let rating: number | null = null\n    const classes = review.find('.ui_bubble_rating').attr('class')!.split(' ')\n\n    for (let i = 0; i < classes.length; i++) {\n      const classname = classes[i]\n      if (classname.startsWith('bubble_')) {\n        rating = parseInt(classname.split('_')[1]) / 10\n      }\n    }\n    return rating\n  }\n\n  private _getOverview(data: ScrapeData) {\n    const source_id = data.redux?.page?.detailId\n    const main = data['redux']['api']['responses']\n    const overview = main[`/data/1.0/restaurant/${source_id}/overview`]['data']\n    return overview\n  }\n\n  private _getMenu(data: ScrapeData) {\n    let menu: ScrapeData = {}\n    const key = 'Menus_getMenuResponse'\n    for (const id in data['urqlCache']) {\n      const section = data['urqlCache'][id]\n      if (section['data']?.hasOwnProperty(key)) {\n        menu = section['data'][key]\n      }\n    }\n    return menu\n  }\n\n  private _extractEmbeddedJSONData(html: string) {\n    const signature = '/data/1.0/restaurants'\n    let the_data_line = ''\n    for (const line of html.split('\\n')) {\n      if (line.includes(signature)) {\n        the_data_line = line\n        break\n      }\n    }\n    if (the_data_line != '') {\n      const $ = cheerio.load(the_data_line)\n      const script = $('script').html()\n      const ast = acorn.parse(script!)\n      const value = ast['body'][0].expression.right.properties[0].value\n      const json = script!.substring(value.start, value.end)\n      return JSON.parse(json)\n    } else {\n      return {}\n    }\n  }\n}\n\nexport async function tripadvisorGetFBC() {\n  console.log('Getting Fresh Brew Coffee from Tripadvisor...')\n  const tripadvisor_fbc =\n    'Restaurant_Review-g60713-d3652374-Reviews-Fresh_Brew_Coffee-San_Francisco_California.html'\n  const t = new Tripadvisor()\n  await t.getRestaurant(tripadvisor_fbc)\n  const restaurant = await restaurantFindOne({ name: 'Fresh Brew Coffee' })\n  if (!restaurant) throw new Error('No restaurant after hot fetching Fresh Brew Coffee')\n  const geocoder = new GoogleGeocoder()\n  const query = restaurant.name + ',' + restaurant.address\n  const lon = restaurant.location.coordinates[0]\n  const lat = restaurant.location.coordinates[1]\n  restaurant.geocoder_id = await geocoder.searchForID(query, lat, lon)\n  await restaurantUpdate(restaurant)\n  console.log('...got Fresh Brew Coffee from Tripadvisor.')\n  return restaurant\n}\n", "import '@dish/common'\n\nimport { WorkerJob } from '@dish/worker'\nimport axios_base, { AxiosResponse } from 'axios'\nimport { JobOptions, QueueOptions } from 'bull'\nimport _ from 'lodash'\n\nimport { restaurantSaveCanonical } from '../canonical-restaurant'\nimport { ScrapeData, scrapeInsert, scrapeMergeData } from '../scrape-helpers'\nimport { aroundCoords, geocode } from '../utils'\nimport categories from './categories'\n\nconst UBEREATS_DOMAIN = process.env.UBEREATS_PROXY || 'https://www.ubereats.com/'\nconst LOCALE = '?localeCode=en-US'\nconst CITIES = 'getCountriesWithCitiesV1'\nconst FEED = 'getFeedV1'\nconst STORE = 'getStoreV1'\nconst PER_PAGE = 80\n\nconst axios = axios_base.create({\n  baseURL: UBEREATS_DOMAIN + 'api/',\n  headers: {\n    common: {\n      'x-csrf-token': 'x',\n    },\n  },\n})\n\nexport class UberEats extends WorkerJob {\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 5,\n      duration: 500,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  static DELIVERY_RADIUS = 30000\n\n  get logName() {\n    return `UberEats`\n  }\n\n  async world() {\n    this.log('Starting crawler. Using domain: ' + UBEREATS_DOMAIN)\n    const response = await axios.post(CITIES, {})\n    const countries = _.shuffle(response.data.data.countryLinks.links)\n    for (let country of countries) {\n      const country_name = country.href.split('/')[1]\n      const locale = '?localeCode=' + country_name\n      const response = await axios.post(CITIES + locale, {})\n      const cities = _.shuffle(response.data.data.cityLinks.links)\n      for (let city of cities) {\n        await this.runOnWorker('getCity', [`${city.title}, ${country.title}`])\n      }\n    }\n  }\n\n  async getCity(city: string) {\n    this.log('Getting city: ' + city)\n    const coords = await geocode(city)\n    await this.runOnWorker('aroundCoords', [coords[0], coords[1]])\n  }\n\n  async aroundCoords(lat: number, lon: number) {\n    const delivery_radius_multiplier = 2\n    const coords_set = aroundCoords(lat, lon, UberEats.DELIVERY_RADIUS, delivery_radius_multiplier)\n    for (let coords of coords_set) {\n      await this.runOnWorker('getFeedPage', [0, '', coords[0], coords[1]])\n    }\n  }\n\n  async getFeedPage(offset: number, category: string, lat: number, lon: number) {\n    this.log(`Getting feed for coords: ${lat}, ${lon}, category: '${category}', offset: ${offset}`)\n    const response = await axios.post(\n      FEED + LOCALE,\n      {\n        pageInfo: {\n          offset: offset,\n          pageSize: PER_PAGE,\n        },\n        userQuery: category,\n      },\n      {\n        headers: {\n          Cookie: 'uev2.loc=' + this.encodeLocation(lat, lon),\n        },\n      }\n    )\n\n    await this.extractRestaurantsFromFeed(response, offset, category)\n\n    if (response.data.data.meta.hasMore) {\n      await this.runOnWorker('getFeedPage', [response.data.data.meta.offset, category, lat, lon])\n    }\n  }\n\n  async extractRestaurantsFromFeed(response: AxiosResponse, offset: number, category: string) {\n    const items = response.data.data.feedItems\n    this.log(\n      items.length + ' restaurants on page: ' + offset / 80 + ', for category: \"' + category + '\"'\n    )\n\n    for (let item of items) {\n      if (item.type == 'STORE') {\n        await this.runOnWorker('getRestaurant', [item.uuid])\n      }\n    }\n  }\n\n  async getRestaurant(uuid: string) {\n    const response = await axios.post(\n      STORE,\n      { storeUuid: uuid },\n      {\n        headers: {\n          'Content-Type': 'application/json',\n        },\n      }\n    )\n    const data = response.data.data\n    const scrape_id = await this.saveRestaurant(data, uuid)\n    if (scrape_id) {\n      await this.getDishes(data, scrape_id)\n    }\n  }\n\n  private async saveRestaurant(data: any, uuid: string) {\n    this.log('Saving restaurant: ' + data.title)\n    const restaurant_id = await restaurantSaveCanonical(\n      'ubereats',\n      uuid,\n      data.location.longitude,\n      data.location.latitude,\n      data.title,\n      data.location.streetAddress\n    )\n    const scrape = await this.saveScrape(uuid, data, restaurant_id)\n    return scrape\n  }\n\n  static getNameAndAddress(scrape: ScrapeData) {\n    return {\n      name: scrape.data.main.title,\n      address: scrape.data.main.location.streetAddress,\n    }\n  }\n\n  private async saveScrape(uuid: string, data: any, canonical_id: string) {\n    const id = await scrapeInsert({\n      source: 'ubereats',\n      id_from_source: uuid,\n      data: {\n        main: data,\n      },\n      location: {\n        lon: data.location.longitude,\n        lat: data.location.latitude,\n      },\n      restaurant_id: canonical_id,\n    })\n    return id\n  }\n\n  private async getDishes(data: any, scrape_id: string) {\n    let dishes = [{}]\n    for (const sid in data.sectionEntitiesMap) {\n      for (const did in data.sectionEntitiesMap[sid]) {\n        dishes.push(data.sectionEntitiesMap[sid][did])\n      }\n    }\n    await scrapeMergeData(scrape_id, { dishes: dishes })\n  }\n\n  private encodeLocation(lat: number, lon: number) {\n    // Only latitude and longitude will ever need to be changed. But the other fields seem\n    // to be needed for validation.\n    const location_template = {\n      address: {\n        address1: '',\n      },\n      latitude: lat,\n      longitude: lon,\n      reference: '',\n      referenceType: '',\n      type: '',\n      source: '',\n    }\n    return encodeURIComponent(JSON.stringify(location_template))\n  }\n\n  // This is a hard-coded list of Uber Eats most popular categories.\n  private loadCategories() {\n    return categories.JSON.data.categories.map((obj: any) => {\n      return obj.title\n    })\n  }\n}\n", "export default {\n  JSON: {\n    status: 'success',\n    data: {\n      categories: [\n        {\n          title: 'Afghan',\n          categoryName: 'Afghan',\n          slug: 'afghan',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/f4a19083bd38d4039c73080dc2a16fee',\n        },\n        {\n          title: 'African',\n          categoryName: 'African',\n          slug: 'african',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d95e8c376f9fde5ece488d3f18cb4166',\n        },\n        {\n          title: 'American',\n          categoryName: 'American',\n          slug: 'american',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/a5aa9bbba0172134449b4ad48611d92b',\n        },\n        {\n          title: 'Arabian',\n          categoryName: 'Arabian',\n          slug: 'arabian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/9ce7071e3e974db190a1cefe9a7b6001',\n        },\n        {\n          title: 'Asian',\n          categoryName: 'Asian',\n          slug: 'asian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/57864fe0d398139ac2175e7457c63954',\n        },\n        {\n          title: 'Asian Fusion',\n          categoryName: 'Asian Fusion',\n          slug: 'asian-fusion',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/c2550f8cf42617cb4d0014de7d0cd577',\n        },\n        {\n          title: 'Austrian',\n          categoryName: 'Austrian',\n          slug: 'austrian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/af4cad13d3bccda0d875ff31311b2a8f',\n        },\n        {\n          title: 'Bakery',\n          categoryName: 'Bakery',\n          slug: 'bakery',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d1164714a259d180471e20254b8211f7',\n        },\n        {\n          title: 'Bangladeshi',\n          categoryName: 'Bangladeshi',\n          slug: 'bangladeshi',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/b0918d1d1c2e68da8e1152050f261910',\n        },\n        {\n          title: 'Bar Food',\n          categoryName: 'Bar Food',\n          slug: 'bar-food',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/92daea70cc9f6b0725ab7bedcf93284c',\n        },\n        {\n          title: 'BBQ',\n          categoryName: 'BBQ',\n          slug: 'bbq',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/eeb45491416e3becc1961d921e667e5d',\n        },\n        {\n          title: 'Belgian',\n          categoryName: 'Belgian',\n          slug: 'belgian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/86e0957908092f9b434b18cb0b728fb7',\n        },\n        {\n          title: 'Biryani',\n          categoryName: 'Biryani',\n          slug: 'biryani',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/cuisine-dish-supertype/Biryani.png',\n        },\n        {\n          title: 'Brazilian',\n          categoryName: 'Brazilian',\n          slug: 'brazilian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/210ed9c483d2ecce321c4e06c7c3da6f',\n        },\n        {\n          title: 'Breakfast and Brunch',\n          categoryName: 'Breakfast and Brunch',\n          slug: 'breakfast-and-brunch',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/0bc9ca19a02e3bd03f2395c8cf8a3e0c',\n        },\n        {\n          title: 'Bubble Tea',\n          categoryName: 'Bubble Tea',\n          slug: 'bubble-tea',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/15033736a6ed78875085114ee74d4b60',\n        },\n        {\n          title: 'Burritos',\n          categoryName: 'Burritos',\n          slug: 'burrito',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_refinements/photos/Burritos.png',\n        },\n        {\n          title: 'Cafe',\n          categoryName: 'Cafe',\n          slug: 'cafe',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/9ddae01d317082a5cb3727d945a4880b',\n        },\n        {\n          title: 'Cajun',\n          categoryName: 'Cajun',\n          slug: 'cajun',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/db2fc543b2b06589a145f55899c71c18',\n        },\n        {\n          title: 'Cambodian',\n          categoryName: 'Cambodian',\n          slug: 'cambodian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/da204f8db3ebef052fade2cab363496e',\n        },\n        {\n          title: 'Cantonese',\n          categoryName: 'Cantonese',\n          slug: 'cantonese',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/85777a0f573a04acaacc19d94ff725fc',\n        },\n        {\n          title: 'Caribbean',\n          categoryName: 'Caribbean',\n          slug: 'caribbean',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/9ccd29d6398697287313006c39498d20',\n        },\n        {\n          title: 'Chicken',\n          categoryName: 'Chicken',\n          slug: 'pollo',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_home/Pollo.jpg',\n        },\n        {\n          title: 'Chinese',\n          categoryName: 'Chinese',\n          slug: 'chinese',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/a84dc69cee307fba4f559b1e825d8e9e',\n        },\n        {\n          title: 'Coffee and Tea',\n          categoryName: 'Coffee and Tea',\n          slug: 'coffee-and-tea',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/3f270d9121923dc25df3a5853bff83a8',\n        },\n        {\n          title: 'Colombian',\n          categoryName: 'Colombian',\n          slug: 'colombian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/e91ac27b3e91b06523cdaf5891f7c69b',\n        },\n        {\n          title: 'Comfort Food',\n          categoryName: 'Comfort Food',\n          slug: 'comfort-food',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/6012a01e7f7efe32e842aa152a999136',\n        },\n        {\n          title: 'Cuban',\n          categoryName: 'Cuban',\n          slug: 'cuban',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/257a7721eb8997d141f3f1cc67bfb0e0',\n        },\n        {\n          title: 'Cupcakes',\n          categoryName: 'Cupcakes',\n          slug: 'cupcake',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/18db7ea345aa5309db75f96f06148ee5',\n        },\n        {\n          title: 'Curry',\n          categoryName: 'Curry',\n          slug: 'curry',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_refinements/photos/Curries.png',\n        },\n        {\n          title: 'Danish',\n          categoryName: 'Danish',\n          slug: 'danish',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d9dfe5f3dac81ff516c4eddee07b0a73',\n        },\n        {\n          title: 'Deli',\n          categoryName: 'Deli',\n          slug: 'deli',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/cc9ef0d3f2b74972f2c97a2781b2880c',\n        },\n        {\n          title: 'Desserts',\n          categoryName: 'Desserts',\n          slug: 'dessert',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/3962b16c350438a56fd7794ba4a15b9c',\n        },\n        {\n          title: 'Diner',\n          categoryName: 'Diner',\n          slug: 'diner',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/fa7ced03c7f36348dd525abb931ee372',\n        },\n        {\n          title: 'Dominican',\n          categoryName: 'Dominican',\n          slug: 'dominican',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/b8d737a79eb768eb868894224dc400e0',\n        },\n        {\n          title: 'Ethiopian',\n          categoryName: 'Ethiopian',\n          slug: 'ethiopian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/b4f03ccb6b22edb09e0631f7912fbe0e',\n        },\n        {\n          title: 'European',\n          categoryName: 'European',\n          slug: 'european',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/6fb0b3e7fadd682aca1f5213d40c33d5',\n        },\n        {\n          title: 'Fast Food',\n          categoryName: 'Fast Food',\n          slug: 'fast-food',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/f6e04e64903c3207e68c649e24cc2f32',\n        },\n        {\n          title: 'Filipino',\n          categoryName: 'Filipino',\n          slug: 'filipino',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/bad5f040f27afdb22c76d8076d57eaa3',\n        },\n        {\n          title: 'Fish and Chips',\n          categoryName: 'Fish and Chips',\n          slug: 'fish-and-chips',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/f3bc6c7cb064c4f1a66f6b6221bd34bd',\n        },\n        {\n          title: 'Flour based food',\n          categoryName: 'Flour based food',\n          slug: 'konamono',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_home/Konamono.jpg',\n        },\n        {\n          title: 'French',\n          categoryName: 'French',\n          slug: 'french',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/60ae0adfdc27ba36ac4ebec59ed47474',\n        },\n        {\n          title: 'Georgian',\n          categoryName: 'Georgian',\n          slug: 'georgian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/ce83a705def45ab34917479369780706',\n        },\n        {\n          title: 'German',\n          categoryName: 'German',\n          slug: 'german',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/c39a4afe3d9130bd4fd0ff1cc6ba43c3',\n        },\n        {\n          title: 'Gluten Free',\n          categoryName: 'Gluten Free',\n          slug: 'gluten-free',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/e40d6fd9f8a594bfad4305fc965b6a4a',\n        },\n        {\n          title: 'Gluten Free Friendly',\n          categoryName: 'Gluten Free Friendly',\n          slug: 'gluten-free-friendly',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/73161aa27cd74c41a11d263ef6ddc9ec',\n        },\n        {\n          title: 'Gourmet',\n          categoryName: 'Gourmet',\n          slug: 'gourmet',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_home/Gourmet.jpg',\n        },\n        {\n          title: 'Greek',\n          categoryName: 'Greek',\n          slug: 'greek',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/3db65f7fe4486b0ae18f1315a6d27bbd',\n        },\n        {\n          title: 'Halal',\n          categoryName: 'Halal',\n          slug: 'halal',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/14707f344282ab7f8b5d7c471128d910',\n        },\n        {\n          title: 'Hawaiian',\n          categoryName: 'Hawaiian',\n          slug: 'hawaiian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/5ef386652232c6e8ca88d9fd7336845b',\n        },\n        {\n          title: 'Healthy',\n          categoryName: 'Healthy',\n          slug: 'healthy',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/5bcce6114b9d2d5a39b81e756a250407',\n        },\n        {\n          title: 'Himalayan',\n          categoryName: 'Himalayan',\n          slug: 'himalayan',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/e918f4ba7b50c5180e72c937f875b7a4',\n        },\n        {\n          title: 'Ice Cream and Frozen Yogurt',\n          categoryName: 'Ice Cream and Frozen Yogurt',\n          slug: 'ice-cream-and-frozen-yogurt',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/65126c9733e086b7dc71a7ae8ccf0d93',\n        },\n        {\n          title: 'Indian',\n          categoryName: 'Indian',\n          slug: 'indian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/836fa3b8cf098f8cbed99cedc7c06779',\n        },\n        {\n          title: 'Indian Curry',\n          categoryName: 'Indian Curry',\n          slug: 'indian-curry',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_home/IndianCurry.jpg',\n        },\n        {\n          title: 'Indonesian',\n          categoryName: 'Indonesian',\n          slug: 'indonesian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/78c936f557b69df49f8afdc19a699c20',\n        },\n        {\n          title: 'Italian',\n          categoryName: 'Italian',\n          slug: 'italian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/256bc34a3917153511de66ce2510be0a',\n        },\n        {\n          title: 'Jamaican',\n          categoryName: 'Jamaican',\n          slug: 'jamaican',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/dde681cc6bbbb8bf6dbe2b30916f1027',\n        },\n        {\n          title: 'Japanese',\n          categoryName: 'Japanese',\n          slug: 'japanese',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/78e3d7f0866e5f17c8350216653b063b',\n        },\n        {\n          title: 'Juice and Smoothies',\n          categoryName: 'Juice and Smoothies',\n          slug: 'juice-and-smoothies',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/9d5cc3244d0b520b45e518966087b756',\n        },\n        {\n          title: 'Kebab',\n          categoryName: 'Kebab',\n          slug: 'kebab',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/cuisine-dish-supertype/Kebab.png',\n        },\n        {\n          title: 'Kids Friendly',\n          categoryName: 'Kids Friendly',\n          slug: 'kids-friendly',\n          imageUrl:\n            'https://d1a3f4spazzrp4.cloudfront.net/chameleon/cms/uploads/2017/10/2/1506928763-Resized1.jpg',\n        },\n        {\n          title: 'Korean',\n          categoryName: 'Korean',\n          slug: 'korean',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/9acf7c2098b64401466cb81ca991f7f6',\n        },\n        {\n          title: 'Kosher',\n          categoryName: 'Kosher',\n          slug: 'kosher',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/2dbee2749e673c7fb190c925d3db34a5',\n        },\n        {\n          title: 'Latin American',\n          categoryName: 'Latin American',\n          slug: 'latin-american',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d7e44b1840cf3f1f77ebe31651b3f9e3',\n        },\n        {\n          title: 'Latin Fusion',\n          categoryName: 'Latin Fusion',\n          slug: 'latin-fusion',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/23f7400a01fa463a0384bb82ebfdf238',\n        },\n        {\n          title: 'Lebanese',\n          categoryName: 'Lebanese',\n          slug: 'lebanese',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/5fc801c20745766a5ae7421dcd945207',\n        },\n        {\n          title: 'Malaysian',\n          categoryName: 'Malaysian',\n          slug: 'malaysian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d1f19d7539cdfb6a3c4241955948b7af',\n        },\n        {\n          title: 'Mediterranean',\n          categoryName: 'Mediterranean',\n          slug: 'mediterranean',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/7aa9aeff334776f152be164cd02ca062',\n        },\n        {\n          title: 'Mexican',\n          categoryName: 'Mexican',\n          slug: 'mexican',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/7b2a32908c050e6b07252ffcbe651e8c',\n        },\n        {\n          title: 'Middle Eastern',\n          categoryName: 'Middle Eastern',\n          slug: 'middle-eastern',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/0f8eb25c1202f7fc963d8e2debc202af',\n        },\n        {\n          title: 'Modern European',\n          categoryName: 'Modern European',\n          slug: 'modern-european',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/b341a87c10d42a3db00843e35f8975c6',\n        },\n        {\n          title: 'Modern French',\n          categoryName: 'Modern French',\n          slug: 'modern-french',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/7c982947ceeb58c68bd7b93f2779d958',\n        },\n        {\n          title: 'Moroccan',\n          categoryName: 'Moroccan',\n          slug: 'moroccan',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/a397e9edbe0c16b1b72daac72a4c1727',\n        },\n        {\n          title: 'Nepalese',\n          categoryName: 'Nepalese',\n          slug: 'nepalese',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/0cc90024dbd2687a54c774078a558e07',\n        },\n        {\n          title: 'New American',\n          categoryName: 'New American',\n          slug: 'new-american',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/12832a352dccdd2d165421e1e73fdad9',\n        },\n        {\n          title: 'New Mexican',\n          categoryName: 'New Mexican',\n          slug: 'new-mexican',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d409b9e4da70c004798275dc9b6a8291',\n        },\n        {\n          title: 'North Indian',\n          categoryName: 'North Indian',\n          slug: 'north-indian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/271de51c4a81a8cc779847ea6534793c',\n        },\n        {\n          title: 'Pakistani',\n          categoryName: 'Pakistani',\n          slug: 'pakistani',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/6e98068c35b3eca8171a0b6e15998086',\n        },\n        {\n          title: 'Pasta',\n          categoryName: 'Pasta',\n          slug: 'pasta',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_refinements/photos/Pasta.png',\n        },\n        {\n          title: 'Pastry',\n          categoryName: 'Pastry',\n          slug: 'pastry',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/861d2b9d393be89f98be5cb2e7e5845c',\n        },\n        {\n          title: 'Persian',\n          categoryName: 'Persian',\n          slug: 'persian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/0fb653ea3a534a06eb1b4ee91e7cd338',\n        },\n        {\n          title: 'Peruvian',\n          categoryName: 'Peruvian',\n          slug: 'peruvian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/6f947d48e064295bbb7325b383ac88ca',\n        },\n        {\n          title: 'Pizza',\n          categoryName: 'Pizza',\n          slug: 'pizza',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/971d80f9ccce0c8eab98014650ee97eb',\n        },\n        {\n          title: 'Polish',\n          categoryName: 'Polish',\n          slug: 'polish',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/2df757a3a6632e75c0ea09a2c54dd51e',\n        },\n        {\n          title: 'Pub',\n          categoryName: 'Pub',\n          slug: 'pub',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/07c8a18c386b4f4263e8c6a8921c4676',\n        },\n        {\n          title: 'Puerto Rican',\n          categoryName: 'Puerto Rican',\n          slug: 'puerto-rican',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/8596515cadd577e2104d068a43a50bf2',\n        },\n        {\n          title: 'Ramen',\n          categoryName: 'Ramen',\n          slug: 'ramen',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/fdb527f9ec336dd1bf0ccad3dae5776d',\n        },\n        {\n          title: 'Rice-bowls',\n          categoryName: 'Rice-bowls',\n          slug: 'don-mono',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_home/DonMono.jpg',\n        },\n        {\n          title: 'Rolls',\n          categoryName: 'Rolls',\n          slug: 'rolls',\n          imageUrl: 'http://duyt4h9nfnj50.cloudfront.net/search_home/Rolls.jpg',\n        },\n        {\n          title: 'Russian',\n          categoryName: 'Russian',\n          slug: 'russian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/1aa7add8beef1f39adf099f57185cb39',\n        },\n        {\n          title: 'Salads',\n          categoryName: 'Salads',\n          slug: 'salad',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/9bc9a3a696651b5e5e777660fa6b0536',\n        },\n        {\n          title: 'Seafood',\n          categoryName: 'Seafood',\n          slug: 'seafood',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/998c405357c700f498fc86be08a0b8c2',\n        },\n        {\n          title: 'Singaporean',\n          categoryName: 'Singaporean',\n          slug: 'singaporean',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/bcb19a729eab24bbf64915206c47fb3d',\n        },\n        {\n          title: 'Soul Food',\n          categoryName: 'Soul Food',\n          slug: 'soul-food',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/9982f7761a86002a43319d300301137e',\n        },\n        {\n          title: 'Soup',\n          categoryName: 'Soup',\n          slug: 'soup',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_refinements/photos/Soups.png',\n        },\n        {\n          title: 'South American',\n          categoryName: 'South American',\n          slug: 'south-american',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d7e44b1840cf3f1f77ebe31651b3f9e3',\n        },\n        {\n          title: 'South Asian',\n          categoryName: 'South Asian',\n          slug: 'south-asian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/8f056997b879abf2e31caa1ca2c2d57e',\n        },\n        {\n          title: 'South Indian',\n          categoryName: 'South Indian',\n          slug: 'south-indian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/58d5b215edd0ca322b7c0f193a495822',\n        },\n        {\n          title: 'Southern',\n          categoryName: 'Southern',\n          slug: 'southern',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/32a82c01404d13aa10e51ec889e860f3',\n        },\n        {\n          title: 'Spanish',\n          categoryName: 'Spanish',\n          slug: 'spanish',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/4f8afc1b602a71736e43c17e25219e3c',\n        },\n        {\n          title: 'Street Food',\n          categoryName: 'Street Food',\n          slug: 'street-food',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/42ce3a81bced6067219d62ca44aec950',\n        },\n        {\n          title: 'Sushi',\n          categoryName: 'Sushi',\n          slug: 'sushi',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/21b6882726bf71ba17b29ab47ef16d22',\n        },\n        {\n          title: 'Swedish',\n          categoryName: 'Swedish',\n          slug: 'swedish',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/43a932e36d56d0258ccd9286dca12a77',\n        },\n        {\n          title: 'Tacos',\n          categoryName: 'Tacos',\n          slug: 'taco',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_refinements/photos/Tacos.png',\n        },\n        {\n          title: 'Taiwanese',\n          categoryName: 'Taiwanese',\n          slug: 'taiwanese',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/da6fcee0cd362a754551e695d7546f62',\n        },\n        {\n          title: 'Tex Mex',\n          categoryName: 'Tex Mex',\n          slug: 'tex-mex',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/82ad068a4fabaa78308cafe9b3f192cd',\n        },\n        {\n          title: 'Thai',\n          categoryName: 'Thai',\n          slug: 'thai',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/9a7792417e52d2be9f6550b48e48a4fc',\n        },\n        {\n          title: 'Traditional American',\n          categoryName: 'Traditional American',\n          slug: 'traditional-american',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/538dbc6b6a0e2fa973d28f8a8d68c8b5',\n        },\n        {\n          title: 'Turkish',\n          categoryName: 'Turkish',\n          slug: 'turkish',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/8dc30bebd98b542e209ee97a9d6977c5',\n        },\n        {\n          title: 'Vegan',\n          categoryName: 'Vegan',\n          slug: 'vegan',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/55c691b1f4df92218a47588c5ec761d1',\n        },\n        {\n          title: 'Vegan Friendly',\n          categoryName: 'Vegan Friendly',\n          slug: 'vegan-friendly',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/89c8254e4ce8e38d996b95fca9ba5334',\n        },\n        {\n          title: 'Vegetarian',\n          categoryName: 'Vegetarian',\n          slug: 'vegetarian',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d05be7041817489907d26ae125aa0de1',\n        },\n        {\n          title: 'Vegetarian Friendly',\n          categoryName: 'Vegetarian Friendly',\n          slug: 'vegetarian-friendly',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/8b64f4fdc97deb44adc209f90d4ea09d',\n        },\n        {\n          title: 'Venezuelan',\n          categoryName: 'Venezuelan',\n          slug: 'venezuelan',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d137f03f42415bc4048ca851f548d7a4',\n        },\n        {\n          title: 'Vietnamese',\n          categoryName: 'Vietnamese',\n          slug: 'vietnamese',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/d5e7d9a8bdea0a76abf96650bbc3af22',\n        },\n        {\n          title: 'Western',\n          categoryName: 'Western',\n          slug: 'western',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/cfb732b6a1111371079b2fdb73287fcc',\n        },\n        {\n          title: 'Wings',\n          categoryName: 'Wings',\n          slug: 'wings',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/sku/062faadce31ecb80703eb7d4d273bc22',\n        },\n        {\n          title: 'Wraps',\n          categoryName: 'Wraps',\n          slug: 'wrap',\n          imageUrl: 'https://duyt4h9nfnj50.cloudfront.net/search_refinements/photos/Wraps.png',\n        },\n      ],\n      slugName: 'new-york',\n      shouldIndex: true,\n    },\n  },\n}\n", "import url from 'url'\n\nimport { sleep } from '@dish/async'\nimport { sentryMessage } from '@dish/common'\nimport { Restaurant, ZeroUUID, query, resolved } from '@dish/graph'\nimport { decode } from '@dish/helpers-node'\nimport { ProxiedRequests, WorkerJob, fetchBrowserScriptData } from '@dish/worker'\nimport { JobOptions, QueueOptions } from 'bull'\nimport _ from 'lodash'\n\nimport { restaurantSaveCanonical } from '../canonical-restaurant'\nimport { DISH_DEBUG } from '../constants'\nimport { YelpDetailPageData, YelpScrapeData } from '../fixtures/fixtures'\nimport {\n  Scrape,\n  ScrapeData,\n  scrapeFindOneBySourceID,\n  scrapeInsert,\n  scrapeMergeData,\n  scrapeUpdateBasic,\n} from '../scrape-helpers'\nimport { aroundCoords, boundingBoxFromCenter, geocode } from '../utils'\nimport { FixAddressBug } from './fix_address_bug'\n\ntype RestaurantMatching = Required<Pick<Restaurant, 'name' | 'address' | 'telephone'>>\n\ntype GetRestaurantsArgs = {\n  top_right: [number, number]\n  bottom_left: [number, number]\n  start: number\n  onlyRestaurant: RestaurantMatching | null\n  category?: 'all' | 'food' | 'restaurants' | 'food,restaurants'\n}\n\nexport type YelpScrape = Scrape<YelpScrapeData>\n\nexport const YELP_DOMAIN = 'https://www.yelp.com'\nexport const YELP_DOMAIN_MOBILE = 'https://m.yelp.com'\n\nexport const yelpAPI = new ProxiedRequests(YELP_DOMAIN, process.env.YELP_AWS_PROXY || YELP_DOMAIN, {\n  headers: {\n    'X-My-X-Forwarded-For': 'www.yelp.com',\n  },\n  timeout: null,\n})\n\nexport const yelpAPIMobile = new ProxiedRequests(\n  YELP_DOMAIN_MOBILE,\n  process.env.YELP_MOBILE_AWS_PROXY || YELP_DOMAIN_MOBILE,\n  {\n    headers: {\n      'X-My-X-Forwarded-For': 'm.yelp.com',\n      'User-Agent':\n        'Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_3_2 like Mac OS X; nl-nl) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8H7 Safari/6533.18.5',\n    },\n    timeout: null,\n  }\n)\n\nexport class Yelp extends WorkerJob {\n  current_biz_path?: string\n  find_only: RestaurantMatching | null = null\n  log_of_found_restaurants = new Set<string>()\n\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 5,\n      duration: 300,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  get logName() {\n    return `Yelp ${this.current_biz_path || this.find_only?.name || '...'}`\n  }\n\n  async crawlSingle(slug: string) {\n    const rest = await resolved(() => {\n      return query\n        .restaurant({\n          where: {\n            slug: {\n              _eq: slug,\n            },\n          },\n        })\n        .map((x) => {\n          return {\n            name: x.name,\n            id: x.id,\n            slug: x.slug,\n            address: x.address,\n            location: x.location,\n            sources: x.sources,\n          }\n        })[0]\n    })\n    if (!rest?.name) {\n      this.log('not found, no name')\n      return\n    }\n    const mv = 0.001\n    const [lng, lat] = rest.location?.coordinates ?? []\n    if (lng && lat) {\n      try {\n        await this.getRestaurants({\n          top_right: [lat - mv, lng - mv],\n          bottom_left: [lat + mv, lng + mv],\n          start: 0,\n          onlyRestaurant: rest as any,\n        })\n      } catch (err) {\n        this.log(\n          'Error finding by searching for exact location, switch to general search',\n          err.message,\n          err.stack\n        )\n        // @ts-ignore\n        await this.refindRestaurant(rest)\n      }\n    } else {\n      this.log(`no lng or lat ${rest.location}`)\n      // @ts-ignore\n      await this.refindRestaurant(rest)\n    }\n  }\n\n  async refindRestaurant(rest: Restaurant) {\n    if (!rest.address) {\n      this.log(`No address`)\n      return\n    }\n    const addrs = rest.address.split(', ')\n    const city = addrs.slice(addrs.length - 2, addrs.length).join(', ')\n    const name = decode(rest.name).replace(/[^a-z0-9]/gi, '')\n    // prettier-ignore\n    const searchUrl = `/search_suggest/v2/prefetch?loc=${encodeURIComponent(city)}&loc_name_param=loc&is_new_loc=&prefix=${encodeURIComponent(name)}&is_initial_prefetch=`\n    this.log(`Searching for restaurant ${YELP_DOMAIN + searchUrl}`)\n    const res: any = await yelpAPI.getJSON(searchUrl)\n    const suggestions = res?.response?.flatMap((x: any) => x.suggestions)\n    if (!suggestions) {\n      throw new Error(`No response: ${JSON.stringify(res || null)}`)\n    }\n    const yelpUrl = rest.sources?.yelp?.url\n    const street = decode(addrs.slice(0, addrs.length - 2).join(', ')).toLowerCase()\n    this.log('check for match', yelpUrl, street, JSON.stringify(suggestions))\n    const found = suggestions.find((x: any) => {\n      if (yelpUrl) {\n        return yelpUrl.includes(x.redirect_url)\n      }\n      if (street) {\n        // subtitle is the street address\n        return street.includes(decode(x.subtitle).toLowerCase())\n      }\n      return false\n    })\n    if (!found) {\n      this.log(`not found anymore, may be closed?`)\n      return\n    }\n    const mv = 0.0025\n    this.log(`found ${JSON.stringify(found || null)}`)\n    const [lat, lng] = await geocode(found.subtitle)\n    this.log('found new coords, try again at', JSON.stringify({ lat, lng }))\n    await this.getRestaurants({\n      top_right: [lat - mv, lng - mv],\n      bottom_left: [lat + mv, lng + mv],\n      start: 0,\n      onlyRestaurant: rest as RestaurantMatching,\n    })\n  }\n\n  async allForCity(city_name: string) {\n    this.log(`Starting on city \"${city_name}\". Using AWS proxy: ${process.env.YELP_AWS_PROXY}`)\n    const MAPVIEW_SIZE = 4000\n    const coords = await geocode(city_name)\n    const region_coords = _.shuffle(aroundCoords(coords[0], coords[1], MAPVIEW_SIZE, 6))\n    const longest_radius = (MAPVIEW_SIZE * Math.sqrt(2)) / 2\n    for (const box_center of region_coords) {\n      const bounding_box = boundingBoxFromCenter(box_center[0], box_center[1], longest_radius)\n      await this.runOnWorker('getRestaurants', [\n        {\n          top_right: bounding_box[0],\n          bottom_left: bounding_box[1],\n          start: 0,\n        },\n      ])\n    }\n  }\n\n  async getRestaurants({\n    top_right,\n    bottom_left,\n    start = 0,\n    onlyRestaurant = null,\n    // comma seems to work!\n    category = 'food,restaurants',\n  }: GetRestaurantsArgs) {\n    const coords = [top_right[1], top_right[0], bottom_left[1], bottom_left[0]].join(',')\n    const bb = encodeURIComponent('g:' + coords)\n    const uri = `/search/snippet?cflt=${category}&l=${bb}&start=${start}`\n    const response: any = await yelpAPI.getJSON(uri)\n    if (!response) {\n      this.log('no response!', response)\n      return []\n    }\n    const componentsList = response.searchPageProps.mainContentComponentsListProps ?? []\n    const pagination = componentsList.find((x: any) => x.type === 'pagination')\n\n    if (!pagination) {\n      this.log('no pagination', componentsList)\n    }\n\n    let found_the_one = false\n    this.find_only = onlyRestaurant\n\n    if (!componentsList.length) {\n      console.error('searchPageProps.searchResultsProps: ', uri, response)\n      throw new Error('Nothing in `response.searchPageProps.searchResultsProps.searchResults`')\n    }\n\n    const validResults = componentsList.filter((data: any) => {\n      if (data?.props?.text?.includes('Sponsored Results')) {\n        return false\n      }\n      if (data?.searchResultLayoutType == 'separator') {\n        return false\n      }\n      return true\n    })\n\n    this.log(`geo search: ${coords}, page ${start}, ${validResults.length} results`)\n\n    let toCrawl: any[] = []\n\n    if (!onlyRestaurant) {\n      toCrawl = validResults\n    } else {\n      this.log(\n        `looking for specific restaurant based on ${onlyRestaurant.name} ${onlyRestaurant.address} ${onlyRestaurant.telephone}`\n      )\n      const findOne = (strategy = 'strict') => {\n        if (toCrawl.length) return\n        for (const data of validResults) {\n          const info = data.searchResultBusiness\n          if (isMatchingRestaurant(info, onlyRestaurant, strategy as any)) {\n            const scrape_msg = `scrape (${info.formattedAddress} ${info.phone} ${info.name})`\n            const restaurant_msg = `restaurant (${onlyRestaurant.address} ${onlyRestaurant.telephone} ${onlyRestaurant.name})`\n            const prefix = `YELP SANDBOX: found ${info.name} ${strategy}`\n            this.log(`${prefix} - ${scrape_msg} ${restaurant_msg}`)\n            toCrawl = [data]\n            found_the_one = true\n            break\n          }\n        }\n      }\n      // findOne('strict')\n      // findOne('fuzzy')\n      findOne('name')\n    }\n\n    if (!toCrawl.length) {\n      console.log(\n        'none found!',\n        validResults.map((x: any) => x?.searchResultBusiness?.name).join(', ')\n      )\n      return\n    }\n\n    this.trackFoundRestaurants(validResults)\n    this.log('got crawlable results', toCrawl.length)\n\n    for (const data of toCrawl) {\n      const timeout = sleep(100_000)\n      await Promise.race([\n        this.processRestaurant(data),\n        timeout.then(() => {\n          console.warn('Timed out getting restaurant', data.searchResultBusiness?.name)\n        }),\n      ])\n      timeout.cancel()\n    }\n\n    await this.paginate(pagination, found_the_one, {\n      top_right,\n      bottom_left,\n      start,\n      onlyRestaurant,\n    })\n\n    if (onlyRestaurant) {\n      if (!found_the_one) {\n        // prettier-ignore\n        this.log('error componentsList\\n', ` > ${YELP_DOMAIN}${uri}\\n`, componentsList?.length)\n        throw new Error(`Couldn't find ${onlyRestaurant.name}`)\n      }\n    }\n\n    this.log('done with getRestaurants')\n  }\n\n  async paginate(pagination: any, found_the_one: boolean, args: GetRestaurantsArgs) {\n    if (!pagination || found_the_one) return\n    if (process.env.NODE_ENV == 'test' && args.start > 50) return\n    const perPage = pagination.props.resultsPerPage\n    const total_results = pagination.props.totalResults\n    args.start += perPage\n    if (args.start <= total_results) {\n      await this.runOnWorker('getRestaurants', [args])\n    }\n  }\n\n  trackFoundRestaurants(validResults: any) {\n    const names = validResults.map((x: any) => x?.searchResultBusiness?.name)\n    names.forEach(this.log_of_found_restaurants.add, this.log_of_found_restaurants)\n    if (DISH_DEBUG >= 2) {\n      this.log(`Found restaurants: ${this.log_of_found_restaurants.size}`)\n    }\n  }\n\n  async processRestaurant(data: any) {\n    if (!data.searchResultBusiness) {\n      console.warn('no data.searchResultBusiness')\n      return\n    }\n    const id = await scrapeInsert({\n      source: 'yelp',\n      restaurant_id: ZeroUUID,\n      location: {\n        lat: 0,\n        lon: 0,\n      },\n      id_from_source: data.bizId,\n      data: {\n        data_from_search_list_item: data.searchResultBusiness,\n      },\n    })\n    this.log('Inserting scrape data for scrape id', id, 'bizId', data.bizId)\n    if (!id) {\n      throw new Error(`No id`)\n    }\n    let bizUrl = data.searchResultBusiness.businessUrl as string\n    const fullUrl = url.parse(bizUrl, true)\n    if (fullUrl.query.redirect_url) {\n      bizUrl = decodeURI(fullUrl.query.redirect_url as string)\n    }\n    // lets use mobile!\n    bizUrl = bizUrl.replace('www.', 'm.')\n    this.log('bizUrl', bizUrl)\n    const bizUrlParsed = url.parse(bizUrl, true)\n    this.log(`RUN_WITHOUT_WORKER=${process.env.RUN_WITHOUT_WORKER}`)\n    await this.runOnWorker('getEmbeddedJSONData', [id, bizUrlParsed.path, data.bizId])\n  }\n\n  async getEmbeddedJSONData(id: string, yelp_path: string, id_from_source: string) {\n    this.current_biz_path = yelp_path\n    this.log(`getting embedded JSON for: ${yelp_path}`)\n    // @ts-ignore\n    const [dynamicIns, ldjsonsIn] = await yelpAPIMobile.getScriptData(yelp_path, [\n      'script[data-hypernova-key*=\"__mobile_site__Biz__dynamic\"]',\n      'script[type*=\"application/ld+json\"]',\n    ])\n    const [dynamicIn] = dynamicIns\n\n    if (!dynamicIn) {\n      console.log('error, got', { dynamicIns, dynamicIn, ldjsonsIn })\n      throw new Error(`No extraction found`)\n    }\n\n    if (!('legacyProps' in dynamicIn)) {\n      if (process.env.NODE_ENV !== 'production') {\n        // prettier-ignore\n        console.log('no legacyProps in\\n', JSON.stringify(dynamicIn, null, 2))\n      }\n      sentryMessage(\"Error Couldn't extract embedded data\", {\n        data: { path: yelp_path },\n        logger: this.log,\n      })\n      return\n    }\n\n    const dynamic = dynamicIn as YelpDetailPageData['dynamic']\n    // clean just a bit\n    delete dynamic['messages']\n\n    const jsonByType = ldjsonsIn\n      .filter(Boolean)\n      .find((x: any) => x['@type'] === 'Restaurant' || x['@type'] === 'LocalBusiness')\n    const json: YelpDetailPageData['json'] | null = jsonByType || ldjsonsIn[1] || null\n\n    if (!json) {\n      console.log('error no schema data found', { json, ldjsonsIn })\n      return\n    }\n\n    this.log(`merge scrape data: ${yelp_path}`)\n    const scrape = (await scrapeMergeData(id, { dynamic, json, yelp_path }))! as YelpScrape\n\n    const { mapState } = scrape.data.dynamic.legacyProps.props.directionsModalProps\n    const { latitude, longitude } = mapState.center\n    const restaurant_id = await restaurantSaveCanonical(\n      'yelp',\n      id_from_source,\n      longitude,\n      latitude,\n      scrape.data.data_from_search_list_item.name,\n      Yelp.getNameAndAddress(scrape).address\n    )\n    if (this.find_only) {\n      this.log(`ID for ${this.find_only.name} is ${restaurant_id}`)\n    }\n    scrape.location = {\n      lon: longitude,\n      lat: latitude,\n    }\n    scrape.restaurant_id = restaurant_id\n    await scrapeUpdateBasic(scrape)\n    await this.getNextScrapes(id, scrape)\n    if (DISH_DEBUG > 2) {\n      const data = await scrapeFindOneBySourceID('yelp', id_from_source)\n      this.log(`Scrape:`, JSON.stringify(data, null, 2))\n    }\n  }\n\n  static getNameAndAddress(scrape: YelpScrape) {\n    const parts = scrape.data.json.address\n    const address = [\n      parts.streetAddress,\n      parts.addressLocality,\n      parts.addressRegion,\n      parts.postalCode,\n      parts.addressCountry,\n    ]\n      .filter(Boolean)\n      .join(', ')\n\n    return {\n      name: scrape.data.data_from_search_list_item.name,\n      address,\n    }\n  }\n\n  async getNextScrapes(id: string, scrape: YelpScrape) {\n    const source = scrape.data.dynamic.legacyProps.props.modules.serverModules\n    const photoGrid = source.flatMap((x) => (x.component === 'PhotoGrid' ? x : []))[0]?.props\n    let photoTotal = (photoGrid.mediaCount as number) ?? 0\n    this.log(`getNextScrapes photoTotal ${photoTotal}`)\n    if (photoTotal > 31 && process.env.NODE_ENV == 'test') {\n      photoTotal = 31\n    }\n    const bizId = scrape.id_from_source\n    if (photoTotal > 0) {\n      await this.runOnWorker('getPhotos', [\n        id,\n        scrape.data.yelp_path.replace('/biz/', ''),\n        photoTotal,\n      ])\n    }\n    await this.runOnWorker('getReviews', [id, bizId])\n  }\n\n  async getPhotos(id: string, slug: string, photoTotal: number) {\n    const PER_PAGE = 30\n    const pagesTotal = Math.ceil(photoTotal / PER_PAGE)\n    let pages = [...new Array(pagesTotal).fill(0)].map((_, i) => i)\n    this.log(`getPhotos pages ${pages.join(', ')}`)\n    for (const page of pages) {\n      await this.runOnWorker('getPhotoPage', [id, slug, page * PER_PAGE, page])\n    }\n  }\n\n  async getPhotoPage(id: string, slug: string, start: number, page: number) {\n    if (page > 2 && process.env.DISH_ENV === 'test') {\n      console.log('test mode exit after first page')\n      return\n    }\n    // this is removed :(\n    // https://m.yelp.com/biz_photos/qs7FgJ-UXgpbAMass0Oojg/get_photos?start=14&dir=b\n    const url = `${YELP_DOMAIN}/biz_photos/${slug}?start=${start}`\n    this.log(`getting photo page ${url}`)\n    //'/biz_photos/' + bizId + '/get_photos' + '?start=' + start + '&dir=b'\n    const response: any = await fetchBrowserScriptData(url, ['[data-photo-id]'])\n    const items = response.flat()\n\n    const data: { url: string; caption: string }[] = []\n\n    for (const item of items) {\n      if (!item || typeof item !== 'string') {\n        continue\n      }\n      const url = (item.match(/src=\"([^\"]+)\"/)?.[1] ?? '').replace(/\\/[0-9]+s.jpg/, '/1000s.jpg')\n      // if no url or exists already ignore\n      if (!url || data.find((x) => x.url === url)) {\n        continue\n      }\n      const caption = item.match(/alt=\"Photo of[^\\.]+\\. ([^\\\"]+)\"/)?.[1] ?? ''\n      data.push({\n        url: url,\n        caption: decode(caption.trim()),\n      })\n    }\n    if (DISH_DEBUG > 3) {\n      console.log(`Got photos`, data)\n    }\n\n    const photos: { [keys: string]: any } = {}\n    photos['photosp' + page] = data\n    await scrapeMergeData(id, photos)\n    this.log(`got photo page ${page} with ${data.length} photos`)\n  }\n\n  async getReviews(id: string, bizId: string, start = 0) {\n    const PER_PAGE = 10\n    const page = start / PER_PAGE\n    const url = '/biz/' + bizId + '/review_feed?rl=en&sort_by=relevance_desc&q=&start=' + start\n    const response: any = await yelpAPI.getJSON(url, {\n      headers: {\n        'X-Requested-With': 'XMLHttpRequest',\n        'X-Requested-By-React': 'true',\n      },\n      timeout: null,\n    })\n    const data = response.reviews\n    let reviews: ScrapeData = {}\n    reviews['reviewsp' + page] = data\n    await scrapeMergeData(id, reviews)\n    this.log(`${this.current_biz_path}, got review page ${page} with ${data.length} reviews`)\n\n    if (process.env.NODE_ENV == 'test' && page > 1) {\n      this.log('Exiting review loop early in test mode')\n      return\n    }\n\n    const next_page = start + PER_PAGE\n    if (next_page <= response.pagination.totalResults) {\n      await this.runOnWorker('getReviews', [id, bizId, next_page])\n    }\n  }\n\n  async _reGeocodeScrapes() {\n    await FixAddressBug.reGeocodeScrapes(this)\n  }\n  async _reGeocodeOneScrape(id: string) {\n    await FixAddressBug.reGeocodeOneScrape(id)\n  }\n}\n\nfunction isMatchingRestaurant(\n  data: any,\n  restaurant: RestaurantMatching,\n  exactness: 'fuzzy' | 'strict' | 'name' = 'strict'\n) {\n  const similarName = isSimilar(restaurant.name, data?.name)\n  if (exactness === 'name') {\n    return similarName\n  }\n  const similarAddress = isSimilar(data.formattedAddress, restaurant?.address)\n  const similarPhone = isSimilar(restaurant.telephone, data.phone)\n  if (exactness !== 'strict') {\n    return (\n      (similarName && similarPhone) ||\n      (similarName && similarAddress) ||\n      (similarAddress && similarPhone)\n    )\n  }\n  if (similarName) {\n    return data.formattedAddress === restaurant.address\n  }\n  return false\n}\n\n// TODO could use levenshtein\nconst isSimilar = (a?: string | null, b?: string | null) => {\n  const ac = stripExtraChars(a ?? '')\n  const bc = stripExtraChars(b ?? '')\n  return ac.includes(bc) || bc.includes(ac)\n}\n\nconst stripExtraChars = (str: string) => str.replace(/[^a-z0-9]/gi, '')\n", "import { restaurantInsert } from '@dish/graph'\nimport { scrape_db } from '@dish/helpers-node'\n\nimport { geocodeRestaurant } from '../canonical-restaurant'\nimport { scrapeFindOneByUUID } from '../scrape-helpers'\nimport { Yelp, YelpScrape } from './Yelp'\n\n// The bug itself was just that the address field we'd chosen was unreliable.\n// This meant that we couldn't guarantee that all Yelp scrapes had found their\n// correct canonical restaurant (the address can often be critical in\n// geocoding). Fixing the underlying bug itself was easy, but fixing the\n// affected data is a little bit harder, hence the code here...\n\n// I ran: `\n//   UPDATE scrape\n//   SET data = data || '{\"is_geocoder_bug_fixed\": false}'\n//   WHERE source = 'yelp'\n// `\n// in order to keep track of which ones had been fixed\n\nexport class FixAddressBug {\n  static run() {\n    const yelp = new Yelp()\n    yelp.addBigJob('_reGeocodeScrapes', [])\n  }\n\n  static async reGeocodeScrapes(yelp: Yelp) {\n    const query = `\n      SELECT * FROM scrape\n        WHERE data->>'is_geocoder_bug_fixed' = 'false'\n        AND source = 'yelp'\n    `\n    console.log('Querying offending scrapes...')\n    const results = await scrape_db.query(query)\n    for (const row of results.rows) {\n      await yelp.runOnWorker('_reGeocodeOneScrape', [row.id])\n    }\n    process.exit(0)\n  }\n\n  static async reGeocodeOneScrape(id: string) {\n    let query: string\n    const scrape = await scrapeFindOneByUUID(id)\n    let restaurant_id: string\n    // @ts-ignore\n    if (scrape.is_geocoder_bug_fixed) {\n      console.log('Skipping already-fixed scrape: ' + scrape.id)\n      return\n    }\n    if (!scrape.data.json) {\n      console.warn('Yelp scrape without its `json` field, deleting: ' + scrape.id)\n      await FixAddressBug.deleteScrape(scrape.id)\n      return\n    }\n    console.log('Checking for bugged scrape: ' + scrape.id)\n    const deets = Yelp.getNameAndAddress(scrape as YelpScrape)\n    let [restaurant, geocoder_id] = await geocodeRestaurant(\n      deets.name,\n      deets.address,\n      scrape.location.lat,\n      scrape.location.lon\n    )\n    if (!restaurant) {\n      console.warn('Creating restaurant for bugged scrape: ' + scrape.id)\n      const data = {\n        name: deets.name,\n        address: deets.address,\n        location: {\n          type: 'Point',\n          coordinates: [scrape.location.lon, scrape.location.lat],\n        },\n        geocoder_id,\n      }\n      const [_restaurant] = await restaurantInsert([data])\n      restaurant = _restaurant\n    }\n    restaurant_id = restaurant.id\n    if (restaurant_id != scrape.restaurant_id) {\n      console.log('Fixing bugged scrape: ' + scrape.id)\n      console.log(`Good restaurant: ${restaurant_id}. Bad restaurant: ${scrape.restaurant_id}`)\n      query = `\n      UPDATE scrape SET\n        restaurant_id = '${restaurant.id}',\n        data = data || '{\"is_geocoder_bug_fixed\": true}'\n      WHERE id_from_source = '${scrape.id_from_source}'\n    `\n      await scrape_db.query(query)\n      console.log(`Bugged scrape fixed (${deets.name}): ${scrape.id}`)\n      // Delete incorrect restaurant???\n    } else {\n      console.log('Good scrape: ' + scrape.id)\n      query = `\n      UPDATE scrape SET\n        data = data || '{\"is_geocoder_bug_fixed\": true}'\n      WHERE id_from_source = '${scrape.id_from_source}'\n    `\n      await scrape_db.query(query)\n    }\n  }\n\n  static async deleteScrape(id: string | undefined) {\n    if (!id) {\n      throw new Error('Scrape without an ID')\n    }\n    const query = `DELETE FROM scrape WHERE id = '${id}'`\n    await scrape_db.query(query)\n  }\n}\n\nif (require.main === module) {\n  FixAddressBug.run()\n}\n", "export const ALL_SOURCES = [\n  'yelp',\n  'ubereats',\n  'infatuation',\n  'michelin',\n  'tripadvisor',\n  'doordash',\n  'grubhub',\n  'google',\n  'google_review_api',\n]\n", "import { sentryMessage } from '@dish/common'\n\nimport { DISH_DEBUG } from '../constants'\nimport { getSummary } from './getSummary'\nimport { Self } from './Self'\n\nconst presets = {\n  witty_guidebook: {\n    // this is 4 chars per token roughly\n    max_tokens: 150,\n    stop: ['\"\"\"'],\n    // not sure, we may want more temp?\n    // What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.\n    // We generally recommend altering this or top_p but not both.\n    temperature: 0,\n    top_p: 1,\n    // Number between 0 and 1 that penalizes new tokens based on their existing frequency in the text so far. Decreases the model's likelihood to repeat the same line verbatim\n    frequency_penalty: 0.5,\n    // Number between 0 and 1 that penalizes new tokens based on whether they appear in the text so far. Increases the model's likelihood to talk about new topics\n    // we actually want it to summarize\n    presence_penalty: 0,\n  },\n}\n\nexport const pre_prompt = `Summarize nicely the following as though you were a smart, wry Pixar food critic summarizing your visit to a restaurant:\n---\nSolid Vietnamese restaurant with pricing almost on par with Orange County! The interior is very spacious. The menu is extensive, lots of protein combinations for the staple dishes. Lovely vermicelli (b\u00FAn), pho, broken rice (com tam), and beef stew (bo kho). Seriously, is the SF version of Pho Lu (in Westminster, CA) or nah?! We shared the vermicelli with grilled chicken and shrimp ($10.75). The fish sauce was flavorful, albeit not spicy. The grilled chicken had a nice char to it, the noodles were still warm when we got home 30 minutes later. Overall, definitely would order again. Next time I'll skip the nearby boba places and get my boba here because their fruit shakes (including durian!) look delicious and c'mon, you know Viet places only use fresh, real fruit for them!\n\"\"\"\nSummary: Pricey but solid Vietnamese! Large menu, lots of protein combos, amazing bun, pho com tam, and bo kho. Of course fresh real fruit boba smoothies (including durian!). C'mon man! \n---\nHands down my favorite taco joint in San Francisco. I think this is one of the few, if not the only restaurant in SF that serves birria tacos -- they are delicious! The beef stew meat and broth on the side go so well together (remember to add the cheese!) The flavors are intense but not too overwhelming. Another plus: these are HUGE tacos; I can only eat 3 at a time. It's always packed. You order at the counter first then wait for a table to open up. You have to strategize and be quick but still be respectful of others - absolutely not a time to be shy. They throw in complimentary chips and salsa with your order that are honestly great. PS: They also have sangria to-go now. It was perfectly concocted!\n\"\"\"\nSummary: Top tier tacos. Big Birria tacos with amazing flavor (the cheese is a must!). Absolutel UNIT of a taco! Hard to get a table sometimes, order at the counter. Tips: Sangria is to-go now, and decent free chips and salsa.\n---\n`\n\nexport const post_prompt = `\n\"\"\"\nSummary:`\n\n// in order of most powerful => least\ntype OpenAIEngines = 'davinci' | 'curie' | 'babbage' | 'ada'\n\nexport class GPT3 {\n  crawler: Self\n\n  constructor(crawler: Self) {\n    this.crawler = crawler\n  }\n\n  async generateGPT3Summary() {\n    const is_in_sanfran = this.crawler.restaurant.address?.includes('Francisco')\n    const is_high_scoring = this.crawler.restaurant.score >= 700\n    const engine: OpenAIEngines = is_in_sanfran && is_high_scoring ? 'davinci' : 'curie'\n    this.crawler.log('Running GPT3 summariser for restaurant...', engine)\n    const highlights = await this.findHighlights()\n    const summary = await getSummary(highlights)\n    const completion = await this.complete(summary, engine)\n    this.crawler.restaurant.summary = completion\n  }\n\n  async findHighlights() {\n    const query = this._byDishCountQuery()\n    const result = await this.crawler.main_db.query(query)\n    const text = result.rows\n      .map((r) => r.text)\n      .join(' ')\n      .replaceAll('\\n', ' ')\n    return text\n  }\n\n  _bySummedSentimentQuery() {\n    return `\n      SELECT SUM(naive_sentiment), text FROM review\n      JOIN review_tag_sentence rts ON rts.review_id = review.id\n        WHERE review.restaurant_id = '${this.crawler.restaurant.id}'\n        AND LENGTH(text) < 1000\n      GROUP BY review.id\n      ORDER BY SUM(naive_sentiment) DESC LIMIT 6\n    `\n  }\n\n  _byDishCountQuery() {\n    return `\n      SELECT COUNT(rts.id), text FROM review\n      JOIN review_tag_sentence rts ON rts.review_id = review.id\n        WHERE review.restaurant_id = '${this.crawler.restaurant.id}'\n        AND LENGTH(text) < 1000\n      GROUP BY review.id\n      ORDER BY COUNT(rts.id) DESC LIMIT 6\n    `\n  }\n\n  async complete(input: string, engine: OpenAIEngines = 'curie', preset = 'witty_guidebook') {\n    let body = presets[preset]\n    body.prompt = `${pre_prompt}${input}${post_prompt}`\n    const request: RequestInit = {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        Authorization: 'Bearer ' + process.env.GPT3_KEY,\n      },\n      body: JSON.stringify(body),\n    }\n    if (DISH_DEBUG > 1) {\n      console.log('Requesting GPT3 summary...')\n      console.log(body.prompt)\n    }\n    const result = await fetch(`https://api.openai.com/v1/engines/${engine}/completions`, request)\n    const response: any = await result.json()\n    let answer = ''\n    if (!response.choices || response.choices.length == 0) {\n      console.error('GPT3 API error:', response)\n      sentryMessage('GPT3 API error', {\n        data: {\n          restaurant: this.crawler.restaurant.slug,\n          response,\n        },\n      })\n    } else {\n      answer = response.choices[0].text\n    }\n    if (DISH_DEBUG > 1) {\n      console.log('...GPT3 summary returned: ')\n      console.log(answer)\n    }\n    return answer\n  }\n}\n", "import { SUMMARIZER_API } from '@dish/graph'\n\nexport async function getSummary(of: string) {\n  const request: RequestInit = {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'text/plain',\n    },\n    body: of,\n  }\n  if (process.env.DISH_DEBUG) {\n    console.log('getting summary...', of)\n  }\n  const result = await fetch(`${SUMMARIZER_API}?ratio=0.1`, request)\n  const response: any = await result.json()\n  if (process.env.DISH_DEBUG) {\n    console.log('...summarized: ', response.summary)\n  }\n  return response.summary\n}\n", "import { deleteByIDs, globalTagId } from '@dish/graph'\n\nimport { getTableCount, photoBatchForAll } from '../utils'\nimport { Self } from './Self'\n\nexport async function remove404Images(internal: Self) {\n  let previous_id = globalTagId\n  let arrived = process.env.START_FROM ? false : true\n  let progress = 0\n  let page = 0\n  console.log('Counting photos...')\n  const count = await getTableCount('photo')\n  const PER_PAGE = 10000\n  console.log('Total photos: ' + count)\n  while (true) {\n    const results = await getFailableBatch(PER_PAGE, previous_id)\n    if (!results) {\n      return\n    }\n    if (results.length == 0) {\n      await internal.job.progress(100)\n      break\n    }\n    for (const result of results) {\n      previous_id = result.id as string\n      if (!arrived) {\n        if (result.id != process.env.START_FROM) {\n          continue\n        } else {\n          arrived = true\n        }\n      }\n      await internal.runOnWorker('checkMaybeDeletePhoto', [result.id, result.url])\n    }\n    page += 1\n    progress = ((page * PER_PAGE) / count) * 100\n    if (process.env.RUN_WITHOUT_WORKER != 'true') {\n      await internal.job.progress(progress)\n    } else {\n      console.log('Progress: ' + progress)\n    }\n  }\n}\n\nexport async function checkMaybeDeletePhoto(photo_id: string, url: string) {\n  if (!url) {\n    await deletePhoto(photo_id)\n    return\n  }\n  const result = await fetch(url)\n  const response = await result.text()\n  try {\n    const json = JSON.parse(response)\n    if (json.status == 404) {\n      await deletePhoto(photo_id)\n    }\n  } catch (e) {\n    if (!e.message.includes('Unexpected token')) {\n      if (e.message.includes('Unexpected end of JSON input')) {\n        await deletePhoto(photo_id)\n      } else {\n        console.error('Unexpected error for: ' + url)\n        throw e\n      }\n    }\n  }\n  console.log('Photo OK: ' + url)\n}\n\nasync function getFailableBatch(per_page: number, previous_id: string) {\n  const sleep = (ms: number) => new Promise((res) => setTimeout(res, ms))\n  let retries = 0\n  while (retries < 10) {\n    try {\n      return await photoBatchForAll(per_page, previous_id)\n    } catch (e) {\n      retries += 1\n      await sleep(5000)\n    }\n  }\n}\n\nasync function deletePhoto(id: string) {\n  console.log('Deleting photo ' + id)\n  await deleteByIDs('photo', [id])\n}\n\nif (require.main === module) {\n  ;(async () => {\n    const internal = new Self()\n    await internal.addBigJob('remove404Images', [])\n  })()\n}\n", "import { tagFindAll, tagFindOne } from '@dish/graph'\nimport { Loggable } from '@dish/worker'\n\nimport { Self } from './Self'\n\nconst REVIEW_BAND_FACTORS = { _5: 2, _4: 1, _3: 0, _2: -1, _1: -2 }\n\nexport class RestaurantBaseScore extends Loggable {\n  crawler: Self\n  breakdown: any = {}\n  gem_tag_id?: string\n\n  constructor(crawler: Self) {\n    super()\n    this.crawler = crawler\n  }\n\n  async calculateScore() {\n    this.log('Calculating scores...')\n    this.crawler.restaurant.score_breakdown = {}\n    this.breakdown.sources = {}\n    const all_sources = [...this.crawler.available_sources, 'dish', 'all']\n    const gem_tag = await tagFindOne({ slug: 'lenses__gems' })\n    if (!gem_tag?.id) {\n      console.log('all tags', await tagFindAll({}))\n      throw new Error(\"Couldn't find the 'lenses__gems' lense tag in DB\")\n    }\n    this.gem_tag_id = gem_tag.id\n    for (const source of all_sources) {\n      this.log('Generate breakdown for', source)\n      this.breakdown.sources[source] = { ratings: {}, summaries: {} } as any\n      if (source != 'dish' && source != 'all') {\n        await this.scoreFromExternalratings(source)\n      } else {\n        delete this.breakdown.sources['dish'].ratings\n      }\n      await this.generateSummaries(source)\n    }\n    this.log('Updating score from votes...')\n    await this.scoreFromVotes()\n    this.log('Updating score from photos...')\n    await this.scoreFromPhotos()\n    this.sumScores()\n    this.crawler.restaurant.source_breakdown = this.breakdown\n    this.upvotesDownvotes()\n  }\n\n  upvotesDownvotes() {\n    const upvotes =\n      this.breakdown.sources.all.ratings['_4'].score +\n      this.breakdown.sources.all.ratings['_5'].score +\n      this.breakdown.votes.upvotes +\n      this.breakdown.photos.score\n    const downvotes =\n      -(\n        this.breakdown.sources.all.ratings['_1'].score +\n        this.breakdown.sources.all.ratings['_2'].score\n      ) + this.breakdown.votes.downvotes\n    this.crawler.restaurant.upvotes = upvotes\n    this.crawler.restaurant.downvotes = downvotes\n    this.crawler.restaurant.votes_ratio = upvotes / (downvotes + upvotes)\n    this.log(\n      `upvotesDownvotes: ${upvotes} / ${downvotes} (votes_ratio: ${this.crawler.restaurant.votes_ratio})`\n    )\n  }\n\n  async scoreFromPhotos() {\n    const PHOTO_SCORE_FACTOR = 0.1\n    const PHOTO_QUALITY_CRITERIA = 5.25\n    const id = this.crawler.restaurant.id\n    const result = await this.crawler.main_db.query(`\n      SELECT count(DISTINCT p.id) FROM photo_xref px\n      JOIN photo p ON px.photo_id = p.id\n        WHERE px.restaurant_id = '${this.crawler.restaurant.id}'\n        AND p.quality > ${PHOTO_QUALITY_CRITERIA}\n    `)\n    const count = parseInt(result.rows[0].count)\n    const score = count * PHOTO_SCORE_FACTOR\n    this.breakdown.photos = {\n      critera: PHOTO_QUALITY_CRITERIA,\n      score_factor: PHOTO_SCORE_FACTOR,\n      meeting_criteria_count: count,\n      score,\n    }\n  }\n\n  async scoreFromVotes() {\n    const PHOTO_SCORE_FACTOR = 0.1\n    const PHOTO_QUALITY_CRITERIA = 5.25\n    const result = await this.crawler.main_db.query(`\n      WITH votes AS (\n        SELECT vote FROM review\n        WHERE restaurant_id = '${this.crawler.restaurant.id}'\n      )\n      SELECT\n        (\n          SELECT COUNT(vote) FROM votes WHERE vote > 0\n        ) AS upvotes,\n        (\n          SELECT COUNT(vote) FROM votes WHERE vote < 0\n        ) AS downvotes\n    `)\n    const row = result.rows[0]\n    const upvotes = parseInt(row.upvotes)\n    const downvotes = parseInt(row.downvotes)\n    const total = upvotes + downvotes\n    this.breakdown.votes = {\n      upvotes,\n      downvotes,\n      score: total,\n    }\n  }\n\n  async scoreFromExternalratings(source: string) {\n    const result = await this.crawler.main_db.query(`\n      SELECT\n        (\n          SELECT count(*) FROM review\n          WHERE restaurant_id = '${this.crawler.restaurant.id}'\n          AND source = '${source}'\n          AND rating >= 4.75\n        ) as _5,\n        (\n          SELECT count(*) FROM review\n          WHERE restaurant_id = '${this.crawler.restaurant.id}'\n          AND source = '${source}'\n          AND rating >= 4 AND rating <= 4.75\n        ) as _4,\n        (\n          SELECT count(*) FROM review\n          WHERE restaurant_id = '${this.crawler.restaurant.id}'\n          AND source = '${source}'\n          AND rating >= 3 AND rating <= 4\n        ) as _3,\n        (\n          SELECT count(*) FROM review\n          WHERE restaurant_id = '${this.crawler.restaurant.id}'\n          AND source = '${source}'\n          AND rating >= 2 AND rating <= 3\n        ) as _2,\n        (\n          SELECT count(*) FROM review\n          WHERE restaurant_id = '${this.crawler.restaurant.id}'\n          AND source = '${source}'\n          AND rating >= 0 AND rating <= 2\n        ) as _1\n    `)\n    this.breakdown.sources[source] = { ratings: {} } as any\n    const row = result.rows[0]\n    let total = 0\n    for (const band in REVIEW_BAND_FACTORS) {\n      const factor = REVIEW_BAND_FACTORS[band]\n      const count = parseInt(row[band])\n      const score = count * factor\n      total += score\n      this.breakdown.sources[source].ratings[band] = {\n        count,\n        score,\n      }\n    }\n    this.breakdown.sources[source].ratings.score = total\n  }\n\n  sumScores() {\n    const sources_total = this.sumSources()\n    let total_score = 0\n    total_score += sources_total\n    total_score += this.breakdown.photos.score\n    total_score += this.breakdown.votes.score\n    this.crawler.restaurant.score = total_score\n  }\n\n  sumSources() {\n    this.breakdown.sources['all'].ratings = { score: 0 }\n    for (const band in REVIEW_BAND_FACTORS) {\n      this.breakdown.sources['all'].ratings[band] = {\n        count: 0,\n        score: 0,\n      }\n    }\n    let sources_total = 0\n    for (const source of this.crawler.available_sources) {\n      this.sumReviewBands(source)\n      const source_total = this.breakdown.sources[source].ratings.score\n      this.breakdown.sources['all'].ratings.score += source_total\n      sources_total += source_total\n    }\n    return sources_total\n  }\n\n  sumReviewBands(source: string) {\n    for (const band in REVIEW_BAND_FACTORS) {\n      const band_object = this.breakdown.sources[source].ratings[band]\n      this.breakdown.sources['all'].ratings[band]['count'] += band_object.count\n      this.breakdown.sources['all'].ratings[band]['score'] += band_object.score\n    }\n  }\n\n  async generateSummaries(source: string) {\n    const sub_query_name = source + '_'\n    const result = await this.crawler.main_db.query(`\n      SELECT json_build_object(\n        'reviews', json_build_object(\n          'best', (SELECT text FROM (\n            ${this.notableReviewSQL('best', source)}\n          ) ${sub_query_name}_best ),\n          'worst', (SELECT text FROM (\n            ${this.notableReviewSQL('worst', source)}\n          ) ${sub_query_name}_worst )\n        ),\n        'sentences', json_build_object(\n          'best', (\n            ${this.notableSentencesSQL('best', source)}\n          ),\n          'worst', (\n            ${this.notableSentencesSQL('worst', source)}\n          )\n        ),\n        'unique_tags', (${this.uniqueTagsSQL(source)})\n      )\n    `)\n    const summaries = result.rows[0].json_build_object\n    this.breakdown.sources[source].summaries = summaries\n  }\n\n  notableReviewSQL(type: string, source: string) {\n    const source_sql = source != 'all' ? `AND source = '${source}'` : ''\n    const order = type == 'best' ? 'DESC' : 'ASC'\n    return `\n      SELECT SUM(rts.naive_sentiment) AS total_sentiment, text FROM review\n      JOIN review_tag_sentence rts ON rts.review_id = review.id\n        WHERE review.restaurant_id = '${this.crawler.restaurant.id}'\n        ${source_sql}\n      GROUP BY review.id\n      ORDER BY total_sentiment ${order} NULLS LAST\n      LIMIT 1\n    `\n  }\n\n  notableSentencesSQL(type: string, source: string) {\n    const source_sql = source != 'all' ? `AND source = '${source}'` : ''\n    const order = type == 'best' ? 'DESC' : 'ASC'\n    const filter = type == 'best' ? '> 0' : '< 0'\n    const sub_query_name = source + '_notable_sentences'\n    return `\n      SELECT json_agg(${sub_query_name}.sentence) FROM (\n        SELECT DISTINCT sentence, naive_sentiment FROM review_tag_sentence rts\n        JOIN review ON rts.review_id = review.id\n          WHERE review.restaurant_id = '${this.crawler.restaurant.id}'\n          AND ml_sentiment ${filter}\n          ${source_sql}\n        ORDER BY naive_sentiment ${order} NULLS LAST\n        LIMIT 2\n      ) ${sub_query_name}\n    `\n  }\n\n  uniqueTagsSQL(source: string) {\n    const source_sql = source != 'all' ? `AND source = '${source}'` : ''\n    const sub_query_name = source + '_unique_tags'\n    return `\n      SELECT json_agg(${sub_query_name}) FROM (\n        SELECT id, name FROM tag\n        WHERE id IN (\n          SELECT DISTINCT tag_id FROM review_tag_sentence\n          WHERE sentence IN (\n            SELECT DISTINCT sentence FROM review_tag_sentence rts\n            JOIN review ON rts.review_id = review.id\n            JOIN tag ON rts.tag_id = tag.id\n              WHERE review.restaurant_id = '${this.crawler.restaurant.id}'\n              AND rts.tag_id = '${this.gem_tag_id}'\n              ${source_sql}\n          )\n        )\n        AND id != '${this.gem_tag_id}'\n      ) ${sub_query_name}\n    `\n  }\n}\n", "import _ from 'lodash'\n\nimport { DISH_DEBUG } from '../constants'\nimport { scrapeGetData } from '../scrape-helpers'\nimport { Self } from './Self'\n\n// Note that there is no unit or reference point for these values. All that\n// matters is simply the relative differences between them. For example therefore\n// there is no need to ensure that the maximum value is 1.0 or 100%.\nexport const RESTAURANT_WEIGHTS = {\n  yelp: 0.6,\n  tripadvisor: 0.6,\n  michelin: 1.0,\n  infatuation: 0.9,\n  ubereats: 0.2,\n  doordash: 0.2,\n  grubhub: 0.2,\n  google: 0.4,\n}\n\nexport class RestaurantRatings {\n  crawler: Self\n\n  constructor(crawler: Self) {\n    this.crawler = crawler\n  }\n\n  getRatings() {\n    const rating = (r: any) => (typeof r === 'string' ? +r : r ?? null)\n    const ratings = {\n      yelp: rating(scrapeGetData(this.crawler.yelp, (x) => x.json.aggregateRating.ratingValue)),\n      ubereats: rating(scrapeGetData(this.crawler.ubereats, (x) => x.main.rating.ratingValue)),\n      infatuation: rating(this._infatuationRating()),\n      tripadvisor: rating(\n        scrapeGetData(this.crawler.tripadvisor, (x) => x.overview.rating.primaryRating)\n      ),\n      michelin: rating(this._getMichelinRating()),\n      doordash: rating(this._doorDashRating()),\n      grubhub: rating(scrapeGetData(this.crawler.grubhub, (x) => x.main.rating.rating_value)),\n\n      // Temporary hack to get the Google rating by averaging the google reviews we scraped\n      google: rating(\n        scrapeGetData(this.crawler.google_review_api, (x) => {\n          const ratings = x.reviews.map((r) => parseFloat(r.rating))\n          const avg = _.mean(ratings)\n          return avg\n        })\n      ),\n    }\n    return {\n      rating: this.weightRatings(ratings, RESTAURANT_WEIGHTS),\n      ratings,\n    }\n  }\n\n  _infatuationRating() {\n    const rating = scrapeGetData(this.crawler.infatuation, (x) =>\n      parseFloat(x.data_from_search_list_item.post.rating || '0')\n    )\n    if (rating < 0) return null\n    return rating / 2\n  }\n\n  _doorDashRating() {\n    const rating = scrapeGetData(\n      this.crawler.doordash,\n      (x) => x.main.averageRating ?? x.main.rating.ratingValue\n    )\n    return rating == 0 ? null : rating\n  }\n\n  weightRatings(\n    ratings: { [source: string]: number | null },\n    master_weights: { [source: string]: number }\n  ) {\n    const weights: { [source: string]: number } = {}\n    let total_weight = 0\n    let final_rating = 0\n    const denulledRatings: { [source: string]: number } = {}\n\n    for (const source in ratings) {\n      const rating = ratings[source]\n      // rating === 0 should be impossible and mean no votes at all, so ignore that too\n      if (Number.isNaN(rating) || typeof rating !== 'number' || rating === 0) {\n        continue\n      } else {\n        weights[source] = master_weights[source]\n        denulledRatings[source] = rating\n        total_weight += master_weights[source]\n      }\n    }\n\n    for (const source in denulledRatings) {\n      const rating = denulledRatings[source]\n      const normalised_weight = weights[source] / total_weight\n      final_rating += rating * normalised_weight\n    }\n\n    if (DISH_DEBUG > 1) {\n      console.log('Calculated final rating', { final_rating, total_weight, ratings, weights })\n    }\n\n    return final_rating\n  }\n\n  private _getMichelinRating() {\n    const rating = scrapeGetData(this.crawler.michelin, (x) => x.main.michelin_award)\n    if (rating == '') {\n      return NaN\n    }\n    switch (rating) {\n      case 'ONE_STAR':\n        return 4.8\n      case 'TWO_STARS':\n        return 4.9\n      case 'THREE_STARS':\n        return 5.0\n      default:\n        return 4.7\n    }\n  }\n}\n", "import { sentryException, sentryMessage } from '@dish/common'\nimport { ReviewTagSentence } from '@dish/graph'\nimport { bertResultToNumber, fetchBertSentiment } from '@dish/helpers'\nimport { Loggable } from '@dish/worker'\nimport { chunk } from 'lodash'\n\nimport { ALL_SOURCES } from './ALL_SOURCES'\nimport { Self } from './Self'\n\nconst BERT_NEGATIVE_SENTIMENT_CRITERIA = -0.999\n\nconst TAG_SCORE_ALL_SOURCES = [...ALL_SOURCES, 'dish']\n\nexport class RestaurantTagScores extends Loggable {\n  crawler: Self\n  breakdown: any = {}\n  total_sentences = 0\n  current_sentence = 0\n\n  constructor(crawler: Self) {\n    super()\n    this.crawler = crawler\n  }\n\n  async calculateScores() {\n    const unanalysed = await this.findAllUnanalyzed()\n    this.total_sentences = unanalysed.length\n    this.crawler.log(`Starting Bert sentiment requests (${this.total_sentences} to analyze)...`)\n    const analyzed = await this.analyzeSentences(unanalysed)\n    await this.updateAnalyzed(analyzed)\n    this.crawler.log(`... ${analyzed.length} Bert sentiment requests done`)\n    await this.updateRestaurantTagScores()\n  }\n\n  async findAllUnanalyzed() {\n    this.crawler.log('Finding unanalyzed...')\n    const restaurant_id = this.crawler.restaurant.id\n    const result = await this.crawler.main_db.query(`\n      SELECT rts.id, sentence FROM review_tag_sentence rts\n      JOIN review r ON r.id = rts.review_id\n        WHERE r.restaurant_id = '${restaurant_id}'\n        AND ml_sentiment IS NULL\n    `)\n    return result.rows as ReviewTagSentence[]\n  }\n\n  async analyzeSentences(review_tag_sentences: ReviewTagSentence[]) {\n    const BERT_BATCH_SIZE = 30\n    let assessed: ReviewTagSentence[] = []\n    const batches = chunk(review_tag_sentences, BERT_BATCH_SIZE)\n    for (const [index, batch] of batches.entries()) {\n      this.log('Analyzing sentiment for batch', index, 'of ', batches.length)\n      const assessed_batch = await this.getBertSentimentBatch(batch)\n      assessed.push(...assessed_batch)\n    }\n    return assessed\n  }\n\n  async getBertSentimentBatch(review_tag_sentences: ReviewTagSentence[]) {\n    let completed = await Promise.all(review_tag_sentences.map((rts) => this.getBertSentiment(rts)))\n    return completed.filter(Boolean) as ReviewTagSentence[]\n  }\n\n  async getBertSentiment(review_tag_sentence: ReviewTagSentence) {\n    if (!review_tag_sentence.sentence) return\n    this.current_sentence = this.current_sentence + 1\n    const result = await this.fetchBertSentimentWithRetries(review_tag_sentence.sentence)\n    if (!result) return\n    return {\n      id: review_tag_sentence.id,\n      ml_sentiment: bertResultToNumber(result),\n    }\n  }\n\n  async updateAnalyzed(review_tag_sentences: ReviewTagSentence[]) {\n    // do granularly to avoid timeouts\n    for (const rts of review_tag_sentences) {\n      await this.crawler.main_db.query(`\n        UPDATE review_tag_sentence\n        SET ml_sentiment = '${rts.ml_sentiment}'\n        WHERE id = '${rts.id}';\n      `)\n    }\n  }\n\n  async fetchBertSentimentWithRetries(text: string) {\n    const MAX_RETRIES = 5\n    let retries = 0\n    while (true) {\n      try {\n        return await fetchBertSentiment(text)\n      } catch (error) {\n        if (!error.message.includes('json')) {\n          sentryException(error, {\n            data: {\n              function: 'fetchBertSentimentWithRetries',\n              restaurant: this.crawler.restaurant.id,\n            },\n            logger: this.log,\n          })\n          return\n        }\n        retries += 1\n        if (retries > MAX_RETRIES) {\n          this.crawler.log('Failed Bert sentiment request: ' + error.message)\n          sentryMessage(MAX_RETRIES + ' failed attempts requesting Bert API', {\n            data: {\n              text: text,\n            },\n          })\n          return\n        }\n        this.log(\n          `Retrying Bert sentiment API: ${retries}/${MAX_RETRIES}. ` +\n            `Sentence ${this.current_sentence}/${this.total_sentences}`\n        )\n      }\n    }\n  }\n\n  async updateRestaurantTagScores() {\n    this.log('Updating tag scores...')\n    const tags = this.crawler.tagging.found_tags // TODO: query DB for all rish tag IDs??\n    for (const tag_id in tags) {\n      const all_sources_score_sql = this._scoreSQL(tag_id)\n      const breakdown_sql = this.generateBreakdownSQL(tag_id)\n      const mention_count_sql = this.generateMentionsCountSQL(tag_id)\n      const updown_sql = this.generateUpDownSQL()\n      // one at a time to avoid timeouts\n      await this.crawler.main_db.query(\n        `\n        WITH\n        breakdown_builder AS (\n          ${breakdown_sql}\n        ),\n        updown AS (\n          ${updown_sql}\n        )\n        UPDATE restaurant_tag SET\n          score = (${all_sources_score_sql}),\n          source_breakdown = (SELECT breakdown FROM breakdown_builder),\n          review_mentions_count = (${mention_count_sql}),\n          upvotes = (SELECT upvotes FROM updown),\n          downvotes = (SELECT downvotes FROM updown),\n          votes_ratio = (\n            SELECT NULLIF(upvotes, 0) / NULLIF(downvotes + upvotes, 0)\n            FROM updown\n          )\n        WHERE restaurant_id = '${this.crawler.restaurant.id}'\n        AND tag_id = '${tag_id}';\n      `\n      )\n    }\n  }\n\n  _scoreSQL(tag_id: string, source: string | undefined = undefined) {\n    return `\n      SELECT\n        COALESCE((${this._scoreFromSentimentSQL(tag_id, source)}), 0)\n        +\n        COALESCE((${this._scoreFromVotesSQL(tag_id, source)}), 0)\n    `\n  }\n\n  _scoreFromSentimentSQL(tag_id: string, source: string | undefined = undefined) {\n    if (source) {\n      source = `AND review.source = '${source}'`\n    } else {\n      source = ''\n    }\n    return `\n      SELECT ROUND(SUM(averaged_ml_sentiment)) FROM (\n        SELECT AVG(ml_sentiment) AS averaged_ml_sentiment FROM review_tag_sentence\n        JOIN review ON review.id = review_tag_sentence.review_id\n          AND review.restaurant_id = '${this.crawler.restaurant.id}'\n          AND review_tag_sentence.tag_id = '${tag_id}'\n          ${source}\n        GROUP BY review.id\n      ) AS score_from_sentiment\n    `\n  }\n\n  _scoreFromVotesSQL(tag_id: string, source: string | undefined = undefined) {\n    if (source) {\n      source = `AND source = '${source}'`\n    } else {\n      source = ''\n    }\n    return `\n      SELECT SUM(vote) FROM review\n        WHERE restaurant_id = '${this.crawler.restaurant.id}'\n        AND tag_id = '${tag_id}'\n        ${source}\n    `\n  }\n\n  generateBreakdownSQL(tag_id: string) {\n    let sources_sql: string[] = []\n    for (const source of TAG_SCORE_ALL_SOURCES) {\n      const source_sql = `\n        '${source}', json_build_object(\n          'score',\n          (${this.sqlForPerSourceScore(tag_id, source)}),\n          'upvotes',\n          (${this.sqlForPerSourceSentiment(tag_id, source, '> 0')}),\n          'downvotes',\n          (${this.sqlForPerSourceSentiment(\n            tag_id,\n            source,\n            '< ' + BERT_NEGATIVE_SENTIMENT_CRITERIA\n          )}),\n          'summary', json_build_object(\n            'positive',\n            (${this.sqlForPerSourceSummary(tag_id, source, 'postive')}),\n            'negative',\n            (${this.sqlForPerSourceSummary(tag_id, source, 'negative')})\n          )\n        )`\n      sources_sql.push(source_sql)\n    }\n    const all = `\n      SELECT json_build_object(\n        ${sources_sql.join(',')}\n      )::jsonb AS breakdown\n    `\n    return all\n  }\n\n  generateMentionsCountSQL(tag_id: string) {\n    return `\n      SELECT count(*) FROM review_tag_sentence rts\n      JOIN review ON rts.review_id = review.id\n        WHERE review.restaurant_id = '${this.crawler.restaurant.id}'\n        AND rts.tag_id = '${tag_id}'\n    `\n  }\n\n  sqlForPerSourceScore(tag_id: string, source: string) {\n    return this._scoreSQL(tag_id, source)\n  }\n\n  sqlForPerSourceSentiment(tag_id: string, source: string, sentiment_criteria: string) {\n    if (source) {\n      source = `AND source = '${source}'`\n    } else {\n      source = ''\n    }\n    return `\n      SELECT COUNT(DISTINCT review_id) FROM review_tag_sentence\n      JOIN review ON review.id = review_tag_sentence.review_id\n        WHERE review.restaurant_id = '${this.crawler.restaurant.id}'\n        AND review_tag_sentence.tag_id = '${tag_id}'\n        ${source}\n        AND review_tag_sentence.ml_sentiment ${sentiment_criteria}\n    `\n  }\n\n  sqlForPerSourceSummary(tag_id: string, source: string, vector: string) {\n    const order = vector == 'postive' ? 'DESC' : 'ASC'\n    const vector_filter = vector == 'postive' ? '> 0' : '< ' + BERT_NEGATIVE_SENTIMENT_CRITERIA\n    const sub_query_name = `${source}_summaries`\n    if (source) {\n      source = `AND source = '${source}'`\n    } else {\n      source = ''\n    }\n    return `\n      SELECT json_agg(${sub_query_name}.sentence) FROM (\n        SELECT sentence FROM review_tag_sentence\n        JOIN review ON review.id = review_tag_sentence.review_id\n          WHERE review.restaurant_id = '${this.crawler.restaurant.id}'\n          AND review_tag_sentence.tag_id = '${tag_id}'\n          ${source}\n          AND ml_sentiment ${vector_filter}\n        ORDER BY naive_sentiment ${order} NULLS LAST\n        LIMIT 2\n      ) ${sub_query_name}\n    `\n  }\n\n  generateUpDownSQL() {\n    let ups: string[] = []\n    let downs: string[] = []\n    for (const source of TAG_SCORE_ALL_SOURCES) {\n      ups.push(`(breakdown->'${source}'->'upvotes')::numeric`)\n      downs.push(`(breakdown->'${source}'->'downvotes')::numeric`)\n    }\n    return `\n      SELECT\n        *,\n        (SELECT NULLIF(upvotes, 0) / NULLIF(upvotes + downvotes, 0)) AS ratio\n        FROM (\n          SELECT\n            (\n              SELECT ${ups.join('+')}\n            ) AS upvotes,\n            (\n              SELECT ${downs.join('+')}\n            ) AS downvotes\n          FROM breakdown_builder\n        ) s\n    `\n  }\n}\n", "import { sentryMessage } from '@dish/common'\nimport {\n  PhotoXref,\n  RestaurantTag,\n  Review,\n  Tag,\n  convertSimpleTagsToRestaurantTags,\n  externalUserUUID,\n  globalTagId,\n  restaurantGetAllPossibleTags,\n  tagFindCountryMatches,\n} from '@dish/graph'\nimport { breakIntoSentences, doesStringContainTag, isPresent } from '@dish/helpers'\nimport {\n  cleanReviewText,\n  dedupeReviews,\n  dedupeSentiments,\n  reviewExternalUpsert,\n} from '@dish/helpers-node'\nimport { Loggable } from '@dish/worker'\nimport * as chrono from 'chrono-node'\nimport { chunk, uniq } from 'lodash'\nimport moment from 'moment'\nimport Sentiment from 'sentiment'\n\nimport { DISH_DEBUG } from '../constants'\nimport { scrapeGetData } from '../scrape-helpers'\nimport { toDBDate } from '../utils'\nimport { Self } from './Self'\n\ntype TextSource = Review | string\ntype PhotoWithText = { url: string; text: string }\n\nconst isReview = (variableToCheck: any): variableToCheck is Review =>\n  (variableToCheck as Review).text !== undefined\n\nexport const GEM_UIID = 'da0e0c85-86b5-4b9e-b372-97e133eccb43'\n\nexport class Tagging extends Loggable {\n  crawler: Self\n  restaurant_tags: Partial<RestaurantTag>[] = []\n  restaurant_tag_ratings: {\n    [key: string]: number[]\n  } = {}\n  all_tags: Tag[] = []\n  found_tags: { [key: string]: Partial<Tag> } = {}\n  SPECIAL_FILTER_THRESHOLD = 3\n  naive_sentiment = new Sentiment()\n  all_reviews: Review[] = []\n\n  get logName() {\n    return `Tagging ${this.crawler.restaurant?.name}`\n  }\n\n  constructor(crawler: Self) {\n    super()\n    this.crawler = crawler\n  }\n\n  async main() {\n    const yelps = scrapeGetData(\n      this.crawler.yelp,\n      (x) => x.data_from_search_list_item.categories,\n      []\n    ).map((c) => c.title)\n    const tripadvisors = scrapeGetData(\n      this.crawler.tripadvisor,\n      (x) => x.overview.detailCard.tagTexts.cuisines.tags,\n      []\n    ).map((c) => c.tagValue)\n    const tags = uniq([...yelps, ...tripadvisors])\n    this.log(`Tags minus orphans: yelp (${yelps.length}), tripadvisor (${tripadvisors.length})`)\n    const orphan_tags = await this.upsertCountryTags(tags)\n    if (orphan_tags.length) {\n      await this.addSimpleTags(orphan_tags)\n    }\n    this.tagIfGem()\n  }\n\n  tagIfGem() {\n    if (this.crawler.restaurant.rating > 4) {\n      this.restaurant_tags.push({\n        tag_id: GEM_UIID,\n        restaurant_id: this.crawler.restaurant.id,\n      })\n    }\n  }\n\n  async addSimpleTags(tags: string[]) {\n    this.addRestaurantTags(await convertSimpleTagsToRestaurantTags(tags))\n  }\n\n  addRestaurantTags(restaurant_tags: Partial<RestaurantTag>[]) {\n    this.restaurant_tags = [\n      ...this.restaurant_tags,\n      ...restaurant_tags.map((tag) => ({\n        restaurant_id: this.crawler.restaurant.id,\n        ...tag,\n      })),\n    ]\n  }\n\n  async upsertCountryTags(tags: string[]) {\n    this.crawler.resetTimer()\n    const country_tags = await tagFindCountryMatches(tags)\n    this.addRestaurantTags(\n      country_tags.map((tag: Tag) => {\n        return {\n          tag_id: tag.id,\n          restaurant_id: this.crawler.restaurant.id,\n        } as RestaurantTag\n      })\n    )\n    const orphan_tags = this._extractOrphanTags(tags, country_tags)\n    this.crawler.log('upsert country tags')\n    return orphan_tags\n  }\n\n  _extractOrphanTags(tags: string[], country_tags: Tag[]) {\n    return tags.filter((tag) => {\n      const is_a_country_name = country_tags.find((ct) => {\n        const is_common_name_match = ct.name == tag\n        const is_alternate_name_match = (ct.alternates || ['']).includes(tag)\n        return is_common_name_match || is_alternate_name_match\n      })\n      return !is_a_country_name\n    })\n  }\n\n  async updateTagRankings() {\n    const all_tags = this.crawler.restaurant.tags || []\n    const chunks = chunk(all_tags, 30)\n    this.log('Update tag rankings chunks', chunks.length)\n    for (const chunk of chunks) {\n      await Promise.all(\n        chunk.map((tag) => {\n          return this.promisedRankForTag(tag.tag.id)\n        })\n      )\n    }\n  }\n\n  async promisedRankForTag(tag_id: string) {\n    const rank = await this.getRankForTag(tag_id)\n    const existing = this.restaurant_tags.find((rt) => rt.tag_id == tag_id)\n    if (existing) {\n      existing.rank = rank\n    } else {\n      const tag = {\n        tag_id,\n        restaurant_id: this.crawler.restaurant.id,\n        rank,\n      }\n      this.restaurant_tags.push(tag)\n    }\n  }\n\n  async getRankForTag(tag_id: string) {\n    const RADIUS = 0.1\n    const result = await this.crawler.main_db.query(`\n    SELECT * FROM (\n      SELECT\n        restaurant.id AS restaurant_id,\n        DENSE_RANK() OVER(ORDER BY rt.score DESC NULLS LAST) AS rank\n      FROM restaurant\n      LEFT JOIN restaurant_tag rt ON rt.restaurant_id = restaurant.id\n        WHERE ST_DWithin(location, location, ${RADIUS})\n        AND rt.tag_id = '${tag_id}'\n    ) league\n    WHERE restaurant_id = '${this.crawler.restaurant.id}'`)\n    if (result.rows.length == 0) {\n      sentryMessage('No rank for tag', {\n        data: {\n          restaurant_id: this.crawler.restaurant.id,\n          tag_id: tag_id,\n        },\n      })\n    }\n    const rank = parseInt(result.rows[0].rank)\n    return rank\n  }\n\n  async scanCorpus() {\n    this.found_tags = {}\n    this.log('Getting all possible tags...')\n    this.all_tags = await restaurantGetAllPossibleTags(this.crawler.restaurant)\n    this.restaurant_tag_ratings = {}\n    this.all_reviews = [\n      ...this._getYelpReviews(),\n      ...this._getTripadvisorReviews(),\n      ...this._getGoogleReviews(),\n    ] as Review[]\n    this.log(`Got reviews ${this.all_reviews.length}...`)\n    const allSources = this.cleanAllSources([...this.all_reviews, ...this._scanMenuItemsForTags()])\n    const reviews_with_sentiments = this.findDishesInText(allSources)\n    this.log('Collecting restaurant tags...')\n    await this.collectFoundRestaurantTags()\n    this.log('Upserting reviews...')\n    try {\n      await reviewExternalUpsert(reviews_with_sentiments)\n    } catch (err) {\n      console.log('upserting failed for', reviews_with_sentiments)\n      throw err\n    }\n  }\n\n  cleanAllSources(sources: TextSource[]) {\n    return sources\n      .map((s) => {\n        if (!s) return\n        if (isReview(s)) {\n          s.text = cleanReviewText(s.text)\n        } else {\n          s = cleanReviewText(s) as string\n        }\n        return s\n      })\n      .filter(isPresent)\n  }\n\n  async collectFoundRestaurantTags() {\n    for (const tag_id of Object.keys(this.restaurant_tag_ratings)) {\n      this.restaurant_tags.push({\n        tag_id,\n        restaurant_id: this.crawler.restaurant.id,\n      })\n    }\n  }\n\n  async findPhotosForTags() {\n    const possibleTags = await restaurantGetAllPossibleTags(this.crawler.restaurant)\n    const tagPhotos: Partial<PhotoXref>[] = []\n    const photos = await this.getPhotosWithText()\n    this.log(`Found ${photos.length} photos with captions for tags`)\n    if (!photos.length) {\n      return []\n    }\n    for (const tag of possibleTags) {\n      const rtag = {\n        tag_id: tag.id,\n        restaurant_id: this.crawler.restaurant.id,\n        photos: [] as string[],\n      }\n      let atLeastOnePhoto = false\n      for (const photo of photos) {\n        if (!photo.text) {\n          continue\n        }\n        if (doesStringContainTag(photo.text, tag)) {\n          atLeastOnePhoto = true\n          tagPhotos.push({\n            restaurant_id: this.crawler.restaurant.id,\n            tag_id: tag.id,\n            photo: {\n              url: photo.url,\n            } as any,\n          })\n        }\n      }\n      if (atLeastOnePhoto) {\n        this.restaurant_tags.push(rtag)\n      }\n    }\n    this.log(`Added ${tagPhotos.length} tag photos`)\n    return tagPhotos\n  }\n\n  async getPhotosWithText() {\n    let photos: PhotoWithText[] = []\n\n    if (this.crawler.yelp?.data.photosp0) {\n      const photoData = this.crawler.getPaginatedDataNumberedKeys(this.crawler.yelp.data, 'photos')\n      this.log(`Yelp main photos: ${photoData.length}`)\n      for (const item of photoData) {\n        if (item.caption) {\n          photos.push({\n            url: item.url,\n            text: item.caption,\n          })\n        }\n      }\n    }\n\n    if (this.crawler.yelp?.data?.reviewsp0) {\n      const reviewPhotos = (\n        await Promise.all(\n          this.crawler\n            .getPaginatedDataNumberedKeys(this.crawler.yelp.data, 'reviews')\n            .flatMap((x) => x.photos)\n            .map(async (item) => {\n              const photo = item.src\n              if (!photo) {\n                return null\n              }\n              if (photo.includes('180s')) {\n                // skip lower res images\n                return\n              }\n              if (item.caption) {\n                // TODO put this high res logic somewhere and use in regular photos\n                // replace with bigger image\n                const largeResUrl = photo.replace('300s', '1000s').replace('348s', '1000s')\n                const largeResExists = await fetch(largeResUrl).then((res) => res.status === 200)\n                const url = largeResExists ? largeResUrl : photo\n                return {\n                  url,\n                  text: item.caption,\n                } as PhotoWithText\n              }\n            })\n        )\n      ).filter(isPresent)\n      this.log(`Yelp review photos: ${reviewPhotos.length}`)\n      photos = [...photos, ...reviewPhotos]\n      const tripAdvisorPhotos =\n        scrapeGetData(this.crawler.tripadvisor, (x) => x.photos_with_captions) || []\n      this.log(`Tripadvisor photos with captions ${tripAdvisorPhotos.length}`)\n      for (const item of tripAdvisorPhotos) {\n        if (item.caption) {\n          photos.push({\n            url: item.url,\n            text: item.caption,\n          })\n        }\n      }\n    }\n\n    return photos\n  }\n\n  findDishesInText(allSources: TextSource[]) {\n    let text: string\n    let reviews: Review[] = []\n    for (let source of allSources) {\n      if (!isReview(source)) {\n        text = source\n      } else {\n        text = source.text ?? ''\n      }\n      for (const tag of this.all_tags) {\n        if (doesStringContainTag(text, tag)) {\n          source = this.tagFound(tag, source)\n        }\n      }\n      if (isReview(source)) {\n        reviews.push(source)\n      }\n    }\n    return dedupeReviews(reviews)\n  }\n\n  tagFound(tag: Tag, text_source: TextSource) {\n    let text: string\n    if (isReview(text_source)) {\n      text_source.sentiments = text_source.sentiments ?? []\n      text = text_source.text ?? ''\n    } else {\n      text = text_source as string\n    }\n    this.found_tags[tag.id] = tag\n    this.restaurant_tag_ratings[tag.id] = this.restaurant_tag_ratings[tag.id] || []\n    const sentences = breakIntoSentences(text)\n    for (const sentence of sentences) {\n      if (!doesStringContainTag(sentence, tag)) continue\n      const rating = this.measureSentiment(sentence)\n      this.restaurant_tag_ratings[tag.id].push(rating)\n      if (isReview(text_source)) {\n        const sentiment: any = {\n          tag_id: tag.id,\n          restaurant_id: this.crawler.restaurant.id,\n          sentence,\n          naive_sentiment: rating,\n        }\n        text_source.sentiments.push(sentiment)\n      }\n    }\n    if (isReview(text_source)) {\n      text_source.sentiments = dedupeSentiments(text_source.sentiments)\n    }\n    return text_source\n  }\n\n  measureSentiment(sentence: string) {\n    return this.naive_sentiment.analyze(sentence).score\n  }\n\n  _getYelpReviews() {\n    const data = this.crawler.yelp?.data\n    if (!data) {\n      this.log(`getYelpReviews: No yelp data found`, this.crawler.yelp)\n      return []\n    }\n    const yelp_reviews = this.crawler.getPaginatedDataNumberedKeys(data, 'reviews')\n    if (DISH_DEBUG > 1) {\n      this.log(`Get yelp reviews`, yelp_reviews)\n    }\n    let reviews: Partial<Review>[] = []\n    for (const yelp_review of yelp_reviews) {\n      reviews.push({\n        user_id: externalUserUUID,\n        tag_id: globalTagId,\n        source: 'yelp',\n        username: 'yelp-' + yelp_review.userId,\n        authored_at: toDBDate(yelp_review.localizedDate, 'MM/DD/YYYY'),\n        restaurant_id: this.crawler.restaurant.id,\n        text: [\n          yelp_review.comment?.text,\n          yelp_review.lightboxMediaItems?.map((i: any) => i.caption).join(' '),\n        ].join(' '),\n        rating: yelp_review.rating,\n        type: 'review',\n      })\n    }\n    return reviews\n  }\n\n  _getTripadvisorReviews() {\n    let reviews: Partial<Review>[] = []\n    const data = this.crawler.tripadvisor?.data\n    if (!data) {\n      return reviews\n    }\n    const tripadvisor_reviews = this.crawler.getPaginatedDataNumberedKeys(data, 'reviews')\n    for (const tripadvisor_review of tripadvisor_reviews) {\n      if (!tripadvisor_review.username || tripadvisor_review.username == '') {\n        sentryMessage('TRIPADVISOR: Review has no username', { data: tripadvisor_review })\n        continue\n      }\n      reviews.push({\n        user_id: externalUserUUID,\n        tag_id: globalTagId,\n        source: 'tripadvisor',\n        username: 'tripadvisor-' + tripadvisor_review.username,\n        authored_at: toDBDate(tripadvisor_review.date, 'MMMM D, YYYY'),\n        restaurant_id: this.crawler.restaurant.id,\n        text: tripadvisor_review.text,\n        rating: tripadvisor_review.rating,\n        type: 'review',\n      })\n    }\n    return reviews\n  }\n\n  _getGoogleReviews() {\n    // @ts-ignore\n    const google_reviews = this.crawler.google_review_api?.data?.reviews || []\n    let reviews: Review[] = []\n    for (const review of google_reviews) {\n      const date = this._quantiseGoogleReviewDate(review.ago_text)\n      reviews.push({\n        user_id: externalUserUUID,\n        tag_id: globalTagId,\n        source: 'google',\n        username: 'google-' + review.user_id,\n        authored_at: date,\n        restaurant_id: this.crawler.restaurant.id,\n        text: review.text,\n        rating: +review.rating,\n        type: 'review',\n      } as Review)\n    }\n    return reviews\n  }\n\n  // We only get dates like \"2 weeks ago\" or \"2 years ago\" from Google. In order\n  // to allow multiple reviews from the same reviewer for the same restaurant we need\n  // some way to consistently differentiate reviews, otherwise successive reviews will\n  // just clobber the old ones. This way we can at least support 1 review per year. Not\n  // perfect, but not too bad either.\n  _quantiseGoogleReviewDate(date: string) {\n    const chrono_date = chrono.parseDate(date)\n    let m = moment(chrono_date)\n    const quantised_date = m.year().toString()\n    return toDBDate(quantised_date, 'YYYY')\n  }\n\n  _scanMenuItemsForTags() {\n    let texts: string[] = []\n    for (const review of this.crawler.menu_items) {\n      const text = review.description\n      if (!text) continue\n      texts.push(text)\n    }\n    return texts\n  }\n\n  deDepulicateTags() {\n    const map = new Map()\n    this.restaurant_tags.forEach((rt) => {\n      map.set(rt.tag_id, {\n        ...rt,\n        ...map.get(rt.tag_id),\n      })\n    })\n    this.restaurant_tags = Array.from(map.values())\n  }\n}\n", "import { Restaurant, globalTagId } from '@dish/graph'\n\nimport { GoogleGeocoder } from '../google/GoogleGeocoder'\nimport {\n  getTableCount,\n  googlePermalink,\n  restaurantDeleteOrUpdateByGeocoderID,\n  restaurantFindBasicBatchForAll,\n} from '../utils'\nimport { Self } from './Self'\n\nexport async function updateAllRestaurantGeocoderIDs(internal: Self) {\n  let previous_id = globalTagId\n  let arrived = process.env.START_FROM ? false : true\n  let progress = 0\n  let page = 0\n  const PER_PAGE = 1000\n  const count = await getTableCount('restaurant', 'WHERE geocoder_id IS NULL')\n  console.log('Total restaurants without geocoder_ids: ' + count)\n  while (true) {\n    const results = await restaurantFindBasicBatchForAll(\n      PER_PAGE,\n      previous_id,\n      'AND geocoder_id IS NULL'\n    )\n    if (results.length == 0) {\n      await internal.job.progress(100)\n      break\n    }\n    for (const result of results) {\n      if (!arrived) {\n        if (result.id != process.env.START_FROM) {\n          console.log('Skipping: ' + result.name)\n          continue\n        } else {\n          arrived = true\n        }\n      }\n      const restaurant_data = {\n        id: result.id,\n        name: result.name,\n        address: result.address,\n        location: JSON.parse(result.location),\n      }\n      await internal.runOnWorker('updateGeocoderID', [restaurant_data])\n      previous_id = result.id as string\n    }\n    page += 1\n    progress = ((page * PER_PAGE) / count) * 100\n    if (process.env.RUN_WITHOUT_WORKER != 'true') {\n      await internal.job.progress(progress)\n    } else {\n      console.log('Progress: ' + progress)\n    }\n  }\n}\n\nexport async function updateGeocoderID(rest: Restaurant) {\n  // prettier-ignore\n  console.log('UPDATE GEOCODER IDS: ', rest.id, `\"${rest.name}\"`, rest.address, rest.location)\n  if (!rest.name) {\n    console.log('Bad restaurant: ', rest)\n    return false\n  }\n  const geocoder = new GoogleGeocoder()\n  const coords = rest.location\n  const lon = coords.coordinates[0]\n  const lat = coords.coordinates[1]\n  const query = rest.name + ',' + rest.address\n  const google_id = await geocoder.searchForID(query, lat, lon)\n  if (google_id) {\n    const permalink = googlePermalink(google_id, lat, lon)\n    rest.geocoder_id = google_id\n    await restaurantDeleteOrUpdateByGeocoderID(rest.id, google_id)\n    console.log('GEOCODER RESULT: ', `\"${rest.name}\"`, permalink)\n  }\n}\n\nif (require.main === module) {\n  ;(async () => {\n    const internal = new Self()\n    //await internal.addBigJob('updateAllRestaurantGeocoderIDs', [])\n    await internal.addBigJob('updateAllDistinctScrapeGeocoderIDs', [])\n  })()\n}\n", "import '@dish/common'\n\nimport { sentryException } from '@dish/common'\nimport { DISH_DEBUG, Restaurant, globalTagId, restaurantFindBatch } from '@dish/graph'\nimport { JobOptions, QueueOptions } from 'bull'\nimport _ from 'lodash'\nimport { Tabletojson } from 'tabletojson'\n\nimport { scrapeInsert } from '../scrape-helpers'\nimport { GoogleGeocoder } from './GoogleGeocoder'\nimport { GooglePuppeteerJob } from './GooglePuppeteerJob'\n\nconst GOOGLE_DOMAIN = 'https://www.google.com'\n\nconst PER_PAGE = 50\n\nString.prototype.replaceAll = function (search, replacement) {\n  var target = this\n  return target.replace(new RegExp(search, 'g'), replacement)\n}\n\nexport class GooglePuppeteer extends GooglePuppeteerJob {\n  searchEndpoint!: string\n  lon!: number\n  lat!: number\n  name!: string\n  address!: string\n  googleRestaurantID!: string\n  scrape_data: any = {}\n\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 4,\n      duration: 5000,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  async allForCity(city: string) {\n    let previous_id = globalTagId\n    while (true) {\n      const results = await restaurantFindBatch(PER_PAGE, previous_id, city)\n      if (results.length == 0) {\n        break\n      }\n      for (const result of results) {\n        await this.runOnWorker('getRestaurant', [result])\n        previous_id = result.id as string\n      }\n    }\n  }\n\n  async getRestaurant(restaurant: Restaurant) {\n    if (!this.booted) await this.boot()\n    this.lon = restaurant.location.coordinates[0]\n    this.lat = restaurant.location.coordinates[1]\n    if (!restaurant.name) {\n      throw new Error(\"Google crawler: restaurant doesn't have a name\")\n    }\n    this.name = restaurant.name\n    this.address = restaurant.address?.split(',')[0] || ''\n    const geocoder = new GoogleGeocoder()\n    const address = restaurant?.address\n    if (!address || address.replaceAll(' ', '') == '') {\n      throw new Error('GOOGLE CRAWLER: restaurant has no address')\n    }\n    const query = restaurant.name + ',' + address\n    this.googleRestaurantID = await geocoder.searchForID(\n      query,\n      restaurant.location.coordinates[1],\n      restaurant.location.coordinates[0]\n    )\n    await this.getAllData(restaurant)\n    await scrapeInsert({\n      restaurant_id: restaurant.id,\n      source: 'google',\n      id_from_source: this.googleRestaurantID,\n      location: {\n        lon: restaurant.location.coordinates[0],\n        lat: restaurant.location.coordinates[1],\n      },\n      data: this.scrape_data,\n    })\n    if (process.env.DISH_ENV != 'production') {\n      this.puppeteer.close()\n    }\n  }\n\n  async getAllData(restaurant: Restaurant) {\n    this.scrape_data.page_url = this.puppeteer.page.url()\n    const steps = [\n      this.getMainPage,\n      this.getHeroImage,\n      this.getPricing,\n      this.getRating,\n      this.getAddress,\n      this.getHours,\n      this.getWebsite,\n      this.getPhone,\n      this.getSynopsis,\n    ]\n    for (const step of steps) {\n      await this.runFailableFn(step, restaurant)\n    }\n  }\n\n  async runFailableFn(func: Function, restaurant: Restaurant) {\n    console.log('GOOGLE: Running step: ' + func.name)\n    try {\n      await func.bind(this)()\n    } catch (e) {\n      console.log('got err', e)\n      if (!e.message?.includes('waiting for selector')) {\n        sentryException(e, {\n          data: { function: func.name, restaurant: restaurant },\n          tags: { source: 'Google crawler' },\n          logger: this.log,\n        })\n      } else {\n        if (process.env.DEBUG) {\n          console.log('error info', await this.puppeteer.page.content())\n        }\n      }\n    }\n  }\n\n  async getMainPage() {\n    let retries = 0\n    while (retries < 4) {\n      const url =\n        GOOGLE_DOMAIN +\n        `/maps/place/@${this.lat},${this.lon},17z/` +\n        `data=!3m1!4b1!4m5!3m4!1s${this.googleRestaurantID}` +\n        `!8m2!3d${this.lat}!4d${this.lon}`\n      console.log('Google Loading', url)\n      try {\n        await this.puppeteer.page.goto(url, {\n          timeout: 15_000,\n          waitUntil: 'networkidle0',\n        })\n        return true\n      } catch (err) {\n        console.error(`Error loading`, err.message)\n        throw err\n      }\n    }\n    throw new Error(\"GOOGLE CRAWLER: Couldn't get main page for: \" + this.name)\n  }\n\n  static convertTableToJSON(html: string) {\n    let json = Tabletojson.convert(html, {\n      useFirstRowForHeadings: true,\n      headings: ['day', 'hours'],\n      ignoreColumns: [2],\n    })[0]\n    if (!Array.isArray(json)) {\n      console.warn('Not an array', json, 'from html', html)\n      return []\n    }\n    return json.map((row) => {\n      const hours = row.hours.split('\\n')[0]\n      return { day: row.day, hours }\n    })\n  }\n\n  async getHeroImage() {\n    const image = await this.puppeteer.page.evaluate(\n      () =>\n        document.querySelector('.section-hero-header-image img')?.getAttribute('src') ??\n        Array.from(document.querySelectorAll(\"img[role='presentation']\"))\n          .map((x) => x?.getAttribute('src') || '')\n          .filter((x) => x.indexOf('googleusercontent.com') > 0)[0]\n    )\n    const hero = image?.replace(/w[0-9]+-h[0-9]+/, 'w1000-h1000')\n    this.scrape_data.hero_image = hero\n  }\n\n  async getSynopsis() {\n    try {\n      // TODO not working\n      this.scrape_data.synopsis = (\n        await this.puppeteer.getElementText('.uxOu9-sTGRBb-T3yXSc span')\n      ).trim()\n    } catch (err) {\n      if (DISH_DEBUG >= 2) {\n        console.log('error page content is', await this.puppeteer.page.content())\n      } else {\n        console.log('likely no synopsis, set DEBUG=1 to see html')\n      }\n      throw err\n    }\n  }\n\n  async getRating() {\n    const stars = await this.puppeteer.page.evaluate(\n      'document.querySelector(\".section-star-array\").getAttribute(\"aria-label\")'\n    )\n    if (typeof stars === 'string') {\n      this.scrape_data.rating = stars.replace(' stars', '').trim()\n    }\n  }\n\n  async getPricing() {\n    this.scrape_data.pricing = (\n      await this.puppeteer.getElementText('[aria-label*=\"Price:\"]')\n    ).trim()\n  }\n\n  async getAddress() {\n    this.scrape_data.address = (\n      await this.puppeteer.getElementText('[data-tooltip*=\"Copy address\"]')\n    ).trim()\n  }\n\n  async getWebsite() {\n    this.scrape_data.website = (\n      await this.puppeteer.getElementText('[data-tooltip*=\"Open website\"]')\n    ).trim()\n  }\n\n  async getPhone() {\n    this.scrape_data.telephone = (\n      await this.puppeteer.getElementText('[data-tooltip*=\"Copy phone number\"]')\n    ).trim()\n  }\n\n  async getHours() {\n    await this.puppeteer.page.click(`img[aria-label=\"Hours\"]`)\n    const html = await this.puppeteer.page.evaluate(() => {\n      // a bit more robust to find a few perhaps\n      const table =\n        document.querySelector('table.y0skZc-jyrRxf-Tydcue') ||\n        document.querySelector('table.NVpwyf-qJTHM-ibL1re') ||\n        document.querySelector('table')\n      return table?.outerHTML\n    })\n    this.scrape_data.hours = GooglePuppeteer.convertTableToJSON(html || '')\n  }\n}\n", "import '@dish/common'\n\nimport { sentryMessage } from '@dish/common'\nimport { Restaurant, globalTagId, restaurantFindOne } from '@dish/graph'\nimport { WorkerJob } from '@dish/worker'\nimport axios_base from 'axios'\nimport { JobOptions, QueueOptions } from 'bull'\nimport * as cheerio from 'cheerio'\n\nimport { ScrapeData, scrapeInsert } from '../scrape-helpers'\nimport { restaurantFindIDBatchForCity } from '../utils'\n\nconst GOOGLE_DOMAIN = process.env.GOOGLE_AWS_PROXY || 'https://www.google.com'\n\nconst axios = axios_base.create({\n  baseURL: GOOGLE_DOMAIN,\n  headers: {\n    common: {\n      'X-My-X-Forwarded-For': 'www.google.com',\n      'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:80.0) Gecko/20100101 Firefox/80.0',\n    },\n  },\n})\n\nconst DISH_RESTAURANT_BATCH_SIZE = 250\n\nexport class GoogleReviewAPI extends WorkerJob {\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 5,\n      duration: 300,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  get logName() {\n    return `GoogleReviewAPI`\n  }\n\n  async allForCity(city: string) {\n    let previous_id = globalTagId\n    while (true) {\n      const results = await restaurantFindIDBatchForCity(\n        DISH_RESTAURANT_BATCH_SIZE,\n        previous_id,\n        city\n      )\n      if (results.length == 0) {\n        break\n      }\n      for (const result of results) {\n        await this.runOnWorker('getRestaurant', [result.id])\n        previous_id = result.id as string\n      }\n    }\n  }\n\n  async getRestaurant(id: string) {\n    const restaurant = await restaurantFindOne({ id })\n    if (!restaurant) {\n      throw new Error('GoogleReviewAPI: No restaurant found for ID:' + id)\n    }\n    if (!restaurant.geocoder_id) {\n      const message = 'GoogleReviewAPI: restaurant.geocoder_id is empty'\n      sentryMessage(message, {\n        data: { restaurant_id: id },\n      })\n      return false\n    }\n    let allData: any[] = []\n    let page = 0\n    let lastToken = ''\n    while (true) {\n      this.log(`fetching page ${page} for ${restaurant.name}`)\n      const html = await this.fetchReviewPage(restaurant.geocoder_id, lastToken)\n\n      const { data, nextPageToken } = this.parseReviewPage(html)\n      lastToken = nextPageToken ?? ''\n      if (data.length == 0) break\n      allData = [...allData, ...data]\n      page++\n      if (process.env.NODE_ENV == 'test') {\n        break\n      }\n      if (!nextPageToken) {\n        this.log(`no next page token, finishing`)\n        break\n      }\n    }\n    await this.saveRestaurant(restaurant, allData)\n    this.log(`Finished getRestaurant() for '${restaurant.name}'`)\n    return true\n  }\n\n  // https://www.google.com/async/reviewSort?async=feature_id:0x0:0x97168583de68f09e,start_index:10,sort_by:newestFirst,review_source:Google,_fmt:html\n  // curl \\\n  //   \"https://www.google.com/async/reviewSort?client=firefox-b-d&yv=3&async=feature_id:0x14cab9e770d06d95%3A0x4b55747a9fc0e67a,review_source:All%20reviews,sort_by:qualityScore,start_index:120,is_owner:false,filter_text:,associated_topic:,next_page_token:120,_pms:s,_fmt:pc\" \\\n  //   -H \"User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:80.0) Gecko/20100101 Firefox/80.0\"\n  async fetchReviewPage(geocoder_id: string, nextPageToken: string) {\n    const GOOGLE_HARDCODED_PAGE_SIZE = 10 // DO NOT CHANGE\n    const base_path = 'async/reviewSort?async='\n    const options = [\n      'feature_id:' + geocoder_id,\n      'start_index:' + GOOGLE_HARDCODED_PAGE_SIZE,\n      'next_page_token:' + nextPageToken,\n      'sort_by:qualityScore',\n      'review_source:Google',\n      '_fmt:html',\n    ]\n    const path = base_path + options.join(',')\n    console.log('path', path)\n    const response = await axios.get(path)\n    if (!response.data) throw new Error('GoogleReviewAPI: no response')\n    return response.data\n  }\n\n  parseReviewPage(html: string) {\n    const $ = cheerio.load(html)\n    const nextPageToken = $('.gws-localreviews__general-reviews-block').attr('data-next-page-token')\n    const reviews = $('.gws-localreviews__google-review')\n    let data: any[] = []\n    for (let i = 0; i < reviews.length; i++) {\n      const divs = $(reviews[i]).find('> div > div')\n      const user = $(divs[0]).find('a').attr('href')\n      const user_id = this.parseUserID(user)\n      const name = $(divs[0]).text()\n      const review = $(divs[2])\n      const stars_text = review.find('g-review-stars > span').attr('aria-label')\n      const rating = this.parseReviewRating(stars_text)\n      const ago_text = review\n        .find('div > span')\n        .filter((i) => i == 0)\n        .text()\n      let text = review.find('> div > span').text()\n      const full_text = review.find('> div .review-full-text').html() || ''\n      text = this.parseReviewText(text, full_text)\n      const photos = this.parsePhotos($(reviews[i]), $)\n      data.push({\n        user_id,\n        name,\n        rating,\n        ago_text,\n        text,\n        photos,\n      })\n    }\n    return { data, nextPageToken }\n  }\n\n  parseReviewText(text: string, full_text: string) {\n    const parts = text.split('-')\n    parts.shift()\n    text = parts.join('-')\n    const more = '\u2026More'\n    if (text.includes(more)) {\n      text = full_text.replaceAll('<br>', '\\n')\n    }\n    const translated_by = '(Translated by Google)'\n    if (text.includes(translated_by)) {\n      text = text.split('(Translated by Google)')[1]\n      text = text.split('(Original)')[0].trim()\n    }\n    return text\n  }\n\n  parseReviewRating(stars: string | undefined) {\n    if (!stars) return null\n    const parts = stars.split(' ')\n    return parts[1]\n  }\n\n  parseUserID(href: string | undefined) {\n    if (!href) return null\n    const parts = href.split('/')\n    return parts[5]\n  }\n\n  parsePhotos(review: any, $: any) {\n    let urls: string[] = []\n    const anchors = review.find('g-scrolling-carousel div div div a')\n    for (let i = 0; i < anchors.length; i++) {\n      const style = $(anchors[i]).find('div').attr('style')\n      if (!style) continue\n      const brackets = style.split('(')\n      if (!brackets) continue\n      const equals = brackets[1].split('=')\n      if (!equals) continue\n      const url = equals[0]\n      urls.push(url)\n    }\n    return urls\n  }\n\n  async saveRestaurant(restaurant: Restaurant, data: ScrapeData) {\n    await scrapeInsert({\n      source: 'google_review_api',\n      restaurant_id: restaurant.id,\n      id_from_source: restaurant.geocoder_id || '',\n      location: {\n        lon: restaurant.location.coordinates[0],\n        lat: restaurant.location.coordinates[1],\n      },\n      data: {\n        reviews: data,\n      },\n    })\n  }\n\n  static getNameAndAddress(scrape: ScrapeData) {}\n}\n", "import '@dish/common'\n\nimport {\n  PhotoXref,\n  TagWithId,\n  ZeroUUID,\n  restaurantFindOne,\n  restaurantUpsert,\n  tagGetAllCuisinesWithDishes,\n  tagUpdate,\n} from '@dish/graph'\nimport { WorkerJob } from '@dish/worker'\nimport axios_base from 'axios'\nimport { JobOptions, QueueOptions } from 'bull'\n\nimport {\n  bestPhotosForTag,\n  photoXrefUpsert,\n  updatePhotoQualityAndCategories,\n  uploadToDO,\n} from '../photo-helpers'\n\n// Prototype:\n/*\ncurl 'https://6rw3mhsrsb.execute-api.us-west-2.amazonaws.com/fireprox/search?q=kitten&client=firefox-b-d&gbv=2&source=lnms&tbm=isch&sa=X&biw=1920&bih=1138'\\\n   -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0'\n*/\n\nif (!process.env.GOOGLE_SEARCH_PROXY) {\n  throw new Error('No GOOGLE_SEARCH_PROXY')\n}\n\nconst axios = axios_base.create({\n  baseURL: process.env.GOOGLE_SEARCH_PROXY + 'search',\n  headers: {\n    common: {\n      'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0',\n    },\n  },\n})\n\nexport class GoogleImages extends WorkerJob {\n  max_images = 10\n\n  static queue_config: QueueOptions = {\n    limiter: {\n      max: 20,\n      duration: 500,\n    },\n  }\n\n  static job_config: JobOptions = {\n    attempts: 3,\n  }\n\n  constructor() {\n    super()\n  }\n\n  get logName() {\n    return `GOOGLE IMAGES`\n  }\n\n  async main() {\n    const batch_size = 100\n    let page = 0\n    await this.checkForZeroUUIDRestaurant()\n    while (true) {\n      this.log('Dish batch...')\n      const dishes_batch = await tagGetAllCuisinesWithDishes(batch_size, page)\n      if (dishes_batch.length == 0) break\n      for (const dish of dishes_batch) {\n        await this.runOnWorker('imagesForDish', [dish])\n      }\n      page += 1\n    }\n  }\n\n  async checkForZeroUUIDRestaurant() {\n    const restaurant = await restaurantFindOne({ id: ZeroUUID })\n    if (restaurant) return\n    await restaurantUpsert([\n      {\n        id: ZeroUUID,\n        name: 'ZeroUUID',\n        location: { type: 'Point', coordinates: [0, 0] },\n      },\n    ])\n  }\n\n  async imagesForDish(dish: TagWithId) {\n    const dish_query = dish.parent?.name + ' ' + dish.name\n    const images = await this.searchForImages(dish_query)\n    const photos_xref = images.map((url) => {\n      return {\n        tag_id: dish.id,\n        restaurant_id: ZeroUUID,\n        photo: {\n          origin: url,\n        },\n      } as PhotoXref\n    })\n    await photoXrefUpsert(photos_xref)\n    await uploadToDO(photos_xref)\n    await updatePhotoQualityAndCategories(photos_xref)\n    const best_photos = await bestPhotosForTag(dish.id)\n    const default_images = best_photos.map((p) => {\n      if (!p.photo || !p.photo.url) throw new Error('imagesForDish(): Photo.url is undefined!?')\n      return p.photo.url\n    })\n    const updated_dish = {\n      id: dish.id,\n      default_images,\n      default_image: default_images[0],\n    }\n    await tagUpdate(updated_dish)\n  }\n\n  async searchForImages(dish: string) {\n    const path =\n      '?q=' +\n      encodeURIComponent(dish) +\n      '&client=firefox-b-d&gbv=2&source=lnms&tbm=isch&sa=X&biw=1920&bih=1138'\n    let images: string[] = []\n    const response = await axios.get(path)\n    const expression =\n      /,\\[\"(https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)).*/\n    var regex = new RegExp(expression)\n    for (const line of response.data.split('\\n')) {\n      if (line.startsWith(',[\"http') && this.isImageBigEnough(line)) {\n        images.push(line.match(regex)[1])\n        if (images.length >= this.max_images) break\n      }\n    }\n    return images\n  }\n\n  isImageBigEnough(line: string) {\n    const matches = line.match(/.*\",([0-9]+),.*/)\n    if (!matches) return false\n    const width = parseInt(matches[1])\n    return width > 400\n  }\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBAAO;AACP,4BAAO;;;ACDP,oBAAO;AAEP,oBAA0B;AAGnB,uBAAiB,wBAAU;AAAA,EAYhC,KAAK,SAAiB;AACpB,YAAQ,IAAI,qCAAqC;AAAA;AAAA;AAb9C;AACE,AADF,GACE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AARF,GAQE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;ACdd,sBAAO;AAEP,sBAA8B;AAC9B,qBAUO;AACP,2BAAyB;AACzB,sBAAuC;AAEvC,uBAAuB;AACvB,sBAAc;AACd,qBAAmB;;;ACnBZ,IAAM,aAAa,CAAE,SAAQ,IAAI,cAAc;;;ACAtD,2BAAO;AACP,qBAAO;AAEP,aAAwB;AACxB,kBAAyB;AAEzB,mBAAsB;AACtB,qBAA+C;AAC/C,mBAgBO;AACP,qBAA0B;AAC1B,0BAAyB;AACzB,uBAAqB;AACrB,kBAA6B;AAC7B,oBAAiD;AAM1C,IAAI,4BAA4B;AAChC,IAAI,2BAA2B;AAEtC,IAAM,wBAAwB,wCAAiC;AAC/D,IAAM,wBAAwB,wCAAiC;AAC/D,IAAM,kBAAkB,sBAAsB;AAEvC,IAAM,kBAAkB,sBAAsB;AAC9C,IAAM,kBAAkB,sBAAsB;AAC9C,IAAM,mBAAmB,sBAAsB;AAEtD,IAAM,4BAA4B;AAAA,EAChC,QAAQ,CAAC,MAAoB;AAC3B,WAAO,EAAE,IAAI,CAAC,MAAM;AAClB,aAAO,iCACF,8BAAa,GAAG,KAAK,KADnB;AAAA,QAEL,OAAO,mBACF,8BAAa,EAAE;AAAA;AAAA;AAAA;AAAA;AAOrB,IAAM,UAAU;AAEvB,2BAAkC,UAAgC;AAChE,MAAI,SAAS,UAAU;AAAG,WAAO;AACjC,MAAI,SAAS,MAAM,kBAAkB,gBAAgB;AACrD,MAAI,CAAC,QAAQ;AACX,WAAO;AAAA;AAET,WAAS,6BAA6B;AACtC,WAAS,0BAAO,QAAQ,CAAC,OAAI;AApE/B;AAoEkC,YAAC,GAAG,QAAQ,GAAG,eAAe,SAAG,UAAH,mBAAU,KAAK;AAAA;AAC7E,WAAS,mBAAmB;AAC5B,QAAM,WAAW,MAAM,gBACrB,QACA,mCAAsB,gDACtB;AAEF,QAAM,UAAU,MAAM,WAAW;AACjC,MAAI,CAAC,SAAS;AACZ,WAAO;AAAA;AAET,MAAI,QAAQ,SAAS,GAAG;AACtB,WAAO;AAAA,SACF;AACL,WAAO,SAAS,IAAI,CAAC,OAAO,GAAG;AAAA;AAAA;AArBb;AAyBtB,4BAA4B,QAA8B;AACxD,SAAO,QAAQ,CAAC,MAAM;AAvFxB;AAwFI,QAAI,CAAC,EAAE,SAAS,CAAC,EAAE,MAAM;AAAK,YAAM;AACpC,MAAE,MAAM,SAAS,yBAAM,QAAE,UAAF,mBAAS;AAChC,WAAO,EAAE,MAAM;AAAA;AAEjB,SAAO;AAAA;AANA;AAST,sCAAsC,QAA8B;AAClE,MAAI,OAAO,GAAG,iBAAiB,CAAC,OAAO,GAAG,QAAQ;AAChD,WAAO,IAAI,CAAC,MAAO,EAAE,SAAS;AAAA;AAEhC,MAAI,OAAO,GAAG,UAAU,CAAC,OAAO,GAAG,eAAe;AAChD,WAAO,IAAI,CAAC,MAAO,EAAE,gBAAgB;AAAA;AAEvC,SAAO;AAAA;AAPA;AAWT,iCAAiC,UAAgC;AAC/D,MAAI,QAAQ,IAAI,oBAAoB;AAClC,YAAQ,IAAI;AACZ;AAAA;AAEF,UAAQ,IAAI,eAAe,SAAS;AACpC,QAAM,QACJ,OAAM,QAAQ,IACZ,SAAS,IAAI,OAAO,UAAU;AAlHpC;AAmHQ,WAAQ,MAAM,aAAa,YAAM,UAAN,mBAAa,OAAQ,QAAQ;AAAA,OAG5D,OAAO;AAET,QAAM,WAAW,8BAAW,UAAU;AACtC,MAAI,SAAS,QAAQ;AAEnB,YAAQ,KAAK,8CAA8C,SAAS,IAAI,CAAC,MAAG;AA3HhF;AA2HmF,sBAAE,UAAF,mBAAS,QAAO;AAAA,OAAI,KAAK;AACxG,eAAW,WAAW,UAAU;AAC9B,UAAI,QAAQ,IAAI;AACd,cAAM,gBAAgB,EAAE,IAAI,QAAQ;AAAA;AAAA;AAAA;AAI1C,UAAQ,IAAI;AACZ,SAAO;AAAA;AAzBM;AA6Bf,4BAA4B,MAAqB;AAC/C,MAAI,CAAC;AAAK,WAAO;AACjB,MAAI;AACF,UAAM,MAAM,MAAM,MAAM;AACxB,QAAI,IAAI,UAAU;AAAK,aAAO;AAC9B,UAAM,cAAc,IAAI,QAAQ,IAAI;AACpC,WAAO,2CAAa,WAAW;AAAA,WACxB,GAAP;AACA,YAAQ,MAAM,sCAAsC,QAAO;AAC3D,WAAO;AAAA;AAAA;AATI;AAaf,yBAAyB,QAA8B;AACrD,MAAI,OAAO,CAAC,GAAG;AACf,MAAI,KAAK,GAAG,iBAAiB,CAAC,KAAK,GAAG,QAAQ;AAC5C,SAAK,IAAI,CAAC,MAAO,EAAE,SAAS;AAAA;AAE9B,MAAI,KAAK,GAAG,UAAU,CAAC,KAAK,GAAG,eAAe;AAC5C,SAAK,IAAI,CAAC,MAAO,EAAE,gBAAgB;AAAA;AAErC,SAAO,0BAAO,MAAM,CAAC,OAAI;AA5J3B;AA4J8B,YAAC,GAAG,QAAQ,GAAG,eAAe,SAAG,UAAH,mBAAU,KAAK;AAAA;AACzE,SAAO,KAAK,IAAI,CAAC,MAAM;AA7JzB;AA8JI,QAAI,CAAC,EAAE,SAAS,CAAC,EAAE,MAAM,KAAK;AAC5B,YAAM,IAAI,MAAM;AAAA;AAElB,MAAE,MAAM,SAAS,QAAE,UAAF,mBAAS;AAC1B,WAAO;AAAA;AAAA;AAdF;AAkBT,0BAA0B,QAA8B;AACtD,QAAM,WAAW;AACjB,QAAM,UAAU,MAAM,gCAAgC;AACtD,SAAO;AAAA;AAHM;AAMf,0BAAiC,QAA8B;AAC7D,QAAM,eAAe,MAAM,sBAAsB;AACjD,MAAI,aAAa,UAAU;AAAG;AAC9B,QAAM,WAAW,MAAM,iBAAiB;AACxC,QAAM,UAAU,SAAS,IAAI,CAAC,MAAW;AACvC,QAAI,CAAC,EAAE;AAAO,YAAM,IAAI,MAAM;AAC9B,WAAO;AAAA,MACL,IAAI,EAAE,MAAM;AAAA,MACZ,KAAK,UAAU,EAAE;AAAA;AAAA;AAGrB,QAAM,gBAAgB,SAAS,8BAAiB;AAAA;AAX5B;AActB,+CAAsD,QAA8B;AAClF,MAAI,QAAQ,IAAI,oBAAoB;AAClC,YAAQ,IAAI;AACZ;AAAA;AAEF,QAAM,oBAAoB,MAAM,qBAAqB;AACrD,QAAM,SAAS,MAAM,gBAAgB;AACrC,MAAI,CAAC,QAAQ;AACX,WAAO,kBAAkB,IAAI,CAAC,SAAQ;AACpC,aAAO,EAAE;AAAA;AAAA,SAEN;AACL,WAAO;AAAA;AAAA;AAZW;AAgBtB,+CAA+C,eAA2C;AACxF,QAAM,SAAS,MAAM,qCAAmB,MAAM;AAC5C,UAAM,IAAI,mBAAM,WAAW;AAAA,MACzB,OAAO;AAAA,QACL,KAAK;AAAA,UACH;AAAA,YACE,eAAe;AAAA,cACb,KAAK;AAAA;AAAA,YAEP,OAAO;AAAA,cACL,KAAK;AAAA,gBACH,QAAQ;AAAA;AAAA;AAAA;AAAA,UAId;AAAA,YACE,eAAe;AAAA,cACb,KAAK;AAAA;AAAA,YAEP,OAAO;AAAA,cACL,KAAK;AAAA,gBACH,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAMpB,aAAa,CAAC,sCAAyB;AAAA;AAGzC,WAAO;AAAA,KACN;AACH,SAAO;AAAA;AAhCM;AAmCf,wCAA+C,QAAoC;AACjF,QAAM,SAAS,MAAM,qCACnB,MACE,mBAAM,WAAW;AAAA,IACf,OAAO;AAAA,MACL,KAAK;AAAA,QACH;AAAA,UACE,QAAQ;AAAA,YACN,KAAK;AAAA;AAAA,UAEP,OAAO;AAAA,YACL,KAAK;AAAA,cACH,QAAQ;AAAA;AAAA;AAAA;AAAA,QAId;AAAA,UACE,QAAQ;AAAA,YACN,KAAK;AAAA;AAAA,UAEP,OAAO;AAAA,YACL,KAAK;AAAA,cACH,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAMpB,aAAa,CAAC,sCAAyB;AAAA,MAE3C;AAEF,SAAO;AAAA;AAhCa;AAmCtB,6CAA6C,eAA2C;AACtF,QAAM,SAAS,MAAM,qCACnB,MACE,mBAAM,WAAW;AAAA,IACf,OAAO;AAAA,MACL,eAAe;AAAA,QACb,KAAK;AAAA;AAAA,MAEP,OAAO;AAAA,QACL,SAAS;AAAA,UACP,UAAU;AAAA;AAAA;AAAA;AAAA,IAIhB,aAAa,CAAC,sCAAyB;AAAA,MAE3C;AAEF,SAAO;AAAA;AAlBM;AAqBf,sCAAsC,QAAoC;AACxE,QAAM,SAAS,MAAM,qCACnB,MACE,mBAAM,WAAW;AAAA,IACf,OAAO;AAAA,MACL,QAAQ;AAAA,QACN,KAAK;AAAA;AAAA,MAEP,OAAO;AAAA,QACL,SAAS;AAAA,UACP,UAAU;AAAA;AAAA;AAAA;AAAA,IAIhB,aAAa,CAAC,sCAAyB;AAAA,MAE3C;AAEF,SAAO;AAAA;AAlBM;AAqBf,gDAAgD,eAA2C;AACzF,QAAM,SAAS,MAAM,qCACnB,MACE,mBAAM,WAAW;AAAA,IACf,OAAO;AAAA,MACL,eAAe;AAAA,QACb,KAAK;AAAA;AAAA,MAEP,QAAQ;AAAA,QACN,MAAM;AAAA;AAAA,MAER,OAAO;AAAA,QACL,SAAS;AAAA,UACP,UAAU;AAAA;AAAA;AAAA;AAAA,IAIhB,aAAa,CAAC,sCAAyB;AAAA,MAE3C;AAAA,IACE,QAAQ,CAAC,MAAoB;AAC3B,aAAO,EAAE,IAAI,CAAC,MAAM;AAClB,cAAM,IAAI,mBACL,8BAAa,GAAG,KAAK;AAE1B,eAAO;AAAA;AAAA;AAAA;AAMf,SAAO;AAAA;AA/BM;AAkCf,uCAA8C,eAA2C;AACvF,QAAM,sBAAsB,QAAQ,IAAI,YAAY,SAAS,IAAI;AACjE,QAAM,SAAS,MAAM,6BAAS,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gDAaF;AAAA;AAAA,iCAEf;AAAA;AAAA;AAAA;AAAA;AAK/B,QAAM,MAAM,OAAO,KAAK,GAAG,YAAY;AACvC,QAAM,SAAS,IAAI,IAAI,CAAC,MAAW;AACjC,MAAE,QAAQ,KAAK,MAAM,EAAE;AACvB,WAAO;AAAA;AAET,SAAO;AAAA;AA3Ba;AA8BtB,gCAAuC,QAAoC;AACzE,QAAM,SAAS,MAAM,qCACnB,MACE,mBAAM,WAAW;AAAA,IACf,OAAO;AAAA,MACL,QAAQ;AAAA,QACN,KAAK;AAAA;AAAA;AAAA,IAGT,UAAU;AAAA,MACR;AAAA,QACE,OAAO;AAAA,UACL,SAAS,sBAAS;AAAA;AAAA;AAAA;AAAA,IAIxB,OAAO;AAAA,MAEX;AAEF,SAAO,0BAAO,QAAQ,CAAC,MAAM,EAAE;AAAA;AApBX;AAuBtB,2CACE,eACA,QACsB;AACtB,QAAM,SAAS,MAAM,qCACnB,MACE,mBAAM,WAAW;AAAA,IACf,OAAO;AAAA,MACL,MAAM;AAAA,QACJ;AAAA,UACE,eAAe;AAAA,YACb,KAAK;AAAA;AAAA;AAAA,QAGT;AAAA,UACE,QAAQ;AAAA,YACN,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA,IAKb,UAAU;AAAA,MACR;AAAA,QACE,OAAO;AAAA,UACL,SAAS,sBAAS;AAAA;AAAA;AAAA;AAAA,IAIxB,OAAO;AAAA,MAEX;AAEF,SAAO,0BAAO,QAAQ,CAAC,MAAM,EAAE;AAAA;AAhCX;AAmCtB,IAAM,+BAA+B;AAErC,+BAA+B,mBAA6B;AAC1D,MAAI,WAAiC;AACrC,MAAI,kBAAkB,UAAU;AAAG;AACnC,8BAA4B;AAC5B,aAAW,SAAS,yBAAM,mBAAmB,+BAA+B;AAC1E,aAAS,KAAK,GAAI,MAAM,YAAY;AAAA;AAEtC,QAAM,SAAS,MAAM,gBAAgB,UAAU,8BAAiB;AAChE,SAAO;AAAA;AARM;AAWf,2BAA2B,MAAgB;AACzC,QAAM,cAAc;AACpB,MAAI,UAAU;AACd,SAAO,MAAM;AACX,QAAI;AACF,aAAO,MAAM,0BAA0B;AAAA,aAChC,OAAP;AACA,cAAQ,IAAI,MAAM,SAAS,WAAW,MAAM,MAAM;AAClD,UAAI,CAAC,MAAM,QAAQ,SAAS,SAAS;AACnC,cAAM;AAAA;AAER,iBAAW;AACX,UAAI,UAAU,aAAa;AACzB,0CAAc,cAAc,6CAA6C,EAAE,MAAM;AACjF,eAAO;AAAA;AAET,cAAQ,IAAI;AACZ,YAAM,wBAAM,MAAO;AAAA;AAAA;AAAA;AAjBV;AAuBf,yCAAyC,MAAgB;AAxdzD;AAydE,MAAI,YAAY;AAEd,YAAQ,IAAI,uCAAuC,KAAK,QAAQ,UAAU,KAAK;AAAA;AAGjF,QAAM,CAAC,gBAAgB,iBAAiB,MAAK,MAAM,QAAQ,IAAI;AAAA,IAC7D,gBAAgB;AAAA,IAChB,iBAAiB;AAAA,IACjB,mBAAmB;AAAA;AAGrB,QAAM,MAA4B;AAClC,aAAW,QAAO,MAAM;AACtB,UAAM,KAAK,AAAO,kBAAW,OAAO,OAAO,MAAK,OAAO;AACvD,UAAM,UAAU,qBAAe,KAAK,CAAC,MAAM,MAAM,EAAE,cAAnC,mBAA8C;AAC9D,UAAM,aAAa,sBAAgB,KAAK,CAAC,MAAM,EAAE,QAAQ,UAAtC,mBAA4C;AAC/D,QAAI,QAAQ,IAAI,YAAY;AAC1B,cAAQ,IAAI,wBAAwB,yCAAY,IAAI,CAAC,MAAM,EAAE,OAAO,KAAK;AAAA;AAE3E,QAAI,CAAC,WAAW,CAAC,YAAY;AAC3B,cAAQ,KAAK;AACb;AAAA;AAEF,QAAI,KAAK;AAAA,MACP;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAGJ,SAAO;AAAA;AA9BM;AAiCf,kCAAkC,MAAgB;AAGhD,aAAW,MAAK,MAAM;AAAA;AAAA;AAHT;AAOf,gCACE,MACkF;AAClF,QAAM,qBAAqB,GAAG,QAAQ,IAAI;AAC1C,SAAO,MAAM,QAAQ,IACnB,KAAK,IAAI,OAAO,SAAQ;AACtB,UAAM,OAAO,MAAM,MAAM,MAAK,KAAK,CAAC,QAAQ,IAAI;AAChD,UAAM,WAAW,IAAI;AACrB,UAAM,YAAY,IAAI,IAAI;AAC1B,UAAM,WAAW,0BAAS,UAAU;AACpC,aAAS,OAAO,SAAS,MAAM;AAC/B,UAAM,WAAgB,MAAM,MAAM,oBAAoB;AAAA,MACpD,QAAQ;AAAA,MACR,MAAM;AAAA,OACL,KAAK,CAAC,QAAQ,IAAI;AACrB,WAAO;AAAA,MACL,YAAa,SAAiB;AAAA,MAC9B;AAAA;AAAA;AAAA;AAjBO;AA6Bf,+BAA+B,MAA+C;AAC5E,QAAM,oBAAoB,GAAG,QAAQ,IAAI;AACzC,QAAM,kBAAuB,MAAM,MAAM,mBAAmB;AAAA,IAC1D,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,gBAAgB;AAAA;AAAA,IAElB,MAAM,KAAK,UAAU;AAAA;AAEvB,SAAQ,MAAM,gBAAgB;AAAA;AATjB;AAYf,sBAAsB,OAAe;AACnC,MAAI,OAAO,QAAQ,IAAI,uBAAuB,QAAW;AACvD,UAAM,MAAM;AAAA;AAEd,SAAO,MAAM,QACX,qCAEA,QAAQ,IAAI;AAAA;AAPP;AAWT,oCAAoC,QAAiD;AACnF,MAAI,aAA0B;AAC9B,QAAM,aAAa,OAAO;AAC1B,MAAI,CAAC,YAAY;AACf,YAAQ,IAAI;AACZ,WAAO;AAAA;AAET,MAAI,WAAW,iBAAiB,yBAAY,WAAW,UAAU,uBAAU;AACzE,iBAAa,MAAM,8BAA8B,WAAW;AAAA;AAE9D,MAAI,WAAW,iBAAiB,yBAAY,WAAW,UAAU,uBAAU;AACzE,iBAAa;AAAA,MAEX,GAAG;AAAA,MACH,GAAI,MAAM,iCAAiC,WAAW;AAAA;AAAA;AAG1D,MAAI,WAAW,UAAU,yBAAY,WAAW,iBAAiB,uBAAU;AACzE,iBAAa;AAAA,MAEX,GAAG;AAAA,MACH,GAAI,MAAM,uBAAuB,WAAW;AAAA;AAAA;AAsBhD,SAAO,WACJ,OAAO,CAAC,MAAM;AAhmBnB;AAimBM,QAAI,CAAC,SAAE,UAAF,mBAAS,MAAK;AACjB,cAAQ,MAAM;AACd,aAAO;AAAA;AAET,WAAO;AAAA,KAER,IAAI,CAAC,MAAM,EAAE,MAAM;AAAA;AAnDT;AAsDf,qCAAqC,QAA8B;AACjE,MAAI,eAA4B;AAChC,MAAI,CAAC,OAAO,IAAI;AACd,YAAQ,IAAI;AACZ,WAAO;AAAA;AAET,MAAI,OAAO,GAAG,iBAAiB,yBAAY,OAAO,GAAG,UAAU,uBAAU;AACvE,mBAAe,MAAM,gCAAgC,OAAO,GAAG;AAAA;AAEjE,MAAI,OAAO,GAAG,iBAAiB,yBAAY,OAAO,GAAG,UAAU,uBAAU;AACvE,mBAAe,MAAM,gCAAgC,OAAO,GAAG;AAAA;AAEjE,MAAI,OAAO,GAAG,UAAU,yBAAY,OAAO,GAAG,iBAAiB,uBAAU;AACvE,mBAAe,MAAM,yBAAyB,OAAO,GAAG;AAAA;AAE1D,SAAO;AAAA;AAfM;AAkBf,gCAAgC,QAAqB;AACnD,+BAA6B;AAC7B,QAAM,8BAA8B;AACpC,MAAI,WAAwB;AAC5B,aAAW,SAAS,yBAAM,QAAQ,8BAA8B;AAC9D,aAAS,KAAK,GAAI,MAAM,sBAAsB;AAAA;AAEhD,SAAO;AAAA;AAPM;AAUf,qCAAqC,QAAqB;AACxD,UAAQ,IAAI;AACZ,MAAI,aAAa,MAAM,QAAQ,IAC7B,OAAO,IAAI,OAAO,MAAM;AAzoB5B;AA0oBM,QAAI,CAAC,EAAE,SAAS,CAAC,EAAE,MAAM,QAAQ;AAC/B,cAAQ,MAAM,uCAAuC;AACrD,aAAO,QAAE,UAAF,mBAAS;AAAA;AAElB,WAAO,SAAS,EAAE,MAAM,QAAQ,EAAE,MAAM;AAAA;AAG5C,eAAa,WAAW,OAAO;AAC/B,QAAM,8BAAY,SAAS;AAC3B,QAAM,WAAW,OAAO,OAAO,CAAC,MAAM;AACpC,WAAO,CAAC,WAAW,SAAS,EAAE;AAAA;AAEhC,UAAQ,IAAI,OAAO,SAAS,WAAW,WAAW;AAClD,SAAO;AAAA;AAjBM;AAoBf,wBAA+B,MAAa,IAAY;AACtD,SAAM,aAAa;AACnB,MAAI;AACJ,MAAI;AACF,eAAW,MAAM,MAAM,MAAK,EAAE,QAAQ;AAAA,WAC/B,GAAP;AACA,sCAAc,iCAAiC,EAAE,MAAM;AACvD,WAAO;AAAA;AAET,QAAM,YAAY,SAAS,QAAQ,IAAI;AACvC,SAAO,MAAM;AACX,QAAI,UAAU;AACd,UAAM,SAAS,MAAM,cAAc,MAAK,IAAI,aAAa;AACzD,UAAM,SAAS,OAAO;AACtB,QAAI,SAAS,KAAK;AAEhB;AAAA;AAEF,QAAI,SAAS,OAAO,UAAU,KAAK;AACjC,aAAO;AAAA;AAET,QAAI,UAAU;AAAK,iBAAW;AAC9B,QAAI,UAAU,IAAI;AAChB,0CAAgB,IAAI,MAAM,6BAA6B;AAAA,QACrD,MAAM;AAAA,UACJ,KAAK;AAAA,UACL;AAAA;AAAA;AAGJ,aAAO;AAAA;AAAA;AAAA;AA7BS;AAkCtB,6BAA6B,MAAa,IAAU,cAAsB;AACxE,QAAM,YAAY,GAAG;AACrB,MAAI;AACF,UAAM,SAAS,MAAM,MAAM,WAAW;AAAA,MACpC,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA;AAAA,MAElB,MAAM,KAAK,UAAU;AAAA,QACnB,UAAU;AAAA,QACV,WAAW;AAAA,QACX;AAAA;AAAA;AAGJ,YAAQ,IAAI,0BAA0B,OAAO,QAAQ,MAAM,OAAO,QAAQ;AAC1E,WAAO;AAAA,WACA,KAAP;AACA,YAAQ,IAAI,wBAAwB;AACpC,UAAM;AAAA;AAAA;AAlBK;AAgCf,+BAAsC,MAAa,eAAqB;AACtE,QAAM,SAAS,MAAM,YAAY;AAAA,IAC/B;AAAA,MACE;AAAA,MACA,QAAQ;AAAA,MACR,MAAM;AAAA,MACN,OAAO,EAAE;AAAA;AAAA;AAGb,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM;AAAA;AAElB,SAAO,OAAO,GAAG;AAAA;AAZG;;;AC5tBtB,oBAAgF;AAChF,2BAA0B;AAC1B,qBAAsB;;;ACFtB,qBAAO;AAEP,qBAA0B;AAC1B,oBAAuB;AAEvB,SAAmB;;;ACLnB,oBAAgF;;;ACAhF,qBAAO;AAEP,oBAAsB;AACtB,oBAA+B;AAC/B,qBAAgC;;;ACJhC,oBAA8B;;;ACA9B,qBAAO;AAEP,qBAA0B;;;ACF1B,qBAAO;AAEP,2BAAqB;AAErB,sBAAyC;AACzC,yBAAuB;AAEvB,6BAAsB;AACtB,4CAA0B;AAE1B,IAAM,QAAQ,wBAAC,QACb,IAAI,QAAgB,CAAC,KAAK,QAAQ;AAChC,iCAAK,KAAK,CAAC,KAAK,WAAY,MAAM,IAAI,OAAO,IAAI,OAAO;AAAA,IAF9C;AAKd,IAAM,UAAU;AAEhB,QAAQ,YAAY,MAAM;AAAA;AAC1B,+BAAU,IAAI;AAEd,IAAM,aACJ;AACF,IAAM,aAAa,QAAQ,IAAI,sBAAsB,MAAM,QAAQ,IAAI;AACvE,IAAM,aACJ,QAAQ,IAAI,iCAAiC,MAAM,QAAQ,IAAI;AACjE,IAAM,QAAQ,YAAY,aAAa,MAAM;AAEtC,sBAAgB;AAAA,EAWrB,YAAmB,QAAgB,YAAgC;AAAhD;AAVnB,iBAAQ;AACR,yBAAgB;AAChB,yBAAgB;AAChB,0BAAiB;AAwHT,8BAAqB,OAAO,YAAqB;AACvD,WAAK,wBAAwB;AAC7B,YAAM,OAAM,KAAK,qBAAqB;AACtC,UAAI,CAAC,MAAK;AACR,aAAK,iBAAiB;AACtB;AAAA;AAEF,UAAI,KAAK,YAAY,UAAU;AAC7B,aAAK,iBAAiB;AACtB;AAAA;AAEF,WAAK,iBAAiB;AACtB,cAAQ,SAAS,EAAE;AAAA;AA5HnB,QAAI,OAAO,cAAc,aAAa;AACpC,YAAM,IAAI,MAAM;AAAA,WACX;AACL,WAAK,YAAY;AACjB,cAAQ,IAAI,sBAAsB,KAAK;AAAA;AAAA;AAAA,QAIrC,OAAO;AACX,UAAM,KAAK;AACX,UAAM,KAAK;AAAA;AAAA,QAGP,eAAe;AACnB,UAAM,KAAK;AACX,UAAM,KAAK;AAAA;AAAA,QAGP,iBAAiB;AACrB,YAAQ,IAAI;AACZ,UAAM,KAAK;AACX,UAAM,KAAK;AACX,YAAQ,IAAI;AAAA;AAAA,QAGR,QAAQ;AACZ,UAAM,KAAK,QAAQ;AAAA;AAAA,QAGf,MAAM,IAAY;AACtB,WAAO,IAAI,QAAQ,CAAC,QAAQ,WAAW,KAAK;AAAA;AAAA,QAGxC,mBAAmB;AACvB,UAAM,SAAS,IAAI,2BAAW,OAAO;AAAA,MACnC,MAAM;AAAA,MACN,wBAAwB,MAAM;AAC5B,eAAO;AAAA,UACL,kBAAkB;AAAA;AAAA;AAAA;AAKxB,WAAO,OAAO,MAAM;AAClB,cAAQ,IAAI,qCAAqC,OAAO;AAAA;AAI1D,WAAO,GAAG,oBAAoB,CAAC,EAAE,YAAY;AAC3C,WAAK,QAAQ,KAAK,QAAQ,MAAM,aAAa,MAAM;AAAA;AAIrD,WAAO,GAAG,iBAAiB,CAAC,EAAE,SAAS,YAAY;AACjD,cAAQ,IAAI,WAAW,QAAQ;AAC/B,cAAQ,MAAM;AAAA;AAAA;AAAA,QAIZ,iBAAiB;AACrB,UAAM,oBAAoB;AAC1B,UAAM,eAAe;AACrB,mCAAU,YAAY;AAAA,MACpB,UAAU;AAAA,MACV,MAAM;AAAA,QACJ;AAAA,QACA,uBAAuB;AAAA,QACvB;AAAA;AAAA;AAGJ,UAAM,WAAW,MAAM,8CAAiC;AAAA,MACtD,MAAM;AAAA,MACN,MAAM;AAAA,MACN,MAAM;AAAA,MACN,MAAM;AAAA,MACN,MAAM;AAAA;AAER,SAAK,UAAU,MAAM,+BAAU,OAAO;AAAA,MACpC,MAAM;AAAA,MACN,mBAAmB,CAAC;AAAA,MACpB,MAAM,CAAC;AAAA,OACH,YAAY;AAAA,MACd,gBAAgB;AAAA;AAGpB,SAAK,OAAO,MAAM,KAAK,QAAQ;AAE/B,SAAK,KAAK,GAAG,SAAS,CAAC,QAAQ;AAC7B,cAAQ,IAAI,mBAAmB;AAAA;AAGjC,SAAK,KAAK,GAAG,aAAa,CAAC,YAAY;AACrC,cAAQ,IAAI,wBAAwB;AAAA;AAEtC,UAAM,KAAK,KAAK,YAAY,EAAE,OAAO,MAAM,QAAQ;AACnD,UAAM,KAAK,KAAK,aAAa;AAAA;AAAA,QAGzB,oBAAoB;AACxB,UAAM,KAAK,KAAK,uBAAuB;AACvC,SAAK,KAAK,GAAG,WAAW,KAAK;AAAA;AAAA,QAGzB,2BAA2B;AAC/B,SAAK,KAAK,IAAI,WAAW,KAAK;AAC9B,UAAM,KAAK,KAAK,uBAAuB;AAAA;AAAA,EAGzC,kBAAkB;AAChB,YAAQ,IAAI,cAAc,KAAK,eAAe,cAAc,KAAK;AAAA;AAAA,EAkBnE,YAAY,SAAkB;AAC5B,UAAM,YAAY,CAAC,SAAS,SAAS,QAAQ,SAAS,SAAS,SAAS;AACxE,UAAM,WAAW,UAAU,KAAK,CAAC,MAAM;AACrC,aAAO,EAAE,KAAK,QAAQ;AAAA;AAExB,UAAM,kBAAkB,KAAK,qBAAqB;AAClD,QAAI,YAAY,CAAC,iBAAiB;AAChC,cAAQ;AACR,aAAO;AAAA;AAET,WAAO;AAAA;AAAA,EAGT,qBAAqB,SAAkB;AACrC,UAAM,iBAAiB,QAAQ,MAAM,SAAS,KAAK;AACnD,UAAM,uBAAuB,KAAK,qBAAqB;AACvD,QAAI,KAAK,8BAA8B,UAAU;AAC/C,aAAO,QAAQ;AAAA;AAEjB,QAAI,gBAAgB;AAClB,YAAM,cAAc,QAAQ,MAAM,QAAQ,KAAK,QAAQ,KAAK,WAAW,QAAQ,MAAM;AACrF,aAAO;AAAA,eACE,sBAAsB;AAC/B,YAAM,cAAc,QACjB,MACA,QAAQ,uBAAuB,QAAQ,IAAI,gCAAgC,IAC3E,QAAQ,MAAM;AACjB,aAAO;AAAA,WACF;AACL,cAAQ;AACR,aAAO;AAAA;AAAA;AAAA,EAIX,8BAA8B,SAAkB;AAC9C,QAAI,QAAQ,MAAM,SAAS;AAAa,aAAO;AAAA;AAAA,EAGjD,qBAAqB,SAAkB;AACrC,WAAO,QAAQ,MAAM,SAAS;AAAA;AAAA,EAGhC,wBAAwB,SAAkB;AACxC,QAAI,CAAC,KAAK;AAAoB;AAC9B,QAAI,QAAQ,MAAM,SAAS,KAAK,qBAAqB;AACnD,cAAQ,IAAI;AACZ,WAAK,wBAAwB,QAAQ;AAAA;AAAA;AAAA,QAInC,QAAQ,MAAa;AACzB,UAAM,KAAK,KAAK,KAAK;AACrB,UAAM,KAAK;AAAA;AAAA,QAGP,aAAa;AACjB,UAAM,KAAK,KAAK,WAAW,EAAE,MAAM;AAAA;AAAA,QAG/B,uBAAuB;AAC3B,WAAO,MAAM,KAAK,KAAK,SAAS,MAAM,OAAO,SAAS;AAAA;AAAA,QAGlD,iBAAiB,MAAa;AAClC,YAAQ,IAAI;AACZ,WAAQ,MAAM,KAAK,0BAA2B,MAAK;AACjD,YAAM,KAAK,MAAM;AAAA;AAEnB,YAAQ,IAAI;AAAA;AAAA,QAGR,eAAe,UAAkB;AACrC,UAAM,KAAK,KAAK,gBAAgB,UAAU;AAAA,MAExC,SAAS;AAAA;AAEX,UAAM,UAAU,MAAM,KAAK,KAAK,EAAE;AAClC,WAAO,MAAM,KAAK,KAAK,SAAS,CAAC,aAAY,SAAQ,aAAa;AAAA;AAAA,QAG9D,kBAAkB,UAAkB;AACxC,SAAK,iBAAiB;AACtB,QAAI,WAAW;AACf,UAAM,KAAK,KAAK,gBAAgB;AAChC,QAAI,gBAAgB;AACpB,WAAO,eAAe;AACpB,iBAAW,MAAM,KAAK,gBAAgB;AACtC,cAAQ,IAAI,gBAAgB,UAAU;AACtC,YAAM,KAAK,gBAAgB;AAC3B,UAAI,QAAQ,IAAI,YAAY,UAAU,WAAW,IAAI;AACnD,gBAAQ,IAAI;AACZ;AAAA;AAEF,sBAAgB,MAAM,KAAK,oBAAoB,UAAU;AAAA;AAAA;AAAA,QAIvD,oBAAoB,UAAkB,UAAkB;AAC5D,UAAM,iCAAiC,KAAK;AAC5C,UAAM,QAAQ;AACd,QAAI,UAAU;AACd,WAAO,UAAU,gCAAgC;AAC/C,YAAM,YAAY,MAAM,KAAK,gBAAgB;AAC7C,UAAI,YAAY;AAAU,eAAO;AACjC,YAAM,KAAK,MAAM;AACjB,gBAAU,UAAU;AAAA;AAEtB,WAAO;AAAA;AAAA,QAGH,gBAAgB,UAAkB;AACtC,SAAK,iBAAiB,MAAM,KAAK,KAAK,SACpC,OAAO,WAAU,mBAAmB;AAClC,4BAAqB,IAAY;AAC/B,eAAO,IAAI,QAAQ,CAAC,QAAQ,WAAW,KAAK;AAAA;AAD/B;AAGf,YAAM,WAAW,SAAS,iBAAiB;AAC3C,eAAS,IAAI,gBAAgB,IAAI,SAAS,QAAQ,KAAK;AACrD,iBAAS,GAAG;AACZ,0BAAkB;AAClB,cAAM,OAAM;AAAA;AAEd,aAAO;AAAA,OAET,UACA,KAAK;AAAA;AAAA,QAIH,gBAAgB,UAAkB;AACtC,WAAO,MAAM,KAAK,KAAK,SAAS,CAAC,cAAa;AAC5C,aAAO,SAAS,iBAAiB,WAAU;AAAA,OAC1C;AAAA;AAAA;AA/QA;;;ADpBA,uCAAiC,yBAAU;AAAA,EAKhD,cAAc;AACZ;AALF,yBAAgB;AAEhB,kBAAS;AAIP,SAAK,YAAY,IAAI,UAAU,KAAK,eAAe,QAAQ,IAAI;AAAA;AAAA,QAG3D,OAAO;AACX,UAAM,KAAK,UAAU;AACrB,SAAK,SAAS;AAAA;AAAA;AAZX;;;ADAP,IAAM,SAAQ,wBAAC,OAAe,IAAI,QAAQ,CAAC,QAAQ,WAAW,KAAK,MAArD;AAEP,IAAM,SAAS;AAEtB,OAAO,UAAU,aAAa,SAAU,QAAQ,aAAa;AAC3D,MAAI,SAAS;AACb,SAAO,OAAO,QAAQ,IAAI,OAAO,QAAQ,MAAM;AAAA;AAG1C,yCAAmC,mBAAmB;AAAA,EAgB3D,cAAc;AACZ;AACA,SAAK,UAAU,qBAAqB;AAAA;AAAA,QAOhC,uBAAuB;AAC3B,YAAQ,IAAI;AACZ,UAAM,KAAK;AACX,UAAM,KAAK;AACX,SAAK;AACL,YAAQ,IAAI,kBAAkB,KAAK;AACnC,UAAM,iCAAc;AAAA,MAClB;AAAA,QACE,KAAK;AAAA,QAEL,OAAO,KAAK;AAAA;AAAA;AAGhB,YAAQ,IAAI;AAAA;AAAA,EAGd,4BAA4B;AAC1B,SAAK,iBAAiB,KAAK,UAAU,sBAClC,WAAW,2BAA2B,IACtC,WAAW,KAAK,IAAI,YAAY,WAChC,WAAW,KAAK,IAAI,YAAY;AAAA;AAAA,EAGrC,SAAS;AACP,UAAM,MAAM;AACZ,UAAM,MAAM;AACZ,WAAO,KAAK,WAAY,OAAM,OAAO;AAAA;AAAA,QASjC,iCAAiC;AACrC,SAAK,MAAM,UAAU,KAAK;AAC1B,SAAK,MAAM,YAAY,KAAK;AAC5B,UAAM,OAAM,KAAK,gBAAgB,UAAU,KAAK,OAAO,KAAK;AAC5D,UAAM,OAAO,KAAK,UAAU;AAC5B,YAAQ,IAAI,kCAAkC;AAC9C,UAAM,KAAK,KAAK;AAChB,UAAM,OAAM,KAAK,WAAW;AAC5B,UAAM,KAAK,MAAM;AACjB,YAAQ,IAAI;AACZ,UAAM,OAAM,KAAK,WAAW;AAC5B,UAAM,KAAK,SAAS,KAAK;AACzB,UAAM,OAAM,KAAK,WAAW;AAC5B,UAAM,KAAK,SAAS,MAAM;AAAA;AAAA,QAGtB,uBAAuB;AAC3B,QAAI,UAAU;AACd,WAAO,UAAU,GAAG;AAClB,YAAM,KAAK;AACX,YAAM,KAAK;AACX,UAAI,KAAK,UAAU,uBAAuB;AACxC;AAAA,aACK;AACL,cAAM,KAAK,UAAU,KAAK;AAC1B;AAAA;AAAA;AAGJ,QAAI,CAAC,KAAK,UAAU,uBAAuB;AACzC,YAAM,IAAI,MAAM,sCAAsC,UAAU;AAAA;AAAA;AAAA,QAI9D,2BAA2B;AAC/B,QAAI,QAAQ;AACZ,WAAO,CAAC,KAAK,UAAU,uBAAuB;AAC5C,YAAM,OAAM;AACZ;AACA,UAAI,QAAQ;AAAK;AAAA;AAAA;AAAA;AAlGhB;AAKE,AALF,qBAKE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AAZF,qBAYE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;ADpBP,IAAM,6BAA6B;AACnC,IAAM,YAAY;AAClB,IAAM,YAAY;AAClB,IAAM,2BAA2B;AAExC,IAAM,gBAAgB;AACtB,IAAM,0BAA0B;AAChC,IAAM,eAAe;AACrB,IAAM,YAAY,IAAI,+BACpB,eACA,QAAQ,IAAI,oBAAoB,eAChC;AAAA,EACE,SAAS;AAAA,IACP,wBAAwB;AAAA;AAAA;AAK9B,OAAO,UAAU,aAAa,SAAU,QAAQ,aAAa;AAC3D,MAAI,SAAS;AACb,SAAO,OAAO,QAAQ,IAAI,OAAO,QAAQ,MAAM;AAAA;AAG1C,2BAAqB;AAAA,QAMpB,YAAY,QAAe,KAAa,KAAa;AACzD,QAAI,UAAU;AACd,SAAK,QAAQ;AACb,SAAK,MAAM;AACX,SAAK,MAAM;AACX,UAAM,KAAK;AACX,WAAO,UAAU,GAAG;AAClB,UAAI;AACF,eAAO,MAAM,KAAK;AAAA,eACX,GAAP;AACA,YAAI,EAAE,WAAW,gBAAgB,EAAE,WAAW,yBAAyB;AACrE,kBAAQ,IACN,0BAA0B,yBAAyB,mBAAkB,EAAE;AAEzE;AACA,gBAAM,yBAAM;AACZ,gBAAM,KAAK;AAAA,eACN;AACL,gBAAM,IAAI,MAAM;AAAA;AAAA;AAAA;AAItB,UAAM,UAAU,qDAAqD;AACrE,UAAM,IAAI,MAAM;AAAA;AAAA,QAGJ,2BAA2B;AACvC,UAAM,SAAS,MAAM,kCAAe;AAAA,MAClC,KAAK;AAAA;AAEP,WAAO,iCAAQ;AAAA;AAAA,QAGH,oBAAoB;AAChC,SAAK,iBAAiB,MAAM,KAAK;AACjC,QAAI,OAAO,KAAK,mBAAmB,UAAU;AAC3C,YAAM,UAAU,IAAI;AACpB,YAAM,QAAQ;AACd,WAAK,iBAAiB,MAAM,KAAK;AAAA;AAEnC,QAAI,OAAO,KAAK,mBAAmB,UAAU;AAC3C,YAAM,IAAI,MAAM;AAAA;AAAA;AAAA,EAIZ,kBAAkB;AACxB,UAAM,OAAM,KAAK;AACjB,WAAQ,MAAI,WAAW,OAAO,OAAM,IAAI,QACrC,WAAW,WAAW,KAAK,IAAI,YAC/B,WAAW,WAAW,KAAK,IAAI,YAC/B,WAAW,QAAQ,mBAAmB,KAAK;AAAA;AAAA,QAGlC,eAAe;AAC3B,UAAM,OAAM,KAAK;AACjB,UAAM,WAAW,MAAM,UAAU,QAAQ,MAAK;AAAA,MAC5C,SAAS,EAAE,cAAc;AAAA,MACzB,aAAa;AAAA;AAEf,QAAI,KAAK,kBAAkB,WAAW;AACpC,YAAM,IAAI,MAAM;AAAA;AAGlB,UAAM,UAAU,SAAS,MAAM;AAC/B,QAAI,SAAS;AACX,aAAO,QAAQ;AAAA,WACV;AACL,cAAQ,MAAM,yBAAyB,SAAS,MAAM,GAAG,OAAO;AAChE,YAAM,IAAI,MAAM;AAAA;AAAA;AAAA,EAMpB,kBAAkB,QAAgB;AAChC,UAAM,gBAAgB,OAAO,MAAM;AACnC,QAAI,CAAC;AAAe,aAAO;AAC3B,UAAM,yBAAyB,cAAc;AAC7C,UAAM,qBAAqB,mBAAmB;AAC9C,UAAM,iBAAiB,mBAAmB,KAAK;AAC/C,QACE,uBAAuB,KAAK,SAC5B,uBAAuB,kBACvB,2BAA2B,gBAC3B;AACA,aAAO;AAAA;AAET,UAAM,mBAAmB,eACtB,WAAW,OAAO,KAClB,WAAW,OAAO,KAClB,WAAW,OAAO,OAClB,WAAW,OAAO,KAClB,WAAW,OAAO,KAClB,WAAW,OAAO,KAClB,WAAW,OAAO;AACrB,QACE,0BAA0B,kBAC1B,0BAA0B,oBAC1B,sBAAsB,KAAK,OAC3B;AACA,cAAQ,IACN;AAAA,wBACgB,KAAK;AAAA,yBACJ;AAAA,wBACD;AAAA,wBACA;AAAA,wBACA;AAAA,wBACA;AAAA,GAChB,YACA;AAEF,aAAO;AAAA;AAET,WAAO;AAAA;AAAA;AAvHJ;AA2HA,4BAA4B,IAAY;AAC7C,SAAO,GAAG,MAAM;AAAA;AADF;;;AD5IhB,uCACE,QACA,gBACA,KACA,KACA,MACA,SACA;AACA,QAAM,CAAC,eAAe,eAAe,MAAM,sBACzC,QACA,gBACA,KACA,KACA,MACA;AAEF,MAAI,CAAC,KAAK,KAAK,YAAY,CAAC,SAAS;AACnC,UAAM,IAAI,MAAM;AAAA;AAElB,MAAI,eAAe;AACjB,WAAO;AAAA;AAET,QAAM,CAAC,cAAc,MAAM,oCAAiB;AAAA,IAC1C;AAAA,MACE;AAAA,MACA;AAAA,MACA,UAAU;AAAA,QACR,MAAM;AAAA,QACN,aAAa,CAAC,KAAK;AAAA;AAAA,MAErB;AAAA;AAAA;AAGJ,MAAI,QAAQ,IAAI,sBAAsB,QAAQ;AAC5C,YAAQ,IAAI,uCAAuC,WAAW;AAAA;AAEhE,SAAO,WAAW;AAAA;AApCE;AAuCtB,qCACE,QACA,gBACA,KACA,KACA,MACA,SACmD;AACnD,QAAM,SAAS,MAAM,wBAAwB,QAAQ,gBAAgB;AACrE,MAAI;AACJ,MAAI;AACJ,MAAI,UAAU,OAAO,kBAAkB,wBAAU;AAC/C,iBAAa,MAAM,qCAAkB,EAAE,IAAI,OAAO;AAClD,QAAI,cAAc,WAAW,aAAa;AACxC,aAAO,CAAC,WAAW,IAAI;AAAA;AAAA;AAG3B,UAAQ,IAAI;AACZ,QAAM,CAAC,aAAa,cAAc,MAAM,kBAAkB,MAAM,SAAS,KAAK;AAC9E,eAAa;AACb,cAAY;AACZ,MAAI,YAAY;AACd,YAAQ,IAAI,oCAAoC,WAAW;AAC3D,WAAO,CAAC,WAAW,IAAI;AAAA,SAClB;AACL,YAAQ,IAAI,yBAAyB;AACrC,WAAO,CAAC,QAAW;AAAA;AAAA;AA1BR;AA8Bf,iCAAwC,MAAc,SAAiB,KAAa,KAAa;AAC/F,MAAI,CAAC,KAAK,KAAK,SAAS,CAAC,MAAM;AAC7B,UAAM,IAAI,MAAM;AAAA;AAElB,MAAI,CAAC,KAAK,KAAK,YAAY,CAAC,SAAS;AACnC,UAAM,IAAI,MAAM;AAAA;AAElB,QAAM,WAAW,IAAI;AACrB,QAAM,SAAQ,OAAO,OAAO;AAC5B,QAAM,YAAY,MAAM,SAAS,YAAY,QAAO,KAAK;AACzD,MAAI,CAAC,WAAW;AACd,UAAM,IAAI,MAAM,gBAAgB,UAAS,OAAO,WAAW,SAAS;AAAA;AAEtE,QAAM,aAAa,MAAM,qCAAkB,EAAE,aAAa;AAC1D,SAAO,CAAC,YAAY;AAAA;AAdA;;;AKpFtB,qBAAO;AAEP,kBAAiB;AAEjB,oBAAmD;AACnD,2BAAyB;AACzB,mBAAkB;AAClB,qBAAc;AACd,oBAA+B;AAK/B,IAAM,QAAO,oBAAK,UAAU,QAAQ,iBAAiB;AAErD,IAAM,qBAAqB,QAAQ,IAAI;AAiChC,6BACL,KACA,KACA,YACA,WACkB;AAClB,QAAM,SAAS;AACf,QAAM,WAAW,aAAa;AAC9B,QAAM,WAAW,YAAa,UAAS,KAAK,IAAK,KAAK,KAAK,MAAO;AAElE,QAAM,OAAO,MAAM,WAAY,OAAM,KAAK;AAC1C,QAAM,OAAO,MAAM,WAAY,OAAM,KAAK;AAC1C,SAAO,CAAC,MAAM;AAAA;AAZA;AAkBT,sBAAsB,KAAa,KAAa,YAAoB,cAAsB;AAC/F,MAAI,SAAkB;AACtB,QAAM,OAAO,aAAa;AAC1B,WAAS,IAAI,MAAM,KAAK,CAAC,MAAM,IAAI,IAAI,YAAY;AACjD,aAAS,IAAI,CAAC,MAAM,KAAK,MAAM,IAAI,IAAI,YAAY;AACjD,aAAO,KAAK,oBAAoB,KAAK,KAAK,GAAG;AAAA;AAAA;AAGjD,SAAO;AAAA;AARO;AAWT,+BAA+B,KAAa,KAAa,QAAgC;AAC9F,QAAM,YAAY,oBAAoB,KAAK,KAAK,QAAQ;AACxD,QAAM,cAAc,oBAAoB,KAAK,KAAK,CAAC,QAAQ,CAAC;AAC5D,SAAO,CAAC,WAAW;AAAA;AAHL;AAMhB,uBAA8B,SAAiC;AAC7D,MAAI;AACJ,QAAM,MAAM;AACZ,QAAM,QAAQ,MAAM,8BAAW;AAC/B,QAAM,iBAAiB,QAAQ,cAAc,QAAQ,WAAW;AAChE,MAAI,MAAM,iBAAiB;AACzB,kBAAc,MAAM;AAAA,SACf;AACL,kBAAc,MAAM,uBAAuB;AAC3C,UAAM,kBAAkB;AACxB,YAAQ,IAAI,kCAAkC;AAC9C,UAAM,8BAAW,KAAK;AAAA;AAExB,SAAO;AAAA;AAba;AAgBtB,sCAAsC,SAAiC;AACrE,QAAM,OAAO;AACb,QAAM,SAAQ,iBAAiB,UAAU;AACzC,QAAM,OAAM,OAAO,qBAAqB;AACxC,QAAM,WAAW,MAAM,qBAAM,IAAI;AACjC,QAAM,SAAS,SAAS,KAAK,SAAS,KAAK,GAAG,OAAO;AACrD,QAAM,SAAS,OAAO,SAAS;AAC/B,SAAO,CAAC,OAAO,UAAU,OAAO;AAAA;AAPnB;AA2CR,kBAAkB,SAAwB,SAAiB,IAAI;AACpE,MAAI;AACJ,MAAI,UAAU,IAAI;AAChB,QAAI,2BAAO;AAAA,SACN;AACL,QAAI,2BAAO,SAAS;AAAA;AAEtB,QAAM,WAAW,EAAE,OAAO,gBAAgB;AAC1C,SAAO;AAAA;AARO;AAWT,yBAAyB,IAAY,KAAa,KAAa;AACpE,SACE,sCACI,OAAO,mCAAmC,YAAY,SAAS;AAAA;AAHvD;AAOhB,4CACE,MACA,aACA,MACA,SAAS,KACc;AACvB,QAAM,SAAS,MAAM,QAAQ;AAC7B,QAAM,SAAQ;AAAA;AAAA;AAAA;AAAA,uBAIO,OAAO,OAAO,OAAO;AAAA,UAClC;AAAA;AAAA,kBAEQ;AAAA;AAAA,YAEN;AAAA;AAEV,QAAM,SAAS,MAAM,8BAAS,kBAAkB;AAChD,SAAO,OAAO;AAAA;AAnBM;AAsBtB,sCAA6C,MAAc,SAAS,KAAK;AACvE,QAAM,SAAS,MAAM,QAAQ;AAC7B,QAAM,SAAQ;AAAA;AAAA;AAAA;AAAA,uBAIO,OAAO,OAAO,OAAO;AAAA,UAClC;AAAA;AAAA;AAGR,QAAM,SAAS,MAAM,8BAAS,kBAAkB;AAChD,SAAO,OAAO,KAAK,GAAG;AAAA;AAXF;AActB,8CACE,MACA,aACA,cAAc,IACS;AACvB,QAAM,SAAQ;AAAA;AAAA,oBAEI;AAAA,QACZ;AAAA;AAAA,YAEI;AAAA;AAEV,QAAM,SAAS,MAAM,8BAAS,kBAAkB;AAChD,SAAO,OAAO;AAAA;AAbM;AAiCtB,gCAAuC,MAAc,aAAqB,cAAc,IAAI;AAC1F,QAAM,SAAQ;AAAA;AAAA,oBAEI;AAAA,QACZ;AAAA;AAAA,YAEI;AAAA;AAEV,QAAM,SAAS,MAAM,8BAAS,kBAAkB;AAChD,SAAO,OAAO;AAAA;AATM;AAYtB,6BAAoC,OAAe,QAAQ,IAAqB;AAC9E,QAAM,SAAQ,yBAAyB,SAAS;AAChD,QAAM,SAAS,MAAM,8BAAS,kBAAkB;AAChD,SAAO,SAAS,OAAO,KAAK,GAAG;AAAA;AAHX;AAMf,gBAAgB,OAAc;AACnC,QAAM,QAAQ;AACd,SAAO,MAAK,MAAM;AAAA;AAFJ;AAWhB,oDACE,eACA,aACA;AACA,MAAI,CAAC,OAAO,kBAAkB,CAAC,mBAAmB,cAAc;AAC9D,UAAM,IAAI,MAAM;AAAA;AAElB,QAAM,SAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+BAMe;AAAA,qBACV;AAAA;AAAA,2CAEsB;AAAA;AAAA,6CAEE;AAAA,sBACvB;AAAA;AAAA;AAAA;AAAA;AAKpB,QAAM,8BAAS,kBAAkB;AAAA;AAxBb;AA2BtB,4CAAmD,eAAuB;AACxE,QAAM,SAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+BAoBe;AAAA;AAAA;AAG7B,QAAM,WAAW,MAAM,8BAAS,kBAAkB;AAClD,QAAM,aAAa,SAAS,KAAK,GAAG,SAAS;AAC7C,MAAI,CAAC,WAAW,MAAM;AACpB,eAAW,OAAO;AAAA;AAEpB,aAAW,WAAW,KAAK,MAAM,WAAW;AAC5C,SAAO;AAAA;AA9Ba;AAiCf,2BAA2B,QAAQ;AACxC,MAAI,aAAoB;AACxB,MAAI,QAAQ,CAAC;AACb,MAAI,QAAQ;AAEZ,SAAO,MAAM,QAAQ;AACnB,QAAI,QAAQ,MAAM;AAElB,QAAI,OAAO,UAAU,WAAW;AAC9B,eAAS;AAAA,eACA,OAAO,UAAU,UAAU;AACpC,eAAS,MAAM,SAAS;AAAA,eACf,OAAO,UAAU,UAAU;AACpC,eAAS;AAAA,eACA,OAAO,UAAU,YAAY,WAAW,QAAQ,WAAW,IAAI;AACxE,iBAAW,KAAK;AAEhB,eAAS,KAAK,OAAO;AACnB,cAAM,KAAK,MAAM;AAAA;AAAA;AAAA;AAIvB,SAAO;AAAA;AAtBO;AAyBT,wBAAwB,eAAe;AAC5C,MAAI,eAAe;AACnB,MAAI,YAAY;AAAA,IACd,MAAM;AAAA,IACN,KAAK;AAAA,IACL,MAAM;AAAA,IACN,IAAI;AAAA,IACJ,IAAI;AAAA;AAEN,SAAO,cACJ,QAAQ,cAAc,SAAU,OAAO,QAAQ;AAC9C,WAAO,UAAU;AAAA,KAElB,QAAQ,cAAc,SAAU,OAAO,QAAQ;AAC9C,QAAI,MAAM,SAAS,QAAQ;AAC3B,WAAO,OAAO,aAAa;AAAA;AAAA;AAfjB;AAmBhB,wBAA+B,MAAa,OAAe,IAAI;AAC7D,QAAM,UAAU,SAAS,SAAQ;AACjC,MAAI,cAAc,GAAG;AACnB,YAAQ,IAAI;AAAA;AAEd,QAAM,EAAE,QAAQ,WAAW,MAAM,MAAK,SAAS,EAAE,WAAW,OAAO;AACnE,SAAO;AAAA;AANa;;;ANzVtB,IAAM,kBAAkB,QAAQ,IAAI,8BAA8B;AAElE,IAAM,SAAQ,sBAAW,OAAO;AAAA,EAC9B,SAAS,kBAAkB;AAAA,EAC3B,SAAS;AAAA,IACP,QAAQ;AAAA,MACN,gBAAgB;AAAA;AAAA;AAAA;AAKf,6BAAuB,yBAAU;AAAA,EAAjC,cA5BP;AA4BO;AACL,kBAAiB;AAGV,wBAAe;AACf,oCAA2B;AAAA;AAAA,QAa5B,WAAW,WAAmB;AAClC,QAAI,SAAuC;AAC3C,YAAQ,IAAI,8CAA8C;AAC1D,UAAM,SAAS,MAAM,QAAQ;AAC7B,UAAM,gBAAgB,AAAE,WACtB,aAAa,OAAO,IAAI,OAAO,IAAI,KAAK,cAAc,KAAK;AAE7D,eAAW,WAAU,eAAe;AAClC,YAAM,aAAa,MAAM,KAAK,OAAO,QAAO,IAAI,QAAO;AACvD,iBAAW,MAAM,OAAO,KAAK,aAAa;AACxC,eAAO,MAAM,WAAW;AAAA;AAE1B,UAAI,QAAQ,IAAI,sBAAsB,QAAQ;AAC5C,YAAI,OAAO,KAAK,QAAQ,SAAS;AAAG;AAAA;AAAA;AAGxC,YAAQ,IAAI,YAAY,OAAO,KAAK,QAAQ,8BAA8B;AAC1E,eAAW,MAAM,OAAO,KAAK,SAAS;AACpC,YAAM,KAAK,YAAY,YAAY,CAAC,OAAO;AAAA;AAAA;AAAA,QAIzC,YAAY;AAChB,UAAM,WAAW,MAAM,OAAM,KAAK,wBAAwB;AAAA,MACxD,eAAe;AAAA,MACf,WAAW;AAAA,MACX,OAAO;AAAA;AAET,UAAM,cAAc,SAAS,QAAQ,cAAc,KAAK,CAAC,MAAM,EAAE,SAAS;AAC1E,SAAK,SAAS,YAAY,MAAM,KAAK,GAAG,MAAM,KAAK;AAAA;AAAA,QAG/C,aAAa,SAAc;AAC/B,QAAI,CAAC,KAAK,UAAU,KAAK,UAAU,IAAI;AACrC,YAAM,KAAK;AAAA;AAEb,YAAQ,IAAI,cAAc,kBAAkB,WAAW,KAAK,QAAQ;AACpE,UAAM,WAAW,MAAM,OAAM,KAAK,KAAK,SAAS;AAAA,MAC9C,SAAS;AAAA,QACP,QAAQ,iBAAiB,KAAK;AAAA;AAAA;AAGlC,WAAO,SAAS,KAAK;AAAA;AAAA,QAGjB,OAAO,KAAa,KAAa,MAAe;AA3FxD;AA4FI,QAAI,UAAU;AACd,QAAI,SAAuC;AAC3C,QAAI,OAAO;AACX,YAAQ,IAAI,0BAA0B,QAAQ;AAC9C,WAAO,SAAS;AACd,YAAM,WAAW,MAAM,KAAK,aAAa,KAAK,WAAW,KAAK,KAAK;AACnE,YAAM,UAAU,SAAS,YAAY;AACrC,cAAQ,IAAI,4BAA4B,QAAQ,SAAS;AACzD,UAAI,QAAQ,SAAS,GAAG;AACtB,mBAAW,SAAS,SAAS;AAC3B,cAAI,CAAC,QAAQ,aAAM,SAAN,mBAAY,SAAS,QAAO;AACvC,mBAAO,MAAM,MAAM;AAAA,cACjB,IAAI,MAAM;AAAA,cACV,KAAK,MAAM,SAAS;AAAA,cACpB,KAAK,MAAM,SAAS;AAAA;AAAA;AAAA;AAI1B,gBAAQ;AAAA,aACH;AACL,kBAAU;AAAA;AAAA;AAGd,WAAO;AAAA;AAAA,QAGH,SAAS,OAAmB;AAChC,UAAM,MAAM,KAAK,aAAa,MAAM;AACpC,UAAM,WAAW,MAAM,KAAK,aAAa;AACzC,UAAM,OAAO,SAAS;AACtB,SAAK,IAAI,uBAAuB,KAAK,OAAO;AAC5C,UAAM,iBAAiB,KAAK;AAC5B,UAAM,gBAAgB,MAAM,wBAC1B,YACA,gBACA,MAAM,KACN,MAAM,KACN,KAAK,MACL,KAAK,QAAQ;AAEf,UAAM,KAAK,MAAM,aAAa;AAAA,MAC5B,QAAQ;AAAA,MACR;AAAA,MACA;AAAA,MACA,UAAU;AAAA,QACR,KAAK,MAAM;AAAA,QACX,KAAK,MAAM;AAAA;AAAA,MAEb,MAAM;AAAA,QACJ;AAAA,QACA,OAAO,SAAS;AAAA,QAChB,cAAc,SAAS;AAAA;AAAA;AAG3B,WAAO;AAAA;AAAA,SAGF,kBAAkB,QAAoB;AAC3C,WAAO;AAAA,MACL,MAAM,OAAO,KAAK,KAAK;AAAA,MACvB,SAAS,OAAO,KAAK,KAAK,QAAQ;AAAA;AAAA;AAAA,EAItC,WAAW,KAAa,KAAa,OAAe,GAAG;AACrD,UAAM,YAAW;AACjB,UAAM,SAAS,OAAO;AACtB,WAAO;AAAA,MACL,eAAe;AAAA,MACf,WAAW;AAAA,QACT,WAAW;AAAA,QACX,WAAW;AAAA,QACX;AAAA,QACA,OAAO;AAAA,QACP,OAAO;AAAA;AAAA,MAET,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EA+DX,aAAa,IAAY;AACvB,WAAO;AAAA,MACL,eAAe;AAAA,MACf,WAAW;AAAA,QACT,SAAS;AAAA,QACT,QAAQ;AAAA,QACR,0BAA0B;AAAA,QAC1B,0BAA0B;AAAA;AAAA,MAE5B,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AApNN;AAOE,AAPF,SAOE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AAdF,SAcE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;AO3Cd,qBAAO;AAEP,qBAA0B;AAC1B,oBAAuB;AAEvB,qBAAwB;AAMxB,IAAM,iBAAiB,QAAQ,IAAI,qBAAqB;AAExD,IAAM,SAAQ,sBAAW,OAAO;AAAA,EAC9B,SAAS;AAAA,EACT,SAAS;AAAA,IACP,QAAQ;AAAA,MACN,gBAAgB;AAAA;AAAA;AAAA;AAKf,4BAAsB,yBAAU;AAAA,EAAhC,cAtBP;AAsBO;AACL,sBAAqB;AAGd,wBAAe;AACf,oCAA2B;AAAA;AAAA,QAa5B,WAAW,WAAmB;AAClC,YAAQ,IAAI,6CAA6C;AACzD,QAAI,MAAgB;AACpB,UAAM,SAAS,MAAM,QAAQ;AAC7B,UAAM,gBAAgB,4BACpB,aAAa,OAAO,IAAI,OAAO,IAAI,KAAK,cAAc,KAAK;AAE7D,eAAW,WAAU,eAAe;AAClC,YAAM,cAAc,MAAM,KAAK,OAAO,QAAO,IAAI,QAAO;AACxD,YAAM,MAAM,YAAY,IAAI,CAAC,MAAM,EAAE;AACrC,YAAM,CAAC,GAAG,KAAK,GAAG;AAAA;AAEpB,YAAQ,IAAI,kBAAkB,IAAI;AAClC,eAAW,MAAM,KAAK;AACpB,YAAM,KAAK,YAAY,iBAAiB,CAAC;AAAA;AAAA;AAAA,QAIvC,eAAe;AACnB,UAAM,WAAW,MAAM,OAAM,KAAK,QAAQ;AAAA,MACxC,OAAO;AAAA,MACP,WAAW;AAAA,MACX,OAAO;AAAA;AAET,SAAK,aAAa,SAAS,KAAK,eAAe;AAAA;AAAA,QAG3C,WAAW,MAAc;AAC7B,QAAI,CAAC,KAAK,YAAqC;AAC7C,YAAM,KAAK;AAAA;AAEb,UAAM,WAAW,MAAM,OAAM,IAAI,MAAM;AAAA,MACrC,SAAS;AAAA,QACP,eAAe,YAAY,KAAK;AAAA;AAAA;AAGpC,WAAO,SAAS;AAAA;AAAA,QAGZ,OAAO,KAAa,KAAa;AACrC,QAAI,OAAO;AACX,QAAI,UAAiB;AACrB,QAAI,MAAa;AACjB,WAAO,QAAQ,KAAK,QAAQ,SAAS,GAAG;AACtC,cAAQ,IAAI,0BAA0B,QAAQ;AAC9C,UAAI,OAAO,KAAK,eAAe,KAAK,KAAK;AACzC,YAAM,WAAW,MAAM,KAAK,WAAW;AACvC,YAAM,WAAU,SAAS,cAAc;AACvC,YAAM,CAAC,GAAG,KAAK,GAAG;AAClB,cAAQ;AAAA;AAEV,WAAO;AAAA;AAAA,QAGH,cAAc,IAAY;AAC9B,UAAM,OAAO,KAAK,mBAAmB;AACrC,UAAM,WAAW,MAAM,KAAK,WAAW;AACvC,UAAM,OAAO,SAAS;AACtB,UAAM,iBAAiB,KAAK;AAC5B,UAAM,MAAM,WAAW,KAAK;AAC5B,UAAM,MAAM,WAAW,KAAK;AAC5B,UAAM,gBAAgB,MAAM,wBAC1B,WACA,gBACA,KACA,KACA,KAAK,MACL,KAAK,QAAQ;AAEf,UAAM,aAAa;AAAA,MACjB,QAAQ;AAAA,MACR;AAAA,MACA;AAAA,MACA,UAAU;AAAA,QACR,KAAK;AAAA,QACL;AAAA;AAAA,MAEF,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,SAAS,MAAM,KAAK,WAAW,KAAK;AAAA;AAAA;AAGxC,WAAO;AAAA;AAAA,SAGF,kBAAkB,QAAoB;AAC3C,WAAO;AAAA,MACL,MAAM,OAAO,KAAK,KAAK;AAAA,MACvB,SAAS,OAAO,KAAK,KAAK,QAAQ;AAAA;AAAA;AAAA,QAIhC,WAAW,IAAY;AAC3B,QAAI,OAAO;AACX,QAAI,UAAiB;AACrB,QAAI,MAAa;AACjB,WAAO,QAAQ,KAAK,QAAQ,SAAS,GAAG;AACtC,YAAM,OAAO,KAAK,gBAAgB;AAClC,YAAM,WAAW,MAAM,KAAK,WAAW;AACvC,YAAM,WAAU,SAAS,QAAQ;AACjC,YAAM,CAAC,GAAG,KAAK,GAAG;AAClB,cAAQ;AAAA;AAEV,WAAO;AAAA;AAAA,EAGT,mBAAmB,IAAY;AAC7B,WACE,eAAe;AAAA;AAAA,EAOnB,eAAe,KAAa,KAAa,OAAe,GAAG;AACzD,WACE,iJAGmB,SAAS,uIAGQ;AAAA;AAAA,EAIxC,gBAAgB,IAAY,OAAe,GAAG;AAC5C,UAAM,YAAY;AAClB,WACE,6BAA6B,eAChB,qBAAqB;AAAA;AAAA;AArJjC;AAOE,AAPF,QAOE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AAdF,QAcE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;ACrCd,sBAAO;AAEP,qBAA0B;AAC1B,oBAAuB;AAEvB,qBAAc;AAMd,IAAM,qBAAqB,QAAQ,IAAI,qBAAqB;AAE5D,IAAM,SAAQ,sBAAW,OAAO;AAAA,EAC9B,SAAS;AAAA,EACT,SAAS;AAAA,IACP,QAAQ;AAAA,MACN,wBAAwB;AAAA;AAAA;AAAA;AAK9B,IAAM,eAAe;AAEd,gCAA0B,yBAAU;AAAA,EAczC,cAAc;AACZ;AACA,SAAK,iBAAkB,eAAe,KAAK,KAAK,KAAM;AAAA;AAAA,QAGlD,WAAW,WAAmB;AAClC,YAAQ,IAAI,qDAAqD;AACjE,UAAM,SAAS,MAAM,QAAQ;AAC7B,UAAM,gBAAgB,uBAAE,QAAQ,aAAa,OAAO,IAAI,OAAO,IAAI,cAAc;AACjF,eAAW,cAAc,eAAe;AACtC,YAAM,KAAK,YAAY,kBAAkB,CAAC,EAAE,QAAQ;AAAA;AAAA;AAAA,QAIlD,eAAe;AAAA,IACnB,QAAQ;AAAA,IACR;AAAA,IACA;AAAA,KAKC;AACD,UAAM,WAAW;AACjB,UAAM,QAAQ;AACd,UAAM,OAAO;AACb,UAAM,OAAO;AACb,UAAM,SAAS,OAAO,OAAO,UAAU,OAAO;AAC9C,UAAM,WAAW,iBAAiB,KAAK;AACvC,UAAM,aAAa,UAAU,eAAe;AAC5C,UAAM,OAAO;AACb,UAAM,SAAQ,CAAC,QAAQ,UAAU,YAAY,MAAM,MAAM,KAAK;AAC9D,YAAQ,IAAI,0BAA0B,qBAAqB,OAAO;AAClE,UAAM,WAAW,MAAM,OAAM,IAAI,OAAO;AACxC,UAAM,cAAc,SAAS,KAAK;AAClC,QAAI,eAAe;AACjB,aAAO;AAAA;AAET,eAAW,cAAc,aAAa;AACpC,YAAM,KAAK,sBAAsB;AAAA;AAEnC,QAAI,YAAY,SAAS,GAAG;AAC1B,YAAM,KAAK,YAAY,kBAAkB,CAAC,EAAE,QAAQ,OAAO,QAAQ;AAAA;AAAA;AAAA,QAIjE,sBAAsB,MAAkB;AAC5C,YAAQ,KAAK,yBAAyB,KAAK;AAC3C,UAAM,iBAAiB,KAAK,GAAG;AAC/B,UAAM,MAAM,KAAK,UAAU,YAAY;AACvC,UAAM,MAAM,KAAK,UAAU,YAAY;AACvC,UAAM,gBAAgB,MAAM,wBAC1B,eACA,gBACA,KACA,KACA,KAAK,MACL,KAAK;AAEP,QAAI,QAAQ,IAAI,OAAO;AACrB,cAAQ,IAAI,oBAAoB;AAAA;AAElC,UAAM,KAAK,MAAM,aAAa;AAAA,MAC5B,QAAQ;AAAA,MACR;AAAA,MACA;AAAA,MACA,UAAU;AAAA,QACR;AAAA,QACA;AAAA;AAAA,MAEF,MAAM;AAAA,QACJ,4BAA4B;AAAA;AAAA;AAGhC,WAAO;AAAA;AAAA,SAGF,kBAAkB,QAAoB;AAC3C,WAAO;AAAA,MACL,MAAM,OAAO,KAAK,2BAA2B;AAAA,MAC7C,SAAS,OAAO,KAAK,2BAA2B;AAAA;AAAA;AAAA;AA9F/C;AAGE,AAHF,YAGE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AAVF,YAUE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;ACnCd,sBAAO;AAEP,sBAAgC;AAChC,qBAA0B;AAC1B,oBAAuB;AAMvB,IAAM,kBAAkB,QAAQ,IAAI,kBAAkB;AAEtD,IAAM,SAAQ,sBAAW,OAAO;AAAA,EAC9B,SAAS;AAAA,EACT,SAAS;AAAA,IACP,QAAQ;AAAA,MACN,wBAAwB;AAAA;AAAA;AAAA;AAKvB,6BAAuB,yBAAU;AAAA,EAYtC,cAAc;AACZ;AACA,YAAQ,IAAI,8CAA8C;AAAA;AAAA,QAGtD,IAAI,OAAe,GAAG,QAAQ,UAAU,MAAe;AAC3D,UAAM,CAAC,KAAK,QAAQ,KAAK,aAAa;AACtC,UAAM,WAAW,MAAM,OAAM,KAAK,KAAe;AACjD,UAAM,cAAc,SAAS,KAAK,QAAQ,GAAG;AAC7C,eAAW,CAAC,OAAO,eAAe,YAAY,WAAW;AACvD,UAAI,SAAS,OAAO;AAClB;AAAA;AAEF,UAAI;AACF,cAAM,EAAE,SAAS,MAAM,KAAK,eAAe;AAC3C,YAAI,QAAQ,SAAS,MAAM;AACzB;AAAA;AAAA,eAEK,GAAP;AACA,gBAAQ,IAAI,kBAAkB;AAC9B,6CAAgB,GAAG;AAAA,UACjB,MAAM,CAAC;AAAA,UACP,QAAQ,KAAK;AAAA;AAAA;AAAA;AAInB,SAAK,IAAI,OAAO,YAAY;AAC5B,QAAI,YAAY,SAAS,KAAK,QAAQ,IAAI,YAAY,QAAQ;AAC5D,YAAM,KAAK,YAAY,OAAO,CAAC,OAAO;AAAA;AAAA;AAAA,EAI1C,aAAa,MAAc;AACzB,UAAM,UACJ;AAIF,UAAM,OAAO;AAAA,MACX,UAAU;AAAA,QACR;AAAA,UACE,WAAW;AAAA,UACX,QACE,qYAMwC;AAAA;AAAA;AAAA;AAOhD,WAAO,CAAC,kBAAkB,SAAS;AAAA;AAAA,QAG/B,eAAe,MAAkB;AACrC,QAAI,QAAQ,IAAI,sBAAsB,QAAQ;AAC5C,cAAQ,KAAK,sBAAsB,KAAK;AAAA;AAE1C,UAAM,iBAAiB,KAAK;AAC5B,UAAM,MAAM,KAAK,QAAQ;AACzB,UAAM,MAAM,KAAK,QAAQ;AAEzB,UAAM,gBAAgB,MAAM,wBAC1B,YACA,gBACA,KACA,KACA,KAAK,MACL,KAAK,iBAAiB,OAAO;AAE/B,SAAK,IAAI,cAAc,KAAK,OAAO,MAAM;AACzC,UAAM,KAAK,MAAM,aAAa;AAAA,MAC5B,QAAQ;AAAA,MACR;AAAA,MACA;AAAA,MACA,UAAU;AAAA,QACR;AAAA,QACA;AAAA;AAAA,MAEF,MAAM;AAAA,QACJ,MAAM;AAAA;AAAA;AAIV,WAAO,EAAE,IAAI,MAAM,KAAK;AAAA;AAAA,SAGnB,kBAAkB,QAAoB;AAC3C,WAAO;AAAA,MACL,MAAM,OAAO,KAAK,KAAK;AAAA,MACvB,SAAS,OAAO,KAAK,KAAK,iBAAiB,OAAO;AAAA;AAAA;AAAA;AA3GjD;AACE,AADF,SACE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AARF,SAQE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;AC9Bd,sBAAO;AAGP,sBAAgC;AAChC,oBAAoD;AACpD,qBAA2C;AAC3C,YAAuB;AACvB,oBAAkB;AAElB,cAAyB;AACzB,qBAAc;AAQd,IAAM,wBAAwB;AAC9B,IAAM,yBAAyB,QAAQ,IAAI,qBAAqB;AAChE,IAAM,gBAAgB;AAAA,EACpB,wBAAwB;AAAA,EACxB,cAAc;AAAA,EACd,mBAAmB;AAAA,EACnB,mBAAmB;AAAA;AAGrB,IAAM,iBAAiB,IAAI,+BACzB,uBACA,QAAQ,IAAI,qBAAqB,IACjC,EAAE,SAAS;AAGN,iCAA0B,yBAAU;AAAA,EAApC,cAjCP;AAiCO;AAEE,wBAAe;AACf,oCAA2B;AAC3B,oCAA2B;AAAA;AAAA,QAe5B,WAAW,WAAmB;AAClC,YAAQ,IAAI,iDAAiD;AAC7D,UAAM,SAAS,MAAM,QAAQ;AAC7B,UAAM,gBAAgB,uBAAE,QACtB,aAAa,OAAO,IAAI,OAAO,IAAI,KAAK,cAAc,KAAK;AAE7D,eAAW,WAAU,eAAe;AAClC,YAAM,KAAK,YAAY,kBAAkB,CAAC,QAAO,IAAI,QAAO,IAAI;AAAA;AAAA;AAAA,QAI9D,eAAe,KAAa,KAAa;AAC7C,UAAM,OACJ;AAGF,UAAM,aAAa,aAAa,KAAK,mBAAmB,KAAK;AAC7D,UAAM,SAAS,OAAO,OAAO;AAC7B,UAAM,MAAM,yBAAyB,OAAO,aAAa;AACzD,UAAM,WAAW,MAAM,sBAAM,IAAI,KAAK,EAAE,SAAS;AAEjD,eAAW,QAAQ,SAAS,KAAK,aAAa;AAC5C,YAAM,KAAK,YAAY,iBAAiB,CAAC,KAAK;AAC9C,UAAI,KAAK;AAA0B;AAAA;AAAA;AAAA,QAIjC,cAAc,MAAc;AAChC,SAAK,YAAY,KAAK,gBAAgB;AACtC,UAAM,WAAW,MAAM,eAAe,IAAI;AAC1C,UAAM,OAAO,MAAM,SAAS;AAC5B,QAAI,OAAO,KAAK,yBAAyB;AACzC,UAAM,YAAY,MAAM,KAAK,eAAe;AAC5C,QAAI,CAAC;AAAW,YAAM,IAAI,MAAM;AAChC,UAAM,KAAK,WAAW;AACtB,UAAM,KAAK,YAAY,MAAM,WAAW,GAAG;AAC3C,SAAK,IAAI,IAAI,KAAK;AAAA;AAAA,QAGd,eAAe,MAAkB;AACrC,UAAM,WAAW,KAAK,aAAa;AACnC,UAAM,OAAO,KAAK,SAAS;AAC3B,QAAI,QAAQ,IAAI,sBAAsB,QAAQ;AAC5C,cAAQ,KAAK,yBAAyB,SAAS;AAAA;AAEjD,UAAM,iBAAiB,SAAS,SAAS;AACzC,UAAM,MAAM,SAAS,SAAS;AAC9B,UAAM,MAAM,SAAS,SAAS;AAC9B,UAAM,kBAAkB,aAAY,UAAU,SAAS;AACvD,SAAK,kBAAkB;AACvB,UAAM,gBAAgB,MAAM,wBAC1B,eACA,gBACA,KACA,KACA,iBACA,SAAS,QAAQ;AAEnB,QAAI,QAAQ,IAAI,sBAAsB,QAAQ;AAC5C,cAAQ,IAAI,iDAAiD;AAAA;AAE/D,UAAM,KAAK,MAAM,aAAa;AAAA,MAC5B,QAAQ;AAAA,MACR;AAAA,MACA;AAAA,MACA,UAAU;AAAA,QACR;AAAA,QACA;AAAA;AAAA,MAEF,MAAM;AAAA,QACJ;AAAA,QACA;AAAA;AAAA;AAGJ,WAAO;AAAA;AAAA,SAGF,kBAAkB,QAAoB;AAC3C,WAAO;AAAA,MACL,MAAM,aAAY,UAAU,OAAO,KAAK,SAAS;AAAA,MACjD,SAAS,OAAO,KAAK,SAAS,QAAQ;AAAA;AAAA;AAAA,QAIpC,YAAY,MAAc,WAAmB,MAAc,OAAe,IAAI;AAClF,UAAM,WAAW,MAAM,eAAe,IAAI;AAC1C,WAAO,MAAM,SAAS;AACtB,UAAM,OAAO,MAAM,KAAK,mBAAmB,MAAM,WAAW,MAAM;AAClE,QAAI,MAAM;AACR;AACA,UAAI,QAAQ,GAAG;AACb,eAAO,KAAK,QAAQ,aAAa,cAAc,OAAO;AAAA,aACjD;AACL,eAAO,KAAK,QAAQ,uBAAuB,cAAc,OAAO;AAAA;AAElE,YAAM,KAAK,YAAY,eAAe,CAAC,MAAM,WAAW;AAAA;AAAA;AAAA,QAOtD,iBAAiB,MAAc,OAAe,IAAI;AACtD,QAAI,OAAO;AACX,QAAI,QAAQ;AACZ,UAAM,YAAY;AAClB,UAAM,SACJ,QAAQ,IAAI,kCACZ,MACA,QAAQ,IAAI,sCACZ,MACA,QAAQ,IAAI,sBACZ,MACA,QAAQ,IAAI;AACd,WAAO,QAAQ,WAAW;AACxB,UAAI;AACF,eAAO,MAAM,SACX,wBAAwB,MACxB,OAAO,MAAM,CAAC,gBAAgB,oBAAoB,WAAU,KAAK;AAAA,eAE5D,OAAP;AACA,YAAI,CAAC,MAAM,QAAQ,SAAS,cAAc;AACxC,gBAAM,IAAI,MAAM;AAAA;AAAA;AAIpB,UAAI,KAAK,SAAS,KAAM;AACtB,eAAO;AAAA,aACF;AACL,gBAAQ,IAAI;AACZ,aAAK,IAAI,0CAA0C;AAAA;AAErD,eAAS;AAAA;AAEX,UAAM,IAAI,MAAM,gBAAgB,WAAW;AAAA;AAAA,QAGvC,WAAW,WAAmB;AAClC,QAAI,OAAO;AACX,QAAI,SAAgB;AACpB,WAAO,MAAM;AAEX,YAAM,SAAS,MAAM,KAAK,eAAe;AACzC,UAAI,CAAC;AAAQ;AACb,YAAM,QAAQ;AACd,eAAS,CAAC,GAAG,QAAQ,GAAG;AACxB;AAAA;AAEF,UAAM,OAAO,OAAO,IAAI,CAAC,MAAM,EAAE;AACjC,UAAM,gBAAgB,WAAW;AAAA,MAC/B,QAAQ;AAAA,MACR,sBAAsB;AAAA;AAAA;AAAA,QAIpB,eAAe,OAAO,GAAG;AAC7B,QAAI,cAAc,GAAG;AACnB,WAAK,IAAI,uBAAuB;AAAA;AAElC,UAAM,OAAO,KAAK,gBAAgB;AAClC,UAAM,WAAW,MAAM,sBAAM,IAAI,yBAAyB,MAAM;AAAA,MAC9D,SAAS,OAAO,OAAO,eAAe,EAAE,oBAAoB;AAAA;AAE9D,UAAM,OAAO,SAAS;AACtB,UAAM,IAAI,AAAQ,aAAK;AACvB,UAAM,SAAS,EAAE;AACjB,QAAI,SAAgB;AACpB,UAAM,qBAAqB;AAC3B,QAAI,KAAK,SAAS,qBAAqB;AACrC,aAAO;AAAA;AAET,aAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,YAAM,QAAQ,EAAE,OAAO;AACvB,YAAM,OAAM,EAAE,OAAO,KAAK;AAC1B,UAAI,UAAU,EAAE,OAAO,KAAK;AAC5B,UAAI,SAAS;AACX,kBAAU,eAAe;AAAA;AAE3B,aAAO,KAAK;AAAA,QACV;AAAA,QACA;AAAA;AAAA;AAGJ,WAAO;AAAA;AAAA,EAGT,gBAAgB,OAAO,GAAG;AACxB,QAAI,OAAO;AACX,UAAM,SAAS,OAAO;AACtB,UAAM,SAAS;AAAA,MACb,YAAY,KAAK;AAAA,MACjB;AAAA,MACA;AAAA,MACA;AAAA,MACA,YAAY;AAAA,MACZ,KAAK;AACP,WAAO,OAAO;AAAA;AAAA,EAGhB,gBAAgB,MAAc;AAC5B,UAAM,KAAK,IAAI,OAAO;AACtB,QAAI,UAAU,GAAG,KAAK;AACtB,QAAI,CAAC;AAAS,YAAM;AACpB,UAAM,YAAY,QAAQ;AAC1B,WAAO;AAAA;AAAA,SAGF,UAAU,MAAc;AAC7B,QAAI,wBAAwB,KAAK,MAAM;AACvC,0BAAsB;AACtB,WAAO,sBAAsB,KAAK;AAAA;AAAA,QAGtB,mBAAmB,MAAc,WAAmB,MAAc,MAAc;AAC5F,QAAI,QAAQ,IAAI,YAAY,gBAAgB,OAAO,GAAG;AACpD,WAAK,IAAI;AACT,aAAO;AAAA;AAET,UAAM,EAAE,MAAM,MAAM,gBAAgB,MAAM,KAAK,gBAAgB,MAAM;AACrE,QAAI,CAAC;AAAa,aAAO;AACzB,QAAI,cAA0B;AAC9B,gBAAY,aAAa,QAAQ;AACjC,UAAM,gBAAgB,WAAW;AACjC,WAAO;AAAA;AAAA,QAGK,gBAAgB,MAAc,MAAc;AACxD,UAAM,OAAO,MAAM,KAAK,eAAe,MAAM;AAC7C,QAAI,CAAC,KAAK,MAAM;AACd,aAAO;AAAA;AAET,UAAM,eAAe,KAAK;AAC1B,UAAM,IAAI,AAAQ,aAAK;AACvB,UAAM,UAAU,EAAE;AAClB,QAAI,OAAqB;AACzB,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,YAAM,SAAS,EAAE,QAAQ;AACzB,WAAK,KAAK;AAAA,QAER,UAAU,OAAO,KAAK,gCAAgC;AAAA,QACtD,QAAQ,KAAK,sBAAsB;AAAA,QACnC,OAAO,OAAO,KAAK,oBAAoB;AAAA,QACvC,MAAM,OAAO,KAAK,kBAAkB;AAAA,QACpC,MAAM,OAAO,KAAK,eAAe,KAAK;AAAA;AAAA;AAG1C,WAAO,EAAE,MAAM,KAAK,MAAM;AAAA;AAAA,QAGd,eAAe,MAAc,cAAsB;AAC/D,QAAI,MAAgB;AACpB,UAAM,IAAI,AAAQ,aAAK;AACvB,UAAM,UAAU,EAAE;AAClB,QAAI,OAAO;AACX,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,YAAM,SAAS,EAAE,QAAQ;AACzB,YAAM,KAAK,OAAO,KAAK,mBAAmB,KAAK;AAC/C,UAAI,CAAC;AAAI;AACT,UAAI,KAAK;AAAA;AAEX,QAAI,IAAI,UAAU,GAAG;AACnB,aAAO,EAAE,MAAM,OAAO,MAAM;AAAA;AAE9B,UAAM,OAAO;AACb,UAAM,eAAe,MAAM,KAAK,gBAAgB,MAAM,cAAc;AAEpE,QAAI;AACF,UAAI,CAAC,EAAE,2BAA4B,KAAK,SAAU,SAAS,aAAa;AACtE,eAAO;AAAA;AAAA,aAEF,OAAP;AAEA,2CAAgB;AAAA;AAElB,WAAO,EAAE,MAAM,MAAM;AAAA;AAAA,QAGT,gBAAgB,MAAc,cAAsB,KAAe;AAC/E,UAAM,OAAO;AAAA,MACX;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,gBAAgB,wBAAwB;AAAA,MACxC,uBAAuB,IAAI,KAAK;AAAA,MAChC,KAAK;AACP,UAAM,OAAO,MAAM,SAAS,yBAAyB,MAAM;AAC3D,WAAO;AAAA;AAAA,QAIK,qBAAqB,MAAa,cAAsB,KAAe;AACnF,UAAM,UAAU;AAAA,MACd,QAAQ;AAAA,MACR,MAAM,WAAW,IAAI,KAAK;AAAA,MAC1B,SAAS;AAAA,MACT,SAAS,iCACJ,gBADI;AAAA,QAEP,oBAAoB;AAAA,QACpB,SAAS,wBAAwB;AAAA;AAAA;AAGrC,UAAM,WAAW,MAAM,eAAe,IAAI,MAAK;AAC/C,UAAM,OAAO,MAAM,SAAS;AAC5B,WAAO;AAAA;AAAA,EAGD,sBAAsB,QAAa;AACzC,QAAI,SAAwB;AAC5B,UAAM,UAAU,OAAO,KAAK,qBAAqB,KAAK,SAAU,MAAM;AAEtE,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,YAAM,YAAY,QAAQ;AAC1B,UAAI,UAAU,WAAW,YAAY;AACnC,iBAAS,SAAS,UAAU,MAAM,KAAK,MAAM;AAAA;AAAA;AAGjD,WAAO;AAAA;AAAA,EAGD,aAAa,MAAkB;AApXzC;AAqXI,UAAM,YAAY,iBAAK,UAAL,mBAAY,SAAZ,mBAAkB;AACpC,UAAM,OAAO,KAAK,SAAS,OAAO;AAClC,UAAM,WAAW,KAAK,wBAAwB,sBAAsB;AACpE,WAAO;AAAA;AAAA,EAGD,SAAS,MAAkB;AA3XrC;AA4XI,QAAI,OAAmB;AACvB,UAAM,MAAM;AACZ,eAAW,MAAM,KAAK,cAAc;AAClC,YAAM,UAAU,KAAK,aAAa;AAClC,UAAI,cAAQ,YAAR,mBAAiB,eAAe,MAAM;AACxC,eAAO,QAAQ,QAAQ;AAAA;AAAA;AAG3B,WAAO;AAAA;AAAA,EAGD,yBAAyB,MAAc;AAC7C,UAAM,YAAY;AAClB,QAAI,gBAAgB;AACpB,eAAW,QAAQ,KAAK,MAAM,OAAO;AACnC,UAAI,KAAK,SAAS,YAAY;AAC5B,wBAAgB;AAChB;AAAA;AAAA;AAGJ,QAAI,iBAAiB,IAAI;AACvB,YAAM,IAAI,AAAQ,aAAK;AACvB,YAAM,SAAS,EAAE,UAAU;AAC3B,YAAM,MAAM,AAAM,YAAM;AACxB,YAAM,QAAQ,IAAI,QAAQ,GAAG,WAAW,MAAM,WAAW,GAAG;AAC5D,YAAM,OAAO,OAAQ,UAAU,MAAM,OAAO,MAAM;AAClD,aAAO,KAAK,MAAM;AAAA,WACb;AACL,aAAO;AAAA;AAAA;AAAA;AAvXN;AAAA;AAQE,AARF,YAQE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AAfF,YAeE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;ACjDd,sBAAO;AAEP,qBAA0B;AAC1B,oBAA0C;AAE1C,qBAAc;;;ACLd,IAAO,qBAAQ;AAAA,EACb,MAAM;AAAA,IACJ,QAAQ;AAAA,IACR,MAAM;AAAA,MACJ,YAAY;AAAA,QACV;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UACE;AAAA;AAAA,QAEJ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA,QAEZ;AAAA,UACE,OAAO;AAAA,UACP,cAAc;AAAA,UACd,MAAM;AAAA,UACN,UAAU;AAAA;AAAA;AAAA,MAGd,UAAU;AAAA,MACV,aAAa;AAAA;AAAA;AAAA;;;ADtsBnB,IAAM,kBAAkB,QAAQ,IAAI,kBAAkB;AACtD,IAAM,SAAS;AACf,IAAM,SAAS;AACf,IAAM,OAAO;AACb,IAAM,QAAQ;AACd,IAAM,WAAW;AAEjB,IAAM,SAAQ,sBAAW,OAAO;AAAA,EAC9B,SAAS,kBAAkB;AAAA,EAC3B,SAAS;AAAA,IACP,QAAQ;AAAA,MACN,gBAAgB;AAAA;AAAA;AAAA;AAKf,8BAAuB,yBAAU;AAAA,MAclC,UAAU;AACZ,WAAO;AAAA;AAAA,QAGH,QAAQ;AACZ,SAAK,IAAI,qCAAqC;AAC9C,UAAM,WAAW,MAAM,OAAM,KAAK,QAAQ;AAC1C,UAAM,YAAY,uBAAE,QAAQ,SAAS,KAAK,KAAK,aAAa;AAC5D,aAAS,WAAW,WAAW;AAC7B,YAAM,eAAe,QAAQ,KAAK,MAAM,KAAK;AAC7C,YAAM,SAAS,iBAAiB;AAChC,YAAM,YAAW,MAAM,OAAM,KAAK,SAAS,QAAQ;AACnD,YAAM,SAAS,uBAAE,QAAQ,UAAS,KAAK,KAAK,UAAU;AACtD,eAAS,QAAQ,QAAQ;AACvB,cAAM,KAAK,YAAY,WAAW,CAAC,GAAG,KAAK,UAAU,QAAQ;AAAA;AAAA;AAAA;AAAA,QAK7D,QAAQ,MAAc;AAC1B,SAAK,IAAI,mBAAmB;AAC5B,UAAM,SAAS,MAAM,QAAQ;AAC7B,UAAM,KAAK,YAAY,gBAAgB,CAAC,OAAO,IAAI,OAAO;AAAA;AAAA,QAGtD,aAAa,KAAa,KAAa;AAC3C,UAAM,6BAA6B;AACnC,UAAM,aAAa,aAAa,KAAK,KAAK,UAAS,iBAAiB;AACpE,aAAS,UAAU,YAAY;AAC7B,YAAM,KAAK,YAAY,eAAe,CAAC,GAAG,IAAI,OAAO,IAAI,OAAO;AAAA;AAAA;AAAA,QAI9D,YAAY,QAAgB,UAAkB,KAAa,KAAa;AAC5E,SAAK,IAAI,4BAA4B,QAAQ,mBAAmB,sBAAsB;AACtF,UAAM,WAAW,MAAM,OAAM,KAC3B,OAAO,QACP;AAAA,MACE,UAAU;AAAA,QACR;AAAA,QACA,UAAU;AAAA;AAAA,MAEZ,WAAW;AAAA,OAEb;AAAA,MACE,SAAS;AAAA,QACP,QAAQ,cAAc,KAAK,eAAe,KAAK;AAAA;AAAA;AAKrD,UAAM,KAAK,2BAA2B,UAAU,QAAQ;AAExD,QAAI,SAAS,KAAK,KAAK,KAAK,SAAS;AACnC,YAAM,KAAK,YAAY,eAAe,CAAC,SAAS,KAAK,KAAK,KAAK,QAAQ,UAAU,KAAK;AAAA;AAAA;AAAA,QAIpF,2BAA2B,UAAyB,QAAgB,UAAkB;AAC1F,UAAM,QAAQ,SAAS,KAAK,KAAK;AACjC,SAAK,IACH,MAAM,SAAS,2BAA2B,SAAS,KAAK,sBAAsB,WAAW;AAG3F,aAAS,QAAQ,OAAO;AACtB,UAAI,KAAK,QAAQ,SAAS;AACxB,cAAM,KAAK,YAAY,iBAAiB,CAAC,KAAK;AAAA;AAAA;AAAA;AAAA,QAK9C,cAAc,OAAc;AAChC,UAAM,WAAW,MAAM,OAAM,KAC3B,OACA,EAAE,WAAW,SACb;AAAA,MACE,SAAS;AAAA,QACP,gBAAgB;AAAA;AAAA;AAItB,UAAM,OAAO,SAAS,KAAK;AAC3B,UAAM,YAAY,MAAM,KAAK,eAAe,MAAM;AAClD,QAAI,WAAW;AACb,YAAM,KAAK,UAAU,MAAM;AAAA;AAAA;AAAA,QAIjB,eAAe,MAAW,OAAc;AACpD,SAAK,IAAI,wBAAwB,KAAK;AACtC,UAAM,gBAAgB,MAAM,wBAC1B,YACA,OACA,KAAK,SAAS,WACd,KAAK,SAAS,UACd,KAAK,OACL,KAAK,SAAS;AAEhB,UAAM,SAAS,MAAM,KAAK,WAAW,OAAM,MAAM;AACjD,WAAO;AAAA;AAAA,SAGF,kBAAkB,QAAoB;AAC3C,WAAO;AAAA,MACL,MAAM,OAAO,KAAK,KAAK;AAAA,MACvB,SAAS,OAAO,KAAK,KAAK,SAAS;AAAA;AAAA;AAAA,QAIzB,WAAW,OAAc,MAAW,cAAsB;AACtE,UAAM,KAAK,MAAM,aAAa;AAAA,MAC5B,QAAQ;AAAA,MACR,gBAAgB;AAAA,MAChB,MAAM;AAAA,QACJ,MAAM;AAAA;AAAA,MAER,UAAU;AAAA,QACR,KAAK,KAAK,SAAS;AAAA,QACnB,KAAK,KAAK,SAAS;AAAA;AAAA,MAErB,eAAe;AAAA;AAEjB,WAAO;AAAA;AAAA,QAGK,UAAU,MAAW,WAAmB;AACpD,QAAI,SAAS,CAAC;AACd,eAAW,OAAO,KAAK,oBAAoB;AACzC,iBAAW,OAAO,KAAK,mBAAmB,MAAM;AAC9C,eAAO,KAAK,KAAK,mBAAmB,KAAK;AAAA;AAAA;AAG7C,UAAM,gBAAgB,WAAW,EAAE;AAAA;AAAA,EAG7B,eAAe,KAAa,KAAa;AAG/C,UAAM,oBAAoB;AAAA,MACxB,SAAS;AAAA,QACP,UAAU;AAAA;AAAA,MAEZ,UAAU;AAAA,MACV,WAAW;AAAA,MACX,WAAW;AAAA,MACX,eAAe;AAAA,MACf,MAAM;AAAA,MACN,QAAQ;AAAA;AAEV,WAAO,mBAAmB,KAAK,UAAU;AAAA;AAAA,EAInC,iBAAiB;AACvB,WAAO,mBAAW,KAAK,KAAK,WAAW,IAAI,CAAC,QAAa;AACvD,aAAO,IAAI;AAAA;AAAA;AAAA;AAzKV;AAAA;AACE,AADF,SACE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AARF,SAQE,aAAyB;AAAA,EAC9B,UAAU;AAAA;AAGL,AAZF,SAYE,kBAAkB;;;AExC3B,iBAAgB;AAEhB,oBAAsB;AACtB,sBAA8B;AAC9B,oBAAsD;AACtD,2BAAuB;AACvB,sBAAmE;AAEnE,qBAAc;;;ACRd,oBAAiC;AACjC,2BAA0B;AAmBnB,0BAAoB;AAAA,SAClB,MAAM;AACX,UAAM,OAAO,IAAI;AACjB,SAAK,UAAU,qBAAqB;AAAA;AAAA,eAGzB,iBAAiB,MAAY;AACxC,UAAM,SAAQ;AAAA;AAAA;AAAA;AAAA;AAKd,YAAQ,IAAI;AACZ,UAAM,UAAU,MAAM,+BAAU,MAAM;AACtC,eAAW,OAAO,QAAQ,MAAM;AAC9B,YAAM,KAAK,YAAY,uBAAuB,CAAC,IAAI;AAAA;AAErD,YAAQ,KAAK;AAAA;AAAA,eAGF,mBAAmB,IAAY;AAC1C,QAAI;AACJ,UAAM,SAAS,MAAM,oBAAoB;AACzC,QAAI;AAEJ,QAAI,OAAO,uBAAuB;AAChC,cAAQ,IAAI,oCAAoC,OAAO;AACvD;AAAA;AAEF,QAAI,CAAC,OAAO,KAAK,MAAM;AACrB,cAAQ,KAAK,qDAAqD,OAAO;AACzE,YAAM,cAAc,aAAa,OAAO;AACxC;AAAA;AAEF,YAAQ,IAAI,iCAAiC,OAAO;AACpD,UAAM,QAAQ,KAAK,kBAAkB;AACrC,QAAI,CAAC,YAAY,eAAe,MAAM,kBACpC,MAAM,MACN,MAAM,SACN,OAAO,SAAS,KAChB,OAAO,SAAS;AAElB,QAAI,CAAC,YAAY;AACf,cAAQ,KAAK,4CAA4C,OAAO;AAChE,YAAM,OAAO;AAAA,QACX,MAAM,MAAM;AAAA,QACZ,SAAS,MAAM;AAAA,QACf,UAAU;AAAA,UACR,MAAM;AAAA,UACN,aAAa,CAAC,OAAO,SAAS,KAAK,OAAO,SAAS;AAAA;AAAA,QAErD;AAAA;AAEF,YAAM,CAAC,eAAe,MAAM,oCAAiB,CAAC;AAC9C,mBAAa;AAAA;AAEf,oBAAgB,WAAW;AAC3B,QAAI,iBAAiB,OAAO,eAAe;AACzC,cAAQ,IAAI,2BAA2B,OAAO;AAC9C,cAAQ,IAAI,oBAAoB,kCAAkC,OAAO;AACzE,eAAQ;AAAA;AAAA,2BAEa,WAAW;AAAA;AAAA,gCAEN,OAAO;AAAA;AAEjC,YAAM,+BAAU,MAAM;AACtB,cAAQ,IAAI,wBAAwB,MAAM,UAAU,OAAO;AAAA,WAEtD;AACL,cAAQ,IAAI,kBAAkB,OAAO;AACrC,eAAQ;AAAA;AAAA;AAAA,gCAGkB,OAAO;AAAA;AAEjC,YAAM,+BAAU,MAAM;AAAA;AAAA;AAAA,eAIb,aAAa,IAAwB;AAChD,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM;AAAA;AAElB,UAAM,SAAQ,kCAAkC;AAChD,UAAM,+BAAU,MAAM;AAAA;AAAA;AArFnB;AAyFP,IAAI,QAAQ,SAAS,QAAQ;AAC3B,gBAAc;AAAA;;;AD1ET,IAAM,cAAc;AACpB,IAAM,qBAAqB;AAE3B,IAAM,UAAU,IAAI,gCAAgB,aAAa,QAAQ,IAAI,kBAAkB,aAAa;AAAA,EACjG,SAAS;AAAA,IACP,wBAAwB;AAAA;AAAA,EAE1B,SAAS;AAAA;AAGJ,IAAM,gBAAgB,IAAI,gCAC/B,oBACA,QAAQ,IAAI,yBAAyB,oBACrC;AAAA,EACE,SAAS;AAAA,IACP,wBAAwB;AAAA,IACxB,cACE;AAAA;AAAA,EAEJ,SAAS;AAAA;AAIN,0BAAmB,0BAAU;AAAA,EAA7B,cA3DP;AA2DO;AAEL,qBAAuC;AACvC,oCAA2B,IAAI;AAAA;AAAA,MAa3B,UAAU;AA3EhB;AA4EI,WAAO,QAAQ,KAAK,oBAAoB,YAAK,cAAL,mBAAgB,SAAQ;AAAA;AAAA,QAG5D,YAAY,MAAc;AA/ElC;AAgFI,UAAM,OAAO,MAAM,4BAAS,MAAM;AAChC,aAAO,oBACJ,WAAW;AAAA,QACV,OAAO;AAAA,UACL,MAAM;AAAA,YACJ,KAAK;AAAA;AAAA;AAAA,SAIV,IAAI,CAAC,MAAM;AACV,eAAO;AAAA,UACL,MAAM,EAAE;AAAA,UACR,IAAI,EAAE;AAAA,UACN,MAAM,EAAE;AAAA,UACR,SAAS,EAAE;AAAA,UACX,UAAU,EAAE;AAAA,UACZ,SAAS,EAAE;AAAA;AAAA,SAEZ;AAAA;AAEP,QAAI,CAAC,8BAAM,OAAM;AACf,WAAK,IAAI;AACT;AAAA;AAEF,UAAM,KAAK;AACX,UAAM,CAAC,KAAK,OAAO,YAAK,aAAL,mBAAe,gBAAe;AACjD,QAAI,OAAO,KAAK;AACd,UAAI;AACF,cAAM,KAAK,eAAe;AAAA,UACxB,WAAW,CAAC,MAAM,IAAI,MAAM;AAAA,UAC5B,aAAa,CAAC,MAAM,IAAI,MAAM;AAAA,UAC9B,OAAO;AAAA,UACP,gBAAgB;AAAA;AAAA,eAEX,KAAP;AACA,aAAK,IACH,2EACA,IAAI,SACJ,IAAI;AAGN,cAAM,KAAK,iBAAiB;AAAA;AAAA,WAEzB;AACL,WAAK,IAAI,iBAAiB,KAAK;AAE/B,YAAM,KAAK,iBAAiB;AAAA;AAAA;AAAA,QAI1B,iBAAiB,MAAkB;AAlI3C;AAmII,QAAI,CAAC,KAAK,SAAS;AACjB,WAAK,IAAI;AACT;AAAA;AAEF,UAAM,QAAQ,KAAK,QAAQ,MAAM;AACjC,UAAM,OAAO,MAAM,MAAM,MAAM,SAAS,GAAG,MAAM,QAAQ,KAAK;AAC9D,UAAM,OAAO,iCAAO,KAAK,MAAM,QAAQ,eAAe;AAEtD,UAAM,YAAY,mCAAmC,mBAAmB,+CAA+C,mBAAmB;AAC1I,SAAK,IAAI,4BAA4B,cAAc;AACnD,UAAM,MAAW,MAAM,QAAQ,QAAQ;AACvC,UAAM,cAAc,iCAAK,aAAL,mBAAe,QAAQ,CAAC,MAAW,EAAE;AACzD,QAAI,CAAC,aAAa;AAChB,YAAM,IAAI,MAAM,gBAAgB,KAAK,UAAU,OAAO;AAAA;AAExD,UAAM,UAAU,iBAAK,YAAL,mBAAc,SAAd,mBAAoB;AACpC,UAAM,SAAS,iCAAO,MAAM,MAAM,GAAG,MAAM,SAAS,GAAG,KAAK,OAAO;AACnE,SAAK,IAAI,mBAAmB,SAAS,QAAQ,KAAK,UAAU;AAC5D,UAAM,QAAQ,YAAY,KAAK,CAAC,MAAW;AACzC,UAAI,SAAS;AACX,eAAO,QAAQ,SAAS,EAAE;AAAA;AAE5B,UAAI,QAAQ;AAEV,eAAO,OAAO,SAAS,iCAAO,EAAE,UAAU;AAAA;AAE5C,aAAO;AAAA;AAET,QAAI,CAAC,OAAO;AACV,WAAK,IAAI;AACT;AAAA;AAEF,UAAM,KAAK;AACX,SAAK,IAAI,SAAS,KAAK,UAAU,SAAS;AAC1C,UAAM,CAAC,KAAK,OAAO,MAAM,QAAQ,MAAM;AACvC,SAAK,IAAI,kCAAkC,KAAK,UAAU,EAAE,KAAK;AACjE,UAAM,KAAK,eAAe;AAAA,MACxB,WAAW,CAAC,MAAM,IAAI,MAAM;AAAA,MAC5B,aAAa,CAAC,MAAM,IAAI,MAAM;AAAA,MAC9B,OAAO;AAAA,MACP,gBAAgB;AAAA;AAAA;AAAA,QAId,WAAW,WAAmB;AAClC,SAAK,IAAI,qBAAqB,gCAAgC,QAAQ,IAAI;AAC1E,UAAM,gBAAe;AACrB,UAAM,SAAS,MAAM,QAAQ;AAC7B,UAAM,gBAAgB,uBAAE,QAAQ,aAAa,OAAO,IAAI,OAAO,IAAI,eAAc;AACjF,UAAM,iBAAkB,gBAAe,KAAK,KAAK,KAAM;AACvD,eAAW,cAAc,eAAe;AACtC,YAAM,eAAe,sBAAsB,WAAW,IAAI,WAAW,IAAI;AACzE,YAAM,KAAK,YAAY,kBAAkB;AAAA,QACvC;AAAA,UACE,WAAW,aAAa;AAAA,UACxB,aAAa,aAAa;AAAA,UAC1B,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA,QAMT,eAAe;AAAA,IACnB;AAAA,IACA;AAAA,IACA,QAAQ;AAAA,IACR,iBAAiB;AAAA,IAEjB,WAAW;AAAA,KACU;AACrB,UAAM,SAAS,CAAC,UAAU,IAAI,UAAU,IAAI,YAAY,IAAI,YAAY,IAAI,KAAK;AACjF,UAAM,KAAK,mBAAmB,OAAO;AACrC,UAAM,MAAM,wBAAwB,cAAc,YAAY;AAC9D,UAAM,WAAgB,MAAM,QAAQ,QAAQ;AAC5C,QAAI,CAAC,UAAU;AACb,WAAK,IAAI,gBAAgB;AACzB,aAAO;AAAA;AAET,UAAM,iBAAiB,SAAS,gBAAgB,kCAAkC;AAClF,UAAM,aAAa,eAAe,KAAK,CAAC,MAAW,EAAE,SAAS;AAE9D,QAAI,CAAC,YAAY;AACf,WAAK,IAAI,iBAAiB;AAAA;AAG5B,QAAI,gBAAgB;AACpB,SAAK,YAAY;AAEjB,QAAI,CAAC,eAAe,QAAQ;AAC1B,cAAQ,MAAM,wCAAwC,KAAK;AAC3D,YAAM,IAAI,MAAM;AAAA;AAGlB,UAAM,eAAe,eAAe,OAAO,CAAC,SAAc;AAhO9D;AAiOM,UAAI,yCAAM,UAAN,mBAAa,SAAb,mBAAmB,SAAS,sBAAsB;AACpD,eAAO;AAAA;AAET,UAAI,8BAAM,2BAA0B,aAAa;AAC/C,eAAO;AAAA;AAET,aAAO;AAAA;AAGT,SAAK,IAAI,eAAe,gBAAgB,UAAU,aAAa;AAE/D,QAAI,UAAiB;AAErB,QAAI,CAAC,gBAAgB;AACnB,gBAAU;AAAA,WACL;AACL,WAAK,IACH,4CAA4C,eAAe,QAAQ,eAAe,WAAW,eAAe;AAE9G,YAAM,UAAU,wBAAC,WAAW,aAAa;AACvC,YAAI,QAAQ;AAAQ;AACpB,mBAAW,QAAQ,cAAc;AAC/B,gBAAM,OAAO,KAAK;AAClB,cAAI,qBAAqB,MAAM,gBAAgB,WAAkB;AAC/D,kBAAM,aAAa,WAAW,KAAK,oBAAoB,KAAK,SAAS,KAAK;AAC1E,kBAAM,iBAAiB,eAAe,eAAe,WAAW,eAAe,aAAa,eAAe;AAC3G,kBAAM,SAAS,uBAAuB,KAAK,QAAQ;AACnD,iBAAK,IAAI,GAAG,YAAY,cAAc;AACtC,sBAAU,CAAC;AACX,4BAAgB;AAChB;AAAA;AAAA;AAAA,SAXU;AAiBhB,cAAQ;AAAA;AAGV,QAAI,CAAC,QAAQ,QAAQ;AACnB,cAAQ,IACN,eACA,aAAa,IAAI,CAAC,MAAQ;AA3QlC;AA2QqC,4CAAG,yBAAH,mBAAyB;AAAA,SAAM,KAAK;AAEnE;AAAA;AAGF,SAAK,sBAAsB;AAC3B,SAAK,IAAI,yBAAyB,QAAQ;AAE1C,eAAW,QAAQ,SAAS;AAC1B,YAAM,UAAU,yBAAM;AACtB,YAAM,QAAQ,KAAK;AAAA,QACjB,KAAK,kBAAkB;AAAA,QACvB,QAAQ,KAAK,MAAM;AAvR3B;AAwRU,kBAAQ,KAAK,gCAAgC,WAAK,yBAAL,mBAA2B;AAAA;AAAA;AAG5E,cAAQ;AAAA;AAGV,UAAM,KAAK,SAAS,YAAY,eAAe;AAAA,MAC7C;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAGF,QAAI,gBAAgB;AAClB,UAAI,CAAC,eAAe;AAElB,aAAK,IAAI,0BAA0B,MAAM,cAAc;AAAA,GAAS,iDAAgB;AAChF,cAAM,IAAI,MAAM,iBAAiB,eAAe;AAAA;AAAA;AAIpD,SAAK,IAAI;AAAA;AAAA,QAGL,SAAS,YAAiB,eAAwB,MAA0B;AAChF,QAAI,CAAC,cAAc;AAAe;AAClC,QAAI,QAAQ,IAAI,YAAY,UAAU,KAAK,QAAQ;AAAI;AACvD,UAAM,UAAU,WAAW,MAAM;AACjC,UAAM,gBAAgB,WAAW,MAAM;AACvC,SAAK,SAAS;AACd,QAAI,KAAK,SAAS,eAAe;AAC/B,YAAM,KAAK,YAAY,kBAAkB,CAAC;AAAA;AAAA;AAAA,EAI9C,sBAAsB,cAAmB;AACvC,UAAM,QAAQ,aAAa,IAAI,CAAC,MAAQ;AA5T5C;AA4T+C,0CAAG,yBAAH,mBAAyB;AAAA;AACpE,UAAM,QAAQ,KAAK,yBAAyB,KAAK,KAAK;AACtD,QAAI,cAAc,GAAG;AACnB,WAAK,IAAI,sBAAsB,KAAK,yBAAyB;AAAA;AAAA;AAAA,QAI3D,kBAAkB,MAAW;AACjC,QAAI,CAAC,KAAK,sBAAsB;AAC9B,cAAQ,KAAK;AACb;AAAA;AAEF,UAAM,KAAK,MAAM,aAAa;AAAA,MAC5B,QAAQ;AAAA,MACR,eAAe;AAAA,MACf,UAAU;AAAA,QACR,KAAK;AAAA,QACL,KAAK;AAAA;AAAA,MAEP,gBAAgB,KAAK;AAAA,MACrB,MAAM;AAAA,QACJ,4BAA4B,KAAK;AAAA;AAAA;AAGrC,SAAK,IAAI,uCAAuC,IAAI,SAAS,KAAK;AAClE,QAAI,CAAC,IAAI;AACP,YAAM,IAAI,MAAM;AAAA;AAElB,QAAI,SAAS,KAAK,qBAAqB;AACvC,UAAM,UAAU,mBAAI,MAAM,QAAQ;AAClC,QAAI,QAAQ,MAAM,cAAc;AAC9B,eAAS,UAAU,QAAQ,MAAM;AAAA;AAGnC,aAAS,OAAO,QAAQ,QAAQ;AAChC,SAAK,IAAI,UAAU;AACnB,UAAM,eAAe,mBAAI,MAAM,QAAQ;AACvC,SAAK,IAAI,sBAAsB,QAAQ,IAAI;AAC3C,UAAM,KAAK,YAAY,uBAAuB,CAAC,IAAI,aAAa,MAAM,KAAK;AAAA;AAAA,QAGvE,oBAAoB,IAAY,WAAmB,gBAAwB;AAC/E,SAAK,mBAAmB;AACxB,SAAK,IAAI,8BAA8B;AAEvC,UAAM,CAAC,YAAY,aAAa,MAAM,cAAc,cAAc,WAAW;AAAA,MAC3E;AAAA,MACA;AAAA;AAEF,UAAM,CAAC,aAAa;AAEpB,QAAI,CAAC,WAAW;AACd,cAAQ,IAAI,cAAc,EAAE,YAAY,WAAW;AACnD,YAAM,IAAI,MAAM;AAAA;AAGlB,QAAI,CAAE,kBAAiB,YAAY;AACjC,UAAI,QAAQ,IAAI,aAAa,cAAc;AAEzC,gBAAQ,IAAI,uBAAuB,KAAK,UAAU,WAAW,MAAM;AAAA;AAErE,yCAAc,wCAAwC;AAAA,QACpD,MAAM,EAAE,MAAM;AAAA,QACd,QAAQ,KAAK;AAAA;AAEf;AAAA;AAGF,UAAM,UAAU;AAEhB,WAAO,QAAQ;AAEf,UAAM,aAAa,UAChB,OAAO,SACP,KAAK,CAAC,MAAW,EAAE,aAAa,gBAAgB,EAAE,aAAa;AAClE,UAAM,OAA0C,cAAc,UAAU,MAAM;AAE9E,QAAI,CAAC,MAAM;AACT,cAAQ,IAAI,8BAA8B,EAAE,MAAM;AAClD;AAAA;AAGF,SAAK,IAAI,sBAAsB;AAC/B,UAAM,SAAU,MAAM,gBAAgB,IAAI,EAAE,SAAS,MAAM;AAE3D,UAAM,EAAE,aAAa,OAAO,KAAK,QAAQ,YAAY,MAAM;AAC3D,UAAM,EAAE,UAAU,cAAc,SAAS;AACzC,UAAM,gBAAgB,MAAM,wBAC1B,QACA,gBACA,WACA,UACA,OAAO,KAAK,2BAA2B,MACvC,MAAK,kBAAkB,QAAQ;AAEjC,QAAI,KAAK,WAAW;AAClB,WAAK,IAAI,UAAU,KAAK,UAAU,WAAW;AAAA;AAE/C,WAAO,WAAW;AAAA,MAChB,KAAK;AAAA,MACL,KAAK;AAAA;AAEP,WAAO,gBAAgB;AACvB,UAAM,kBAAkB;AACxB,UAAM,KAAK,eAAe,IAAI;AAC9B,QAAI,aAAa,GAAG;AAClB,YAAM,OAAO,MAAM,wBAAwB,QAAQ;AACnD,WAAK,IAAI,WAAW,KAAK,UAAU,MAAM,MAAM;AAAA;AAAA;AAAA,SAI5C,kBAAkB,QAAoB;AAC3C,UAAM,QAAQ,OAAO,KAAK,KAAK;AAC/B,UAAM,UAAU;AAAA,MACd,MAAM;AAAA,MACN,MAAM;AAAA,MACN,MAAM;AAAA,MACN,MAAM;AAAA,MACN,MAAM;AAAA,MAEL,OAAO,SACP,KAAK;AAER,WAAO;AAAA,MACL,MAAM,OAAO,KAAK,2BAA2B;AAAA,MAC7C;AAAA;AAAA;AAAA,QAIE,eAAe,IAAY,QAAoB;AA7bvD;AA8bI,UAAM,SAAS,OAAO,KAAK,QAAQ,YAAY,MAAM,QAAQ;AAC7D,UAAM,YAAY,aAAO,QAAQ,CAAC,MAAO,EAAE,cAAc,cAAc,IAAI,IAAK,OAA9D,mBAAkE;AACpF,QAAI,aAAc,UAAU,cAAyB;AACrD,SAAK,IAAI,6BAA6B;AACtC,QAAI,aAAa,MAAM,QAAQ,IAAI,YAAY,QAAQ;AACrD,mBAAa;AAAA;AAEf,UAAM,QAAQ,OAAO;AACrB,QAAI,aAAa,GAAG;AAClB,YAAM,KAAK,YAAY,aAAa;AAAA,QAClC;AAAA,QACA,OAAO,KAAK,UAAU,QAAQ,SAAS;AAAA,QACvC;AAAA;AAAA;AAGJ,UAAM,KAAK,YAAY,cAAc,CAAC,IAAI;AAAA;AAAA,QAGtC,UAAU,IAAY,MAAc,YAAoB;AAC5D,UAAM,YAAW;AACjB,UAAM,aAAa,KAAK,KAAK,aAAa;AAC1C,QAAI,QAAQ,CAAC,GAAG,IAAI,MAAM,YAAY,KAAK,IAAI,IAAI,CAAC,IAAG,MAAM;AAC7D,SAAK,IAAI,mBAAmB,MAAM,KAAK;AACvC,eAAW,QAAQ,OAAO;AACxB,YAAM,KAAK,YAAY,gBAAgB,CAAC,IAAI,MAAM,OAAO,WAAU;AAAA;AAAA;AAAA,QAIjE,aAAa,IAAY,MAAc,OAAe,MAAc;AA1d5E;AA2dI,QAAI,OAAO,KAAK,QAAQ,IAAI,aAAa,QAAQ;AAC/C,cAAQ,IAAI;AACZ;AAAA;AAIF,UAAM,OAAM,GAAG,0BAA0B,cAAc;AACvD,SAAK,IAAI,sBAAsB;AAE/B,UAAM,WAAgB,MAAM,4CAAuB,MAAK,CAAC;AACzD,UAAM,QAAQ,SAAS;AAEvB,UAAM,OAA2C;AAEjD,eAAW,QAAQ,OAAO;AACxB,UAAI,CAAC,QAAQ,OAAO,SAAS,UAAU;AACrC;AAAA;AAEF,YAAM,OAAO,aAAK,MAAM,qBAAX,mBAA8B,OAAM,IAAI,QAAQ,iBAAiB;AAE9E,UAAI,CAAC,QAAO,KAAK,KAAK,CAAC,MAAM,EAAE,QAAQ,OAAM;AAC3C;AAAA;AAEF,YAAM,UAAU,YAAK,MAAM,uCAAX,mBAAgD,OAAM;AACtE,WAAK,KAAK;AAAA,QACR,KAAK;AAAA,QACL,SAAS,iCAAO,QAAQ;AAAA;AAAA;AAG5B,QAAI,aAAa,GAAG;AAClB,cAAQ,IAAI,cAAc;AAAA;AAG5B,UAAM,SAAkC;AACxC,WAAO,YAAY,QAAQ;AAC3B,UAAM,gBAAgB,IAAI;AAC1B,SAAK,IAAI,kBAAkB,aAAa,KAAK;AAAA;AAAA,QAGzC,WAAW,IAAY,OAAe,QAAQ,GAAG;AACrD,UAAM,YAAW;AACjB,UAAM,OAAO,QAAQ;AACrB,UAAM,OAAM,UAAU,QAAQ,wDAAwD;AACtF,UAAM,WAAgB,MAAM,QAAQ,QAAQ,MAAK;AAAA,MAC/C,SAAS;AAAA,QACP,oBAAoB;AAAA,QACpB,wBAAwB;AAAA;AAAA,MAE1B,SAAS;AAAA;AAEX,UAAM,OAAO,SAAS;AACtB,QAAI,UAAsB;AAC1B,YAAQ,aAAa,QAAQ;AAC7B,UAAM,gBAAgB,IAAI;AAC1B,SAAK,IAAI,GAAG,KAAK,qCAAqC,aAAa,KAAK;AAExE,QAAI,QAAQ,IAAI,YAAY,UAAU,OAAO,GAAG;AAC9C,WAAK,IAAI;AACT;AAAA;AAGF,UAAM,YAAY,QAAQ;AAC1B,QAAI,aAAa,SAAS,WAAW,cAAc;AACjD,YAAM,KAAK,YAAY,cAAc,CAAC,IAAI,OAAO;AAAA;AAAA;AAAA,QAI/C,oBAAoB;AACxB,UAAM,cAAc,iBAAiB;AAAA;AAAA,QAEjC,oBAAoB,IAAY;AACpC,UAAM,cAAc,mBAAmB;AAAA;AAAA;AAvepC;AAAA;AAKE,AALF,KAKE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AAZF,KAYE,aAAyB;AAAA,EAC9B,UAAU;AAAA;AA8dd,8BACE,MACA,YACA,YAAyC,UACzC;AACA,QAAM,cAAc,UAAU,WAAW,MAAM,6BAAM;AACrD,MAAI,cAAc,QAAQ;AACxB,WAAO;AAAA;AAET,QAAM,iBAAiB,UAAU,KAAK,kBAAkB,yCAAY;AACpE,QAAM,eAAe,UAAU,WAAW,WAAW,KAAK;AAC1D,MAAI,cAAc,UAAU;AAC1B,WACG,eAAe,gBACf,eAAe,kBACf,kBAAkB;AAAA;AAGvB,MAAI,aAAa;AACf,WAAO,KAAK,qBAAqB,WAAW;AAAA;AAE9C,SAAO;AAAA;AArBA;AAyBT,IAAM,YAAY,wBAAC,GAAmB,MAAsB;AAC1D,QAAM,KAAK,gBAAgB,KAAK;AAChC,QAAM,KAAK,gBAAgB,KAAK;AAChC,SAAO,GAAG,SAAS,OAAO,GAAG,SAAS;AAAA,GAHtB;AAMlB,IAAM,kBAAkB,wBAAC,QAAgB,IAAI,QAAQ,eAAe,KAA5C;;;AdviBjB,uBAIL,QACA,QACA,eAAoB,IACoC;AACxD,MAAI,CAAC,QAAQ;AACX,WAAO;AAAA;AAET,SAAO,0BAAM,OAAO,OAAO,SAAS;AAAA;AAXtB;AAchB,uCAA8C,QAAgB,IAAY,kBAAkB,OAAO;AACjG,QAAM,SAAS,MAAM,+BAAU,MAAM;AAAA;AAAA;AAAA,sBAGjB;AAAA,4BACM;AAAA,4BACA;AAAA;AAAA;AAAA;AAI1B,MAAI,OAAO,KAAK,UAAU,GAAG;AAC3B,QAAI,iBAAiB;AACnB,aAAO;AAAA,WACF;AACL,YAAM,IAAI,MAAM,uBAAuB;AAAA;AAAA;AAG3C,SAAO,KAAK,GAAG,WAAW,cAAc,OAAO,KAAK,GAAG;AACvD,SAAO,OAAO,KAAK;AAAA;AAlBC;AAqBtB,mCAA0C,IAAY;AACpD,QAAM,SAAS,MAAM,+BAAU,MAAM;AAAA;AAAA;AAAA,oBAGnB;AAAA;AAElB,SAAO,KAAK,GAAG,WAAW,cAAc,OAAO,KAAK,GAAG;AACvD,SAAO,OAAO,KAAK;AAAA;AAPC;AAUtB,uBAAuB,MAAc;AACnC,QAAM,WAAW,KAAK,MAAM;AAC5B,SAAO;AAAA,IACL,KAAK,SAAS,YAAY;AAAA,IAC1B,KAAK,SAAS,YAAY;AAAA;AAAA;AAJrB;AAQT,yCAAgD,YAA8B,QAAgB;AAC5F,QAAM,SAAS,MAAM,+BAAU,MAAM;AAAA;AAAA;AAAA,+BAGR,WAAW;AAAA,sBACpB;AAAA;AAAA;AAAA;AAIpB,MAAI,OAAO,KAAK,UAAU,GAAG;AAC3B,QAAI,QAAQ,IAAI,aAAa,QAAQ;AACnC,cAAQ,MAAM,wBAAwB,aAAa,WAAW;AAAA;AAEhE,WAAO;AAAA,SACF;AACL,QAAI,QAAQ,IAAI,aAAa,QAAQ;AACnC,cAAQ,IAAI,GAAG,8BAA8B,WAAW;AAAA;AAE1D,WAAO,OAAO,KAAK;AAAA;AAAA;AAlBD;AAgCtB,4BAAmC,QAAgB;AACjD,MAAI;AACF,UAAM,OAAO,KAAK,UAAU,oCAAiB,OAAO,OAAO,QAAQ,MAAM;AACzE,UAAM,SAAS,MAAM,+BAAU,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,WAU9B,OAAO;AAAA,WACP,OAAO;AAAA,WACP;AAAA,WACA,OAAO;AAAA;AAAA,YAEN,OAAO,SAAS,OAAO,OAAO,SAAS;AAAA;AAAA;AAAA;AAAA;AAK/C,UAAM,MAAM,OAAO,KAAK,GAAG;AAC3B,WAAO;AAAA,WACA,KAAP;AACA,YAAQ,MAAM,0BAA0B;AAAA;AAAA;AA1BtB;AA8BtB,iCAAwC,QAAgB;AACtD,UAAQ,IAAI,mBAAmB,OAAO,6BAA6B,OAAO;AAC1E,QAAM,SAAS,MAAM,+BAAU,MAAM;AAAA;AAAA,yBAEd,OAAO;AAAA;AAAA,UAEtB,OAAO,SAAS,OAAO,OAAO,SAAS;AAAA;AAAA,kBAE/B,OAAO;AAAA;AAEvB,SAAO,OAAO,KAAK;AAAA;AAVC;AAatB,4CACE,QACA,gBACA,eACA;AACA,kBAAgB,iBAAiB,OAAO,SAAS,IAAI;AACrD,QAAM,+BAAU,MAAM;AAAA;AAAA,wBAEA;AAAA,sBACF;AAAA,8BACQ;AAAA;AAAA;AAVR;AAwBtB,+BAAsC,IAAY,MAAkB;AAClE,SAAO,oCAAiB;AACxB,QAAM,cAAc,KAAK,UAAU,MAAM,QAAQ,MAAM;AACvD,QAAM,SAAS,MAAM,+BAAU,MAAM;AAAA;AAAA,4BAEX;AAAA,oBACR;AAAA;AAAA;AAGlB,SAAO,OAAO,KAAK;AAAA;AATC;AAwBtB,sCAA6C;AAC3C,QAAM,SAAS,MAAM,+BAAU,MAAM;AACrC,SAAO,OAAO;AAAA;AAFM;AAKtB,sCAA6C,WAAmB;AAC9D,QAAM,SAAS,MAAM,+BAAU,MAC7B;AAAA;AAAA,gCAE4B;AAAA;AAG9B,MAAI,SAAS,OAAO,KAAK;AACzB,SAAO,WAAW,KAAK,MAAM,OAAO;AACpC,MAAI;AACJ,UAAQ,OAAO;AAAA,SACR;AACH,cAAQ,SAAS,kBAAkB;AACnC;AAAA,SACG;AAEH;AAAA,SACG;AACH,cAAQ,QAAQ,kBAAkB;AAClC;AAAA,SACG;AACH,cAAQ,YAAY,kBAAkB;AACtC;AAAA,SACG;AACH,cAAQ,SAAS,kBAAkB;AACnC;AAAA,SACG;AACH,cAAQ,YAAY,kBAAkB;AACtC;AAAA,SACG;AACH,cAAQ,SAAS,kBAAkB;AACnC;AAAA,SACG;AACH,cAAQ,KAAK,kBAAkB;AAC/B;AAAA;AAEA;AAAA;AAEJ,QAAM,WAAW,IAAI;AACrB,QAAM,MAAM,OAAO,SAAS,YAAY;AACxC,QAAM,MAAM,OAAO,SAAS,YAAY;AACxC,QAAM,SAAQ,MAAM,OAAO,MAAM,MAAM;AACvC,QAAM,YAAY,MAAM,SAAS,YAAY,QAAO,KAAK;AACzD,MAAI,WAAW;AACb,UAAM,aAAa,MAAM,qCAAkB,EAAE,aAAa;AAC1D,QAAI,YAAY;AACd,cAAQ,IAAI,mBAAmB,MAAM,MAAM,OAAO,eAAe,WAAW;AAC5E,aAAO,gBAAgB,WAAW;AAClC,YAAM,6BAA6B,OAAO,QAAQ,OAAO,gBAAgB,WAAW;AAAA;AAAA,SAEjF;AACL,YAAQ,IAAI,mBAAmB,MAAM,MAAM,OAAO,eAAe;AACjE,UAAM,6BAA6B,OAAO,QAAQ,OAAO,gBAAgB;AAAA;AAAA;AApDvD;;;AgBnNf,IAAM,cAAc;AAAA,EACzB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;;;ACTF,sBAA8B;;;ACA9B,qBAA+B;AAE/B,0BAAiC,IAAY;AAC3C,QAAM,UAAuB;AAAA,IAC3B,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,gBAAgB;AAAA;AAAA,IAElB,MAAM;AAAA;AAER,MAAI,QAAQ,IAAI,YAAY;AAC1B,YAAQ,IAAI,sBAAsB;AAAA;AAEpC,QAAM,SAAS,MAAM,MAAM,GAAG,2CAA4B;AAC1D,QAAM,WAAgB,MAAM,OAAO;AACnC,MAAI,QAAQ,IAAI,YAAY;AAC1B,YAAQ,IAAI,mBAAmB,SAAS;AAAA;AAE1C,SAAO,SAAS;AAAA;AAhBI;;;ADItB,IAAM,UAAU;AAAA,EACd,iBAAiB;AAAA,IAEf,YAAY;AAAA,IACZ,MAAM,CAAC;AAAA,IAIP,aAAa;AAAA,IACb,OAAO;AAAA,IAEP,mBAAmB;AAAA,IAGnB,kBAAkB;AAAA;AAAA;AAIf,IAAM,aAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAYnB,IAAM,cAAc;AAAA;AAAA;AAOpB,iBAAW;AAAA,EAGhB,YAAY,SAAe;AACzB,SAAK,UAAU;AAAA;AAAA,QAGX,sBAAsB;AAlD9B;AAmDI,UAAM,gBAAgB,WAAK,QAAQ,WAAW,YAAxB,mBAAiC,SAAS;AAChE,UAAM,kBAAkB,KAAK,QAAQ,WAAW,SAAS;AACzD,UAAM,SAAwB,iBAAiB,kBAAkB,YAAY;AAC7E,SAAK,QAAQ,IAAI,6CAA6C;AAC9D,UAAM,aAAa,MAAM,KAAK;AAC9B,UAAM,UAAU,MAAM,WAAW;AACjC,UAAM,aAAa,MAAM,KAAK,SAAS,SAAS;AAChD,SAAK,QAAQ,WAAW,UAAU;AAAA;AAAA,QAG9B,iBAAiB;AACrB,UAAM,SAAQ,KAAK;AACnB,UAAM,SAAS,MAAM,KAAK,QAAQ,QAAQ,MAAM;AAChD,UAAM,OAAO,OAAO,KACjB,IAAI,CAAC,MAAM,EAAE,MACb,KAAK,KACL,WAAW,MAAM;AACpB,WAAO;AAAA;AAAA,EAGT,0BAA0B;AACxB,WAAO;AAAA;AAAA;AAAA,wCAG6B,KAAK,QAAQ,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAO9D,oBAAoB;AAClB,WAAO;AAAA;AAAA;AAAA,wCAG6B,KAAK,QAAQ,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOxD,SAAS,OAAe,SAAwB,SAAS,SAAS,mBAAmB;AACzF,QAAI,OAAO,QAAQ;AACnB,SAAK,SAAS,GAAG,aAAa,QAAQ;AACtC,UAAM,UAAuB;AAAA,MAC3B,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,eAAe,YAAY,QAAQ,IAAI;AAAA;AAAA,MAEzC,MAAM,KAAK,UAAU;AAAA;AAEvB,QAAI,aAAa,GAAG;AAClB,cAAQ,IAAI;AACZ,cAAQ,IAAI,KAAK;AAAA;AAEnB,UAAM,SAAS,MAAM,MAAM,qCAAqC,sBAAsB;AACtF,UAAM,WAAgB,MAAM,OAAO;AACnC,QAAI,SAAS;AACb,QAAI,CAAC,SAAS,WAAW,SAAS,QAAQ,UAAU,GAAG;AACrD,cAAQ,MAAM,mBAAmB;AACjC,yCAAc,kBAAkB;AAAA,QAC9B,MAAM;AAAA,UACJ,YAAY,KAAK,QAAQ,WAAW;AAAA,UACpC;AAAA;AAAA;AAAA,WAGC;AACL,eAAS,SAAS,QAAQ,GAAG;AAAA;AAE/B,QAAI,aAAa,GAAG;AAClB,cAAQ,IAAI;AACZ,cAAQ,IAAI;AAAA;AAEd,WAAO;AAAA;AAAA;AAnFJ;;;AE3CP,qBAAyC;AAKzC,+BAAsC,UAAgB;AACpD,MAAI,cAAc;AAClB,MAAI,UAAU,QAAQ,IAAI,aAAa,QAAQ;AAC/C,MAAI,WAAW;AACf,MAAI,OAAO;AACX,UAAQ,IAAI;AACZ,QAAM,QAAQ,MAAM,cAAc;AAClC,QAAM,YAAW;AACjB,UAAQ,IAAI,mBAAmB;AAC/B,SAAO,MAAM;AACX,UAAM,UAAU,MAAM,iBAAiB,WAAU;AACjD,QAAI,CAAC,SAAS;AACZ;AAAA;AAEF,QAAI,QAAQ,UAAU,GAAG;AACvB,YAAM,SAAS,IAAI,SAAS;AAC5B;AAAA;AAEF,eAAW,UAAU,SAAS;AAC5B,oBAAc,OAAO;AACrB,UAAI,CAAC,SAAS;AACZ,YAAI,OAAO,MAAM,QAAQ,IAAI,YAAY;AACvC;AAAA,eACK;AACL,oBAAU;AAAA;AAAA;AAGd,YAAM,SAAS,YAAY,yBAAyB,CAAC,OAAO,IAAI,OAAO;AAAA;AAEzE,YAAQ;AACR,eAAa,OAAO,YAAY,QAAS;AACzC,QAAI,QAAQ,IAAI,sBAAsB,QAAQ;AAC5C,YAAM,SAAS,IAAI,SAAS;AAAA,WACvB;AACL,cAAQ,IAAI,eAAe;AAAA;AAAA;AAAA;AAlCX;AAuCtB,qCAA4C,UAAkB,MAAa;AACzE,MAAI,CAAC,MAAK;AACR,UAAM,YAAY;AAClB;AAAA;AAEF,QAAM,SAAS,MAAM,MAAM;AAC3B,QAAM,WAAW,MAAM,OAAO;AAC9B,MAAI;AACF,UAAM,OAAO,KAAK,MAAM;AACxB,QAAI,KAAK,UAAU,KAAK;AACtB,YAAM,YAAY;AAAA;AAAA,WAEb,GAAP;AACA,QAAI,CAAC,EAAE,QAAQ,SAAS,qBAAqB;AAC3C,UAAI,EAAE,QAAQ,SAAS,iCAAiC;AACtD,cAAM,YAAY;AAAA,aACb;AACL,gBAAQ,MAAM,2BAA2B;AACzC,cAAM;AAAA;AAAA;AAAA;AAIZ,UAAQ,IAAI,eAAe;AAAA;AAtBP;AAyBtB,gCAAgC,UAAkB,aAAqB;AACrE,QAAM,SAAQ,wBAAC,OAAe,IAAI,QAAQ,CAAC,QAAQ,WAAW,KAAK,MAArD;AACd,MAAI,UAAU;AACd,SAAO,UAAU,IAAI;AACnB,QAAI;AACF,aAAO,MAAM,iBAAiB,UAAU;AAAA,aACjC,GAAP;AACA,iBAAW;AACX,YAAM,OAAM;AAAA;AAAA;AAAA;AARH;AAaf,2BAA2B,IAAY;AACrC,UAAQ,IAAI,oBAAoB;AAChC,QAAM,gCAAY,SAAS,CAAC;AAAA;AAFf;AAKf,IAAI,QAAQ,SAAS,QAAQ;AAC3B;AAAC,EAAC,aAAY;AACZ,UAAM,WAAW,IAAI;AACrB,UAAM,SAAS,UAAU,mBAAmB;AAAA;AAAA;;;AC1FhD,qBAAuC;AACvC,sBAAyB;AAIzB,IAAM,sBAAsB,EAAE,IAAI,GAAG,IAAI,GAAG,IAAI,GAAG,IAAI,IAAI,IAAI;AAExD,wCAAkC,yBAAS;AAAA,EAKhD,YAAY,SAAe;AACzB;AAJF,qBAAiB;AAKf,SAAK,UAAU;AAAA;AAAA,QAGX,iBAAiB;AACrB,SAAK,IAAI;AACT,SAAK,QAAQ,WAAW,kBAAkB;AAC1C,SAAK,UAAU,UAAU;AACzB,UAAM,cAAc,CAAC,GAAG,KAAK,QAAQ,mBAAmB,QAAQ;AAChE,UAAM,UAAU,MAAM,+BAAW,EAAE,MAAM;AACzC,QAAI,CAAC,oCAAS,KAAI;AAChB,cAAQ,IAAI,YAAY,MAAM,+BAAW;AACzC,YAAM,IAAI,MAAM;AAAA;AAElB,SAAK,aAAa,QAAQ;AAC1B,eAAW,UAAU,aAAa;AAChC,WAAK,IAAI,0BAA0B;AACnC,WAAK,UAAU,QAAQ,UAAU,EAAE,SAAS,IAAI,WAAW;AAC3D,UAAI,UAAU,UAAU,UAAU,OAAO;AACvC,cAAM,KAAK,yBAAyB;AAAA,aAC/B;AACL,eAAO,KAAK,UAAU,QAAQ,QAAQ;AAAA;AAExC,YAAM,KAAK,kBAAkB;AAAA;AAE/B,SAAK,IAAI;AACT,UAAM,KAAK;AACX,SAAK,IAAI;AACT,UAAM,KAAK;AACX,SAAK;AACL,SAAK,QAAQ,WAAW,mBAAmB,KAAK;AAChD,SAAK;AAAA;AAAA,EAGP,mBAAmB;AACjB,UAAM,UACJ,KAAK,UAAU,QAAQ,IAAI,QAAQ,MAAM,QACzC,KAAK,UAAU,QAAQ,IAAI,QAAQ,MAAM,QACzC,KAAK,UAAU,MAAM,UACrB,KAAK,UAAU,OAAO;AACxB,UAAM,YACJ,CACE,MAAK,UAAU,QAAQ,IAAI,QAAQ,MAAM,QACzC,KAAK,UAAU,QAAQ,IAAI,QAAQ,MAAM,SACvC,KAAK,UAAU,MAAM;AAC3B,SAAK,QAAQ,WAAW,UAAU;AAClC,SAAK,QAAQ,WAAW,YAAY;AACpC,SAAK,QAAQ,WAAW,cAAc,UAAW,aAAY;AAC7D,SAAK,IACH,qBAAqB,aAAa,2BAA2B,KAAK,QAAQ,WAAW;AAAA;AAAA,QAInF,kBAAkB;AACtB,UAAM,qBAAqB;AAC3B,UAAM,yBAAyB;AAC/B,UAAM,KAAK,KAAK,QAAQ,WAAW;AACnC,UAAM,SAAS,MAAM,KAAK,QAAQ,QAAQ,MAAM;AAAA;AAAA;AAAA,oCAGhB,KAAK,QAAQ,WAAW;AAAA,0BAClC;AAAA;AAEtB,UAAM,QAAQ,SAAS,OAAO,KAAK,GAAG;AACtC,UAAM,QAAQ,QAAQ;AACtB,SAAK,UAAU,SAAS;AAAA,MACtB,SAAS;AAAA,MACT,cAAc;AAAA,MACd,wBAAwB;AAAA,MACxB;AAAA;AAAA;AAAA,QAIE,iBAAiB;AACrB,UAAM,qBAAqB;AAC3B,UAAM,yBAAyB;AAC/B,UAAM,SAAS,MAAM,KAAK,QAAQ,QAAQ,MAAM;AAAA;AAAA;AAAA,iCAGnB,KAAK,QAAQ,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUrD,UAAM,MAAM,OAAO,KAAK;AACxB,UAAM,UAAU,SAAS,IAAI;AAC7B,UAAM,YAAY,SAAS,IAAI;AAC/B,UAAM,QAAQ,UAAU;AACxB,SAAK,UAAU,QAAQ;AAAA,MACrB;AAAA,MACA;AAAA,MACA,OAAO;AAAA;AAAA;AAAA,QAIL,yBAAyB,QAAgB;AAC7C,UAAM,SAAS,MAAM,KAAK,QAAQ,QAAQ,MAAM;AAAA;AAAA;AAAA;AAAA,mCAIjB,KAAK,QAAQ,WAAW;AAAA,0BACjC;AAAA;AAAA;AAAA;AAAA;AAAA,mCAKS,KAAK,QAAQ,WAAW;AAAA,0BACjC;AAAA;AAAA;AAAA;AAAA;AAAA,mCAKS,KAAK,QAAQ,WAAW;AAAA,0BACjC;AAAA;AAAA;AAAA;AAAA;AAAA,mCAKS,KAAK,QAAQ,WAAW;AAAA,0BACjC;AAAA;AAAA;AAAA;AAAA;AAAA,mCAKS,KAAK,QAAQ,WAAW;AAAA,0BACjC;AAAA;AAAA;AAAA;AAItB,SAAK,UAAU,QAAQ,UAAU,EAAE,SAAS;AAC5C,UAAM,MAAM,OAAO,KAAK;AACxB,QAAI,QAAQ;AACZ,eAAW,QAAQ,qBAAqB;AACtC,YAAM,SAAS,oBAAoB;AACnC,YAAM,QAAQ,SAAS,IAAI;AAC3B,YAAM,QAAQ,QAAQ;AACtB,eAAS;AACT,WAAK,UAAU,QAAQ,QAAQ,QAAQ,QAAQ;AAAA,QAC7C;AAAA,QACA;AAAA;AAAA;AAGJ,SAAK,UAAU,QAAQ,QAAQ,QAAQ,QAAQ;AAAA;AAAA,EAGjD,YAAY;AACV,UAAM,gBAAgB,KAAK;AAC3B,QAAI,cAAc;AAClB,mBAAe;AACf,mBAAe,KAAK,UAAU,OAAO;AACrC,mBAAe,KAAK,UAAU,MAAM;AACpC,SAAK,QAAQ,WAAW,QAAQ;AAAA;AAAA,EAGlC,aAAa;AACX,SAAK,UAAU,QAAQ,OAAO,UAAU,EAAE,OAAO;AACjD,eAAW,QAAQ,qBAAqB;AACtC,WAAK,UAAU,QAAQ,OAAO,QAAQ,QAAQ;AAAA,QAC5C,OAAO;AAAA,QACP,OAAO;AAAA;AAAA;AAGX,QAAI,gBAAgB;AACpB,eAAW,UAAU,KAAK,QAAQ,mBAAmB;AACnD,WAAK,eAAe;AACpB,YAAM,eAAe,KAAK,UAAU,QAAQ,QAAQ,QAAQ;AAC5D,WAAK,UAAU,QAAQ,OAAO,QAAQ,SAAS;AAC/C,uBAAiB;AAAA;AAEnB,WAAO;AAAA;AAAA,EAGT,eAAe,QAAgB;AAC7B,eAAW,QAAQ,qBAAqB;AACtC,YAAM,cAAc,KAAK,UAAU,QAAQ,QAAQ,QAAQ;AAC3D,WAAK,UAAU,QAAQ,OAAO,QAAQ,MAAM,YAAY,YAAY;AACpE,WAAK,UAAU,QAAQ,OAAO,QAAQ,MAAM,YAAY,YAAY;AAAA;AAAA;AAAA,QAIlE,kBAAkB,QAAgB;AACtC,UAAM,iBAAiB,SAAS;AAChC,UAAM,SAAS,MAAM,KAAK,QAAQ,QAAQ,MAAM;AAAA;AAAA;AAAA;AAAA,cAItC,KAAK,iBAAiB,QAAQ;AAAA,cAC9B;AAAA;AAAA,cAEA,KAAK,iBAAiB,SAAS;AAAA,cAC/B;AAAA;AAAA;AAAA;AAAA,cAIA,KAAK,oBAAoB,QAAQ;AAAA;AAAA;AAAA,cAGjC,KAAK,oBAAoB,SAAS;AAAA;AAAA;AAAA,0BAGtB,KAAK,cAAc;AAAA;AAAA;AAGzC,UAAM,YAAY,OAAO,KAAK,GAAG;AACjC,SAAK,UAAU,QAAQ,QAAQ,YAAY;AAAA;AAAA,EAG7C,iBAAiB,MAAc,QAAgB;AAC7C,UAAM,aAAa,UAAU,QAAQ,iBAAiB,YAAY;AAClE,UAAM,QAAQ,QAAQ,SAAS,SAAS;AACxC,WAAO;AAAA;AAAA;AAAA,wCAG6B,KAAK,QAAQ,WAAW;AAAA,UACtD;AAAA;AAAA,iCAEuB;AAAA;AAAA;AAAA;AAAA,EAK/B,oBAAoB,MAAc,QAAgB;AAChD,UAAM,aAAa,UAAU,QAAQ,iBAAiB,YAAY;AAClE,UAAM,QAAQ,QAAQ,SAAS,SAAS;AACxC,UAAM,SAAS,QAAQ,SAAS,QAAQ;AACxC,UAAM,iBAAiB,SAAS;AAChC,WAAO;AAAA,wBACa;AAAA;AAAA;AAAA,0CAGkB,KAAK,QAAQ,WAAW;AAAA,6BACrC;AAAA,YACjB;AAAA,mCACuB;AAAA;AAAA,UAEzB;AAAA;AAAA;AAAA,EAIR,cAAc,QAAgB;AAC5B,UAAM,aAAa,UAAU,QAAQ,iBAAiB,YAAY;AAClE,UAAM,iBAAiB,SAAS;AAChC,WAAO;AAAA,wBACa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8CAQsB,KAAK,QAAQ,WAAW;AAAA,kCACpC,KAAK;AAAA,gBACvB;AAAA;AAAA;AAAA,qBAGK,KAAK;AAAA,UAChB;AAAA;AAAA;AAAA;AA5QH;;;ACPP,qBAAc;AASP,IAAM,qBAAqB;AAAA,EAChC,MAAM;AAAA,EACN,aAAa;AAAA,EACb,UAAU;AAAA,EACV,aAAa;AAAA,EACb,UAAU;AAAA,EACV,UAAU;AAAA,EACV,SAAS;AAAA,EACT,QAAQ;AAAA;AAGH,8BAAwB;AAAA,EAG7B,YAAY,SAAe;AACzB,SAAK,UAAU;AAAA;AAAA,EAGjB,aAAa;AACX,UAAM,SAAS,wBAAC,MAAY,OAAO,MAAM,WAAW,CAAC,IAAI,KAAK,MAA/C;AACf,UAAM,UAAU;AAAA,MACd,MAAM,OAAO,cAAc,KAAK,QAAQ,MAAM,CAAC,MAAM,EAAE,KAAK,gBAAgB;AAAA,MAC5E,UAAU,OAAO,cAAc,KAAK,QAAQ,UAAU,CAAC,MAAM,EAAE,KAAK,OAAO;AAAA,MAC3E,aAAa,OAAO,KAAK;AAAA,MACzB,aAAa,OACX,cAAc,KAAK,QAAQ,aAAa,CAAC,MAAM,EAAE,SAAS,OAAO;AAAA,MAEnE,UAAU,OAAO,KAAK;AAAA,MACtB,UAAU,OAAO,KAAK;AAAA,MACtB,SAAS,OAAO,cAAc,KAAK,QAAQ,SAAS,CAAC,MAAM,EAAE,KAAK,OAAO;AAAA,MAGzE,QAAQ,OACN,cAAc,KAAK,QAAQ,mBAAmB,CAAC,MAAM;AACnD,cAAM,WAAU,EAAE,QAAQ,IAAI,CAAC,MAAM,WAAW,EAAE;AAClD,cAAM,MAAM,uBAAE,KAAK;AACnB,eAAO;AAAA;AAAA;AAIb,WAAO;AAAA,MACL,QAAQ,KAAK,cAAc,SAAS;AAAA,MACpC;AAAA;AAAA;AAAA,EAIJ,qBAAqB;AACnB,UAAM,SAAS,cAAc,KAAK,QAAQ,aAAa,CAAC,MACtD,WAAW,EAAE,2BAA2B,KAAK,UAAU;AAEzD,QAAI,SAAS;AAAG,aAAO;AACvB,WAAO,SAAS;AAAA;AAAA,EAGlB,kBAAkB;AAChB,UAAM,SAAS,cACb,KAAK,QAAQ,UACb,CAAC,MAAM,EAAE,KAAK,iBAAiB,EAAE,KAAK,OAAO;AAE/C,WAAO,UAAU,IAAI,OAAO;AAAA;AAAA,EAG9B,cACE,SACA,gBACA;AACA,UAAM,UAAwC;AAC9C,QAAI,eAAe;AACnB,QAAI,eAAe;AACnB,UAAM,kBAAgD;AAEtD,eAAW,UAAU,SAAS;AAC5B,YAAM,SAAS,QAAQ;AAEvB,UAAI,OAAO,MAAM,WAAW,OAAO,WAAW,YAAY,WAAW,GAAG;AACtE;AAAA,aACK;AACL,gBAAQ,UAAU,eAAe;AACjC,wBAAgB,UAAU;AAC1B,wBAAgB,eAAe;AAAA;AAAA;AAInC,eAAW,UAAU,iBAAiB;AACpC,YAAM,SAAS,gBAAgB;AAC/B,YAAM,oBAAoB,QAAQ,UAAU;AAC5C,sBAAgB,SAAS;AAAA;AAG3B,QAAI,aAAa,GAAG;AAClB,cAAQ,IAAI,2BAA2B,EAAE,cAAc,cAAc,SAAS;AAAA;AAGhF,WAAO;AAAA;AAAA,EAGD,qBAAqB;AAC3B,UAAM,SAAS,cAAc,KAAK,QAAQ,UAAU,CAAC,MAAM,EAAE,KAAK;AAClE,QAAI,UAAU,IAAI;AAChB,aAAO;AAAA;AAET,YAAQ;AAAA,WACD;AACH,eAAO;AAAA,WACJ;AACH,eAAO;AAAA,WACJ;AACH,eAAO;AAAA;AAEP,eAAO;AAAA;AAAA;AAAA;AAlGR;;;ACpBP,sBAA+C;AAE/C,sBAAuD;AACvD,sBAAyB;AACzB,sBAAsB;AAKtB,IAAM,mCAAmC;AAEzC,IAAM,wBAAwB,CAAC,GAAG,aAAa;AAExC,wCAAkC,yBAAS;AAAA,EAMhD,YAAY,SAAe;AACzB;AALF,qBAAiB;AACjB,2BAAkB;AAClB,4BAAmB;AAIjB,SAAK,UAAU;AAAA;AAAA,QAGX,kBAAkB;AACtB,UAAM,aAAa,MAAM,KAAK;AAC9B,SAAK,kBAAkB,WAAW;AAClC,SAAK,QAAQ,IAAI,qCAAqC,KAAK;AAC3D,UAAM,WAAW,MAAM,KAAK,iBAAiB;AAC7C,UAAM,KAAK,eAAe;AAC1B,SAAK,QAAQ,IAAI,OAAO,SAAS;AACjC,UAAM,KAAK;AAAA;AAAA,QAGP,oBAAoB;AACxB,SAAK,QAAQ,IAAI;AACjB,UAAM,gBAAgB,KAAK,QAAQ,WAAW;AAC9C,UAAM,SAAS,MAAM,KAAK,QAAQ,QAAQ,MAAM;AAAA;AAAA;AAAA,mCAGjB;AAAA;AAAA;AAG/B,WAAO,OAAO;AAAA;AAAA,QAGV,iBAAiB,sBAA2C;AAChE,UAAM,kBAAkB;AACxB,QAAI,WAAgC;AACpC,UAAM,UAAU,2BAAM,sBAAsB;AAC5C,eAAW,CAAC,OAAO,UAAU,QAAQ,WAAW;AAC9C,WAAK,IAAI,iCAAiC,OAAO,OAAO,QAAQ;AAChE,YAAM,iBAAiB,MAAM,KAAK,sBAAsB;AACxD,eAAS,KAAK,GAAG;AAAA;AAEnB,WAAO;AAAA;AAAA,QAGH,sBAAsB,sBAA2C;AACrE,QAAI,YAAY,MAAM,QAAQ,IAAI,qBAAqB,IAAI,CAAC,QAAQ,KAAK,iBAAiB;AAC1F,WAAO,UAAU,OAAO;AAAA;AAAA,QAGpB,iBAAiB,qBAAwC;AAC7D,QAAI,CAAC,oBAAoB;AAAU;AACnC,SAAK,mBAAmB,KAAK,mBAAmB;AAChD,UAAM,SAAS,MAAM,KAAK,8BAA8B,oBAAoB;AAC5E,QAAI,CAAC;AAAQ;AACb,WAAO;AAAA,MACL,IAAI,oBAAoB;AAAA,MACxB,cAAc,wCAAmB;AAAA;AAAA;AAAA,QAI/B,eAAe,sBAA2C;AAE9D,eAAW,OAAO,sBAAsB;AACtC,YAAM,KAAK,QAAQ,QAAQ,MAAM;AAAA;AAAA,8BAET,IAAI;AAAA,sBACZ,IAAI;AAAA;AAAA;AAAA;AAAA,QAKlB,8BAA8B,MAAc;AAChD,UAAM,cAAc;AACpB,QAAI,UAAU;AACd,WAAO,MAAM;AACX,UAAI;AACF,eAAO,MAAM,wCAAmB;AAAA,eACzB,OAAP;AACA,YAAI,CAAC,MAAM,QAAQ,SAAS,SAAS;AACnC,+CAAgB,OAAO;AAAA,YACrB,MAAM;AAAA,cACJ,UAAU;AAAA,cACV,YAAY,KAAK,QAAQ,WAAW;AAAA;AAAA,YAEtC,QAAQ,KAAK;AAAA;AAEf;AAAA;AAEF,mBAAW;AACX,YAAI,UAAU,aAAa;AACzB,eAAK,QAAQ,IAAI,oCAAoC,MAAM;AAC3D,6CAAc,cAAc,wCAAwC;AAAA,YAClE,MAAM;AAAA,cACJ;AAAA;AAAA;AAGJ;AAAA;AAEF,aAAK,IACH,gCAAgC,WAAW,yBAC7B,KAAK,oBAAoB,KAAK;AAAA;AAAA;AAAA;AAAA,QAM9C,4BAA4B;AAChC,SAAK,IAAI;AACT,UAAM,OAAO,KAAK,QAAQ,QAAQ;AAClC,eAAW,UAAU,MAAM;AACzB,YAAM,wBAAwB,KAAK,UAAU;AAC7C,YAAM,gBAAgB,KAAK,qBAAqB;AAChD,YAAM,oBAAoB,KAAK,yBAAyB;AACxD,YAAM,aAAa,KAAK;AAExB,YAAM,KAAK,QAAQ,QAAQ,MACzB;AAAA;AAAA;AAAA,YAGI;AAAA;AAAA;AAAA,YAGA;AAAA;AAAA;AAAA,qBAGS;AAAA;AAAA,qCAEgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iCAOJ,KAAK,QAAQ,WAAW;AAAA,wBACjC;AAAA;AAAA;AAAA;AAAA,EAMtB,UAAU,QAAgB,SAA6B,QAAW;AAChE,WAAO;AAAA;AAAA,oBAES,KAAK,uBAAuB,QAAQ;AAAA;AAAA,oBAEpC,KAAK,mBAAmB,QAAQ;AAAA;AAAA;AAAA,EAIlD,uBAAuB,QAAgB,SAA6B,QAAW;AAC7E,QAAI,QAAQ;AACV,eAAS,wBAAwB;AAAA,WAC5B;AACL,eAAS;AAAA;AAEX,WAAO;AAAA;AAAA;AAAA;AAAA,wCAI6B,KAAK,QAAQ,WAAW;AAAA,8CAClB;AAAA,YAClC;AAAA;AAAA;AAAA;AAAA;AAAA,EAMV,mBAAmB,QAAgB,SAA6B,QAAW;AACzE,QAAI,QAAQ;AACV,eAAS,iBAAiB;AAAA,WACrB;AACL,eAAS;AAAA;AAEX,WAAO;AAAA;AAAA,iCAEsB,KAAK,QAAQ,WAAW;AAAA,wBACjC;AAAA,UACd;AAAA;AAAA;AAAA,EAIR,qBAAqB,QAAgB;AACnC,QAAI,cAAwB;AAC5B,eAAW,UAAU,uBAAuB;AAC1C,YAAM,aAAa;AAAA,WACd;AAAA;AAAA,aAEE,KAAK,qBAAqB,QAAQ;AAAA;AAAA,aAElC,KAAK,yBAAyB,QAAQ,QAAQ;AAAA;AAAA,aAE9C,KAAK,yBACN,QACA,QACA,OAAO;AAAA;AAAA;AAAA,eAIJ,KAAK,uBAAuB,QAAQ,QAAQ;AAAA;AAAA,eAE5C,KAAK,uBAAuB,QAAQ,QAAQ;AAAA;AAAA;AAGrD,kBAAY,KAAK;AAAA;AAEnB,UAAM,MAAM;AAAA;AAAA,UAEN,YAAY,KAAK;AAAA;AAAA;AAGvB,WAAO;AAAA;AAAA,EAGT,yBAAyB,QAAgB;AACvC,WAAO;AAAA;AAAA;AAAA,wCAG6B,KAAK,QAAQ,WAAW;AAAA,4BACpC;AAAA;AAAA;AAAA,EAI1B,qBAAqB,QAAgB,QAAgB;AACnD,WAAO,KAAK,UAAU,QAAQ;AAAA;AAAA,EAGhC,yBAAyB,QAAgB,QAAgB,oBAA4B;AACnF,QAAI,QAAQ;AACV,eAAS,iBAAiB;AAAA,WACrB;AACL,eAAS;AAAA;AAEX,WAAO;AAAA;AAAA;AAAA,wCAG6B,KAAK,QAAQ,WAAW;AAAA,4CACpB;AAAA,UAClC;AAAA,+CACqC;AAAA;AAAA;AAAA,EAI7C,uBAAuB,QAAgB,QAAgB,QAAgB;AACrE,UAAM,QAAQ,UAAU,YAAY,SAAS;AAC7C,UAAM,gBAAgB,UAAU,YAAY,QAAQ,OAAO;AAC3D,UAAM,iBAAiB,GAAG;AAC1B,QAAI,QAAQ;AACV,eAAS,iBAAiB;AAAA,WACrB;AACL,eAAS;AAAA;AAEX,WAAO;AAAA,wBACa;AAAA;AAAA;AAAA,0CAGkB,KAAK,QAAQ,WAAW;AAAA,8CACpB;AAAA,YAClC;AAAA,6BACiB;AAAA,mCACM;AAAA;AAAA,UAEzB;AAAA;AAAA;AAAA,EAIR,oBAAoB;AAClB,QAAI,MAAgB;AACpB,QAAI,QAAkB;AACtB,eAAW,UAAU,uBAAuB;AAC1C,UAAI,KAAK,gBAAgB;AACzB,YAAM,KAAK,gBAAgB;AAAA;AAE7B,WAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBAOY,IAAI,KAAK;AAAA;AAAA;AAAA,uBAGT,MAAM,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA5R3B;;;ACbP,sBAA8B;AAC9B,qBAUO;AACP,sBAAoE;AACpE,2BAKO;AACP,sBAAyB;AACzB,aAAwB;AACxB,sBAA4B;AAC5B,qBAAmB;AACnB,uBAAsB;AAUtB,IAAM,WAAW,wBAAC,oBACf,gBAA2B,SAAS,QADtB;AAGV,IAAM,WAAW;AAEjB,4BAAsB,yBAAS;AAAA,EAgBpC,YAAY,SAAe;AACzB;AAfF,2BAA4C;AAC5C,kCAEI;AACJ,oBAAkB;AAClB,sBAA8C;AAC9C,oCAA2B;AAC3B,2BAAkB,IAAI;AACtB,uBAAwB;AAQtB,SAAK,UAAU;AAAA;AAAA,MANb,UAAU;AAlDhB;AAmDI,WAAO,WAAW,WAAK,QAAQ,eAAb,mBAAyB;AAAA;AAAA,QAQvC,OAAO;AACX,UAAM,QAAQ,cACZ,KAAK,QAAQ,MACb,CAAC,MAAM,EAAE,2BAA2B,YACpC,IACA,IAAI,CAAC,MAAM,EAAE;AACf,UAAM,eAAe,cACnB,KAAK,QAAQ,aACb,CAAC,MAAM,EAAE,SAAS,WAAW,SAAS,SAAS,MAC/C,IACA,IAAI,CAAC,MAAM,EAAE;AACf,UAAM,OAAO,0BAAK,CAAC,GAAG,OAAO,GAAG;AAChC,SAAK,IAAI,6BAA6B,MAAM,yBAAyB,aAAa;AAClF,UAAM,cAAc,MAAM,KAAK,kBAAkB;AACjD,QAAI,YAAY,QAAQ;AACtB,YAAM,KAAK,cAAc;AAAA;AAE3B,SAAK;AAAA;AAAA,EAGP,WAAW;AACT,QAAI,KAAK,QAAQ,WAAW,SAAS,GAAG;AACtC,WAAK,gBAAgB,KAAK;AAAA,QACxB,QAAQ;AAAA,QACR,eAAe,KAAK,QAAQ,WAAW;AAAA;AAAA;AAAA;AAAA,QAKvC,cAAc,MAAgB;AAClC,SAAK,kBAAkB,MAAM,sDAAkC;AAAA;AAAA,EAGjE,kBAAkB,iBAA2C;AAC3D,SAAK,kBAAkB;AAAA,MACrB,GAAG,KAAK;AAAA,MACR,GAAG,gBAAgB,IAAI,CAAC,QAAS;AAAA,QAC/B,eAAe,KAAK,QAAQ,WAAW;AAAA,SACpC;AAAA;AAAA;AAAA,QAKH,kBAAkB,MAAgB;AACtC,SAAK,QAAQ;AACb,UAAM,eAAe,MAAM,0CAAsB;AACjD,SAAK,kBACH,aAAa,IAAI,CAAC,QAAa;AAC7B,aAAO;AAAA,QACL,QAAQ,IAAI;AAAA,QACZ,eAAe,KAAK,QAAQ,WAAW;AAAA;AAAA;AAI7C,UAAM,cAAc,KAAK,mBAAmB,MAAM;AAClD,SAAK,QAAQ,IAAI;AACjB,WAAO;AAAA;AAAA,EAGT,mBAAmB,MAAgB,cAAqB;AACtD,WAAO,KAAK,OAAO,CAAC,QAAQ;AAC1B,YAAM,oBAAoB,aAAa,KAAK,CAAC,OAAO;AAClD,cAAM,uBAAuB,GAAG,QAAQ;AACxC,cAAM,0BAA2B,IAAG,cAAc,CAAC,KAAK,SAAS;AACjE,eAAO,wBAAwB;AAAA;AAEjC,aAAO,CAAC;AAAA;AAAA;AAAA,QAIN,oBAAoB;AACxB,UAAM,WAAW,KAAK,QAAQ,WAAW,QAAQ;AACjD,UAAM,SAAS,2BAAM,UAAU;AAC/B,SAAK,IAAI,8BAA8B,OAAO;AAC9C,eAAW,UAAS,QAAQ;AAC1B,YAAM,QAAQ,IACZ,OAAM,IAAI,CAAC,QAAQ;AACjB,eAAO,KAAK,mBAAmB,IAAI,IAAI;AAAA;AAAA;AAAA;AAAA,QAMzC,mBAAmB,QAAgB;AACvC,UAAM,OAAO,MAAM,KAAK,cAAc;AACtC,UAAM,WAAW,KAAK,gBAAgB,KAAK,CAAC,OAAO,GAAG,UAAU;AAChE,QAAI,UAAU;AACZ,eAAS,OAAO;AAAA,WACX;AACL,YAAM,MAAM;AAAA,QACV;AAAA,QACA,eAAe,KAAK,QAAQ,WAAW;AAAA,QACvC;AAAA;AAEF,WAAK,gBAAgB,KAAK;AAAA;AAAA;AAAA,QAIxB,cAAc,QAAgB;AAClC,UAAM,SAAS;AACf,UAAM,SAAS,MAAM,KAAK,QAAQ,QAAQ,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+CAOL;AAAA,2BACpB;AAAA;AAAA,6BAEE,KAAK,QAAQ,WAAW;AACjD,QAAI,OAAO,KAAK,UAAU,GAAG;AAC3B,yCAAc,mBAAmB;AAAA,QAC/B,MAAM;AAAA,UACJ,eAAe,KAAK,QAAQ,WAAW;AAAA,UACvC;AAAA;AAAA;AAAA;AAIN,UAAM,OAAO,SAAS,OAAO,KAAK,GAAG;AACrC,WAAO;AAAA;AAAA,QAGH,aAAa;AACjB,SAAK,aAAa;AAClB,SAAK,IAAI;AACT,SAAK,WAAW,MAAM,iDAA6B,KAAK,QAAQ;AAChE,SAAK,yBAAyB;AAC9B,SAAK,cAAc;AAAA,MACjB,GAAG,KAAK;AAAA,MACR,GAAG,KAAK;AAAA,MACR,GAAG,KAAK;AAAA;AAEV,SAAK,IAAI,eAAe,KAAK,YAAY;AACzC,UAAM,aAAa,KAAK,gBAAgB,CAAC,GAAG,KAAK,aAAa,GAAG,KAAK;AACtE,UAAM,0BAA0B,KAAK,iBAAiB;AACtD,SAAK,IAAI;AACT,UAAM,KAAK;AACX,SAAK,IAAI;AACT,QAAI;AACF,YAAM,+CAAqB;AAAA,aACpB,KAAP;AACA,cAAQ,IAAI,wBAAwB;AACpC,YAAM;AAAA;AAAA;AAAA,EAIV,gBAAgB,SAAuB;AACrC,WAAO,QACJ,IAAI,CAAC,MAAM;AACV,UAAI,CAAC;AAAG;AACR,UAAI,SAAS,IAAI;AACf,UAAE,OAAO,0CAAgB,EAAE;AAAA,aACtB;AACL,YAAI,0CAAgB;AAAA;AAEtB,aAAO;AAAA,OAER,OAAO;AAAA;AAAA,QAGN,6BAA6B;AACjC,eAAW,UAAU,OAAO,KAAK,KAAK,yBAAyB;AAC7D,WAAK,gBAAgB,KAAK;AAAA,QACxB;AAAA,QACA,eAAe,KAAK,QAAQ,WAAW;AAAA;AAAA;AAAA;AAAA,QAKvC,oBAAoB;AACxB,UAAM,eAAe,MAAM,iDAA6B,KAAK,QAAQ;AACrE,UAAM,YAAkC;AACxC,UAAM,SAAS,MAAM,KAAK;AAC1B,SAAK,IAAI,SAAS,OAAO;AACzB,QAAI,CAAC,OAAO,QAAQ;AAClB,aAAO;AAAA;AAET,eAAW,OAAO,cAAc;AAC9B,YAAM,OAAO;AAAA,QACX,QAAQ,IAAI;AAAA,QACZ,eAAe,KAAK,QAAQ,WAAW;AAAA,QACvC,QAAQ;AAAA;AAEV,UAAI,kBAAkB;AACtB,iBAAW,SAAS,QAAQ;AAC1B,YAAI,CAAC,MAAM,MAAM;AACf;AAAA;AAEF,YAAI,0CAAqB,MAAM,MAAM,MAAM;AACzC,4BAAkB;AAClB,oBAAU,KAAK;AAAA,YACb,eAAe,KAAK,QAAQ,WAAW;AAAA,YACvC,QAAQ,IAAI;AAAA,YACZ,OAAO;AAAA,cACL,KAAK,MAAM;AAAA;AAAA;AAAA;AAAA;AAKnB,UAAI,iBAAiB;AACnB,aAAK,gBAAgB,KAAK;AAAA;AAAA;AAG9B,SAAK,IAAI,SAAS,UAAU;AAC5B,WAAO;AAAA;AAAA,QAGH,oBAAoB;AA3Q5B;AA4QI,QAAI,SAA0B;AAE9B,QAAI,WAAK,QAAQ,SAAb,mBAAmB,KAAK,UAAU;AACpC,YAAM,YAAY,KAAK,QAAQ,6BAA6B,KAAK,QAAQ,KAAK,MAAM;AACpF,WAAK,IAAI,qBAAqB,UAAU;AACxC,iBAAW,QAAQ,WAAW;AAC5B,YAAI,KAAK,SAAS;AAChB,iBAAO,KAAK;AAAA,YACV,KAAK,KAAK;AAAA,YACV,MAAM,KAAK;AAAA;AAAA;AAAA;AAAA;AAMnB,QAAI,iBAAK,QAAQ,SAAb,mBAAmB,SAAnB,mBAAyB,WAAW;AACtC,YAAM,eACJ,OAAM,QAAQ,IACZ,KAAK,QACF,6BAA6B,KAAK,QAAQ,KAAK,MAAM,WACrD,QAAQ,CAAC,MAAM,EAAE,QACjB,IAAI,OAAO,SAAS;AACnB,cAAM,QAAQ,KAAK;AACnB,YAAI,CAAC,OAAO;AACV,iBAAO;AAAA;AAET,YAAI,MAAM,SAAS,SAAS;AAE1B;AAAA;AAEF,YAAI,KAAK,SAAS;AAGhB,gBAAM,cAAc,MAAM,QAAQ,QAAQ,SAAS,QAAQ,QAAQ;AACnE,gBAAM,iBAAiB,MAAM,MAAM,aAAa,KAAK,CAAC,QAAQ,IAAI,WAAW;AAC7E,gBAAM,OAAM,iBAAiB,cAAc;AAC3C,iBAAO;AAAA,YACL;AAAA,YACA,MAAM,KAAK;AAAA;AAAA;AAAA,WAKrB,OAAO;AACT,WAAK,IAAI,uBAAuB,aAAa;AAC7C,eAAS,CAAC,GAAG,QAAQ,GAAG;AACxB,YAAM,oBACJ,cAAc,KAAK,QAAQ,aAAa,CAAC,MAAM,EAAE,yBAAyB;AAC5E,WAAK,IAAI,oCAAoC,kBAAkB;AAC/D,iBAAW,QAAQ,mBAAmB;AACpC,YAAI,KAAK,SAAS;AAChB,iBAAO,KAAK;AAAA,YACV,KAAK,KAAK;AAAA,YACV,MAAM,KAAK;AAAA;AAAA;AAAA;AAAA;AAMnB,WAAO;AAAA;AAAA,EAGT,iBAAiB,YAA0B;AACzC,QAAI;AACJ,QAAI,UAAoB;AACxB,aAAS,UAAU,YAAY;AAC7B,UAAI,CAAC,SAAS,SAAS;AACrB,eAAO;AAAA,aACF;AACL,eAAO,OAAO,QAAQ;AAAA;AAExB,iBAAW,OAAO,KAAK,UAAU;AAC/B,YAAI,0CAAqB,MAAM,MAAM;AACnC,mBAAS,KAAK,SAAS,KAAK;AAAA;AAAA;AAGhC,UAAI,SAAS,SAAS;AACpB,gBAAQ,KAAK;AAAA;AAAA;AAGjB,WAAO,wCAAc;AAAA;AAAA,EAGvB,SAAS,KAAU,aAAyB;AAC1C,QAAI;AACJ,QAAI,SAAS,cAAc;AACzB,kBAAY,aAAa,YAAY,cAAc;AACnD,aAAO,YAAY,QAAQ;AAAA,WACtB;AACL,aAAO;AAAA;AAET,SAAK,WAAW,IAAI,MAAM;AAC1B,SAAK,uBAAuB,IAAI,MAAM,KAAK,uBAAuB,IAAI,OAAO;AAC7E,UAAM,YAAY,wCAAmB;AACrC,eAAW,YAAY,WAAW;AAChC,UAAI,CAAC,0CAAqB,UAAU;AAAM;AAC1C,YAAM,SAAS,KAAK,iBAAiB;AACrC,WAAK,uBAAuB,IAAI,IAAI,KAAK;AACzC,UAAI,SAAS,cAAc;AACzB,cAAM,YAAiB;AAAA,UACrB,QAAQ,IAAI;AAAA,UACZ,eAAe,KAAK,QAAQ,WAAW;AAAA,UACvC;AAAA,UACA,iBAAiB;AAAA;AAEnB,oBAAY,WAAW,KAAK;AAAA;AAAA;AAGhC,QAAI,SAAS,cAAc;AACzB,kBAAY,aAAa,2CAAiB,YAAY;AAAA;AAExD,WAAO;AAAA;AAAA,EAGT,iBAAiB,UAAkB;AACjC,WAAO,KAAK,gBAAgB,QAAQ,UAAU;AAAA;AAAA,EAGhD,kBAAkB;AAlYpB;AAmYI,UAAM,OAAO,WAAK,QAAQ,SAAb,mBAAmB;AAChC,QAAI,CAAC,MAAM;AACT,WAAK,IAAI,sCAAsC,KAAK,QAAQ;AAC5D,aAAO;AAAA;AAET,UAAM,eAAe,KAAK,QAAQ,6BAA6B,MAAM;AACrE,QAAI,aAAa,GAAG;AAClB,WAAK,IAAI,oBAAoB;AAAA;AAE/B,QAAI,UAA6B;AACjC,eAAW,eAAe,cAAc;AACtC,cAAQ,KAAK;AAAA,QACX,SAAS;AAAA,QACT,QAAQ;AAAA,QACR,QAAQ;AAAA,QACR,UAAU,UAAU,YAAY;AAAA,QAChC,aAAa,SAAS,YAAY,eAAe;AAAA,QACjD,eAAe,KAAK,QAAQ,WAAW;AAAA,QACvC,MAAM;AAAA,UACJ,kBAAY,YAAZ,mBAAqB;AAAA,UACrB,kBAAY,uBAAZ,mBAAgC,IAAI,CAAC,MAAW,EAAE,SAAS,KAAK;AAAA,UAChE,KAAK;AAAA,QACP,QAAQ,YAAY;AAAA,QACpB,MAAM;AAAA;AAAA;AAGV,WAAO;AAAA;AAAA,EAGT,yBAAyB;AAha3B;AAiaI,QAAI,UAA6B;AACjC,UAAM,OAAO,WAAK,QAAQ,gBAAb,mBAA0B;AACvC,QAAI,CAAC,MAAM;AACT,aAAO;AAAA;AAET,UAAM,sBAAsB,KAAK,QAAQ,6BAA6B,MAAM;AAC5E,eAAW,sBAAsB,qBAAqB;AACpD,UAAI,CAAC,mBAAmB,YAAY,mBAAmB,YAAY,IAAI;AACrE,2CAAc,uCAAuC,EAAE,MAAM;AAC7D;AAAA;AAEF,cAAQ,KAAK;AAAA,QACX,SAAS;AAAA,QACT,QAAQ;AAAA,QACR,QAAQ;AAAA,QACR,UAAU,iBAAiB,mBAAmB;AAAA,QAC9C,aAAa,SAAS,mBAAmB,MAAM;AAAA,QAC/C,eAAe,KAAK,QAAQ,WAAW;AAAA,QACvC,MAAM,mBAAmB;AAAA,QACzB,QAAQ,mBAAmB;AAAA,QAC3B,MAAM;AAAA;AAAA;AAGV,WAAO;AAAA;AAAA,EAGT,oBAAoB;AA3btB;AA6bI,UAAM,iBAAiB,kBAAK,QAAQ,sBAAb,mBAAgC,SAAhC,mBAAsC,YAAW;AACxE,QAAI,UAAoB;AACxB,eAAW,UAAU,gBAAgB;AACnC,YAAM,OAAO,KAAK,0BAA0B,OAAO;AACnD,cAAQ,KAAK;AAAA,QACX,SAAS;AAAA,QACT,QAAQ;AAAA,QACR,QAAQ;AAAA,QACR,UAAU,YAAY,OAAO;AAAA,QAC7B,aAAa;AAAA,QACb,eAAe,KAAK,QAAQ,WAAW;AAAA,QACvC,MAAM,OAAO;AAAA,QACb,QAAQ,CAAC,OAAO;AAAA,QAChB,MAAM;AAAA;AAAA;AAGV,WAAO;AAAA;AAAA,EAQT,0BAA0B,MAAc;AACtC,UAAM,cAAc,AAAO,iBAAU;AACrC,QAAI,IAAI,4BAAO;AACf,UAAM,iBAAiB,EAAE,OAAO;AAChC,WAAO,SAAS,gBAAgB;AAAA;AAAA,EAGlC,wBAAwB;AACtB,QAAI,QAAkB;AACtB,eAAW,UAAU,KAAK,QAAQ,YAAY;AAC5C,YAAM,OAAO,OAAO;AACpB,UAAI,CAAC;AAAM;AACX,YAAM,KAAK;AAAA;AAEb,WAAO;AAAA;AAAA,EAGT,mBAAmB;AACjB,UAAM,MAAM,IAAI;AAChB,SAAK,gBAAgB,QAAQ,CAAC,OAAO;AACnC,UAAI,IAAI,GAAG,QAAQ,kCACd,KACA,IAAI,IAAI,GAAG;AAAA;AAGlB,SAAK,kBAAkB,MAAM,KAAK,IAAI;AAAA;AAAA;AAxcnC;;;ACtCP,qBAAwC;AAWxC,8CAAqD,UAAgB;AACnE,MAAI,cAAc;AAClB,MAAI,UAAU,QAAQ,IAAI,aAAa,QAAQ;AAC/C,MAAI,WAAW;AACf,MAAI,OAAO;AACX,QAAM,YAAW;AACjB,QAAM,QAAQ,MAAM,cAAc,cAAc;AAChD,UAAQ,IAAI,6CAA6C;AACzD,SAAO,MAAM;AACX,UAAM,UAAU,MAAM,+BACpB,WACA,aACA;AAEF,QAAI,QAAQ,UAAU,GAAG;AACvB,YAAM,SAAS,IAAI,SAAS;AAC5B;AAAA;AAEF,eAAW,UAAU,SAAS;AAC5B,UAAI,CAAC,SAAS;AACZ,YAAI,OAAO,MAAM,QAAQ,IAAI,YAAY;AACvC,kBAAQ,IAAI,eAAe,OAAO;AAClC;AAAA,eACK;AACL,oBAAU;AAAA;AAAA;AAGd,YAAM,kBAAkB;AAAA,QACtB,IAAI,OAAO;AAAA,QACX,MAAM,OAAO;AAAA,QACb,SAAS,OAAO;AAAA,QAChB,UAAU,KAAK,MAAM,OAAO;AAAA;AAE9B,YAAM,SAAS,YAAY,oBAAoB,CAAC;AAChD,oBAAc,OAAO;AAAA;AAEvB,YAAQ;AACR,eAAa,OAAO,YAAY,QAAS;AACzC,QAAI,QAAQ,IAAI,sBAAsB,QAAQ;AAC5C,YAAM,SAAS,IAAI,SAAS;AAAA,WACvB;AACL,cAAQ,IAAI,eAAe;AAAA;AAAA;AAAA;AAzCX;AA8CtB,gCAAuC,MAAkB;AAEvD,UAAQ,IAAI,yBAAyB,KAAK,IAAI,IAAI,KAAK,SAAS,KAAK,SAAS,KAAK;AACnF,MAAI,CAAC,KAAK,MAAM;AACd,YAAQ,IAAI,oBAAoB;AAChC,WAAO;AAAA;AAET,QAAM,WAAW,IAAI;AACrB,QAAM,SAAS,KAAK;AACpB,QAAM,MAAM,OAAO,YAAY;AAC/B,QAAM,MAAM,OAAO,YAAY;AAC/B,QAAM,SAAQ,KAAK,OAAO,MAAM,KAAK;AACrC,QAAM,YAAY,MAAM,SAAS,YAAY,QAAO,KAAK;AACzD,MAAI,WAAW;AACb,UAAM,YAAY,gBAAgB,WAAW,KAAK;AAClD,SAAK,cAAc;AACnB,UAAM,qCAAqC,KAAK,IAAI;AACpD,YAAQ,IAAI,qBAAqB,IAAI,KAAK,SAAS;AAAA;AAAA;AAjBjC;AAqBtB,IAAI,QAAQ,SAAS,QAAQ;AAC3B;AAAC,EAAC,aAAY;AACZ,UAAM,WAAW,IAAI;AAErB,UAAM,SAAS,UAAU,sCAAsC;AAAA;AAAA;;;A3BrBnE,QAAQ,GAAG,sBAAsB,CAAC,QAAQ,OAAM;AAC9C,UAAQ,IAAI,uBAAuB;AACnC,UAAQ,KAAK;AAAA;AAGf,IAAM,WAAW,CAAC,OAAO,OAAO,OAAO,OAAO,OAAO,OAAO;AAG5D,IAAM,iBAAiB,wBAAC,KAAU,SAAiB;AACjD,QAAM,iBAAiB;AACvB,QAAM,QAAQ,SAAS,QAAQ,OAAO;AACtC,QAAM,QAAQ,4BAAO,WAAW,SAAS,QAAQ;AACjD,QAAM,YAAY,MAAM,OAAO,sBAAsB;AACrD,SAAO;AAAA,GALc;AAQvB,IAAM,cAAc,CAAC,QAAQ,IAAI;AAE1B,0BAAmB,0BAAU;AAAA,EAwClC,cAAc;AACZ;AAxCF,gBAA0B;AAC1B,oBAA8C;AAC9C,uBAAoD;AACpD,oBAA0B;AAC1B,uBAAoD;AACpD,oBAA8C;AAC9C,mBAAyB;AACzB,kBAA0C;AAC1C,6BAA2D;AAC3D,6BAA8B;AAS9B,sBAAyB;AAEzB,kCAAyB;AAqBvB,SAAK,UAAU,IAAI,QAAQ;AAC3B,SAAK,qBAAqB,IAAI,kBAAkB;AAChD,SAAK,wBAAwB,IAAI,oBAAoB;AACrD,SAAK,wBAAwB,IAAI,oBAAoB;AACrD,SAAK,OAAO,IAAI,KAAK;AAAA;AAAA,MAVnB,UAAU;AAnHhB;AAoHI,WAAO,UAAU,YAAK,eAAL,mBAAiB,SAAQ;AAAA;AAAA,QAYtC,WAAW,MAAc;AAC7B,UAAM,YAAW;AACjB,QAAI,cAAc;AAClB,UAAM,QAAQ,MAAM,uBAAuB;AAC3C,QAAI,QAAQ;AACZ,WAAO,MAAM;AACX,YAAM,UAAU,MAAM,6BAA6B,WAAU,aAAa;AAC1E,UAAI,QAAQ,UAAU,GAAG;AACvB;AAAA;AAEF,YAAM,QAAQ,IACZ,QAAQ,IAAI,OAAO,WAAW;AAE5B,cAAM,YAAY,MAAM,QAAQ,IAC9B,YAAY,IAAI,OAAO,WAAW;AAChC,iBAAO,MAAM,0BAA0B,QAAQ;AAAA;AAGnD,YAAI,UAAU,KAAK,UAAU;AAC3B,gBAAM,KAAK,YAAY,YAAY,CAAC,OAAO;AAAA;AAAA;AAIjD,eAAS,QAAQ;AACjB,YAAM,WAAY,QAAQ,QAAS;AACnC,YAAM,KAAK,IAAI,SAAS;AACxB,oBAAc,QAAQ,QAAQ,SAAS,GAAG;AAAA;AAAA;AAAA,QAIxC,SAAS,IAAY;AACzB,SAAK,gCAAgC;AACrC,UAAM,aAAa,MAAM,6BAA6B;AACtD,SAAK,IAAI,6BAA6B,kBAAkB,yCAAY;AACpE,QAAI,CAAC,YAAY;AACf,yCAAc,iDAAiD;AAAA,QAC7D,MAAM;AAAA,UACJ,YAAY;AAAA;AAAA;AAGhB,cAAQ,KAAK;AAAA;AAEf,QAAI,YAAY;AACd,YAAM,KAAK,SAAS;AACpB,YAAM,cAAc;AAAA,QAClB,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA;AAGP,iBAAW,cAAc,aAAa;AACpC,YACE,eACA,QAAQ,IAAI,aAAa,WAAW,QACpC,WAAW,QAAQ,iBACnB;AACA,eAAK,IAAI,gBAAgB,WAAW;AACpC,gBAAM,KAAK,qBAAqB;AAAA;AAAA;AAGpC,YAAM,KAAK;AACX,WAAK,IAAI,wBAAwB;AAAA;AAAA;AAAA,QAI/B,gBAAgB;AACpB,QAAI,eAAe;AACnB,eAAW,UAAU,aAAa;AAChC,YAAM,SAAS,MAAM,0BAA0B,KAAK,YAAY;AAChE,UAAI,QAAQ;AACV,uBAAe;AACf,YAAI,aAAa,GAAG;AAClB,eAAK,IAAI,oBAAoB,oBAAoB,iCAAQ;AAAA;AAAA;AAG7D,WAAK,UAAU;AAAA;AAEjB,QAAI,CAAC,cAAc;AACjB,YAAM,IAAI,MAAM;AAAA;AAAA;AAAA,QAId,gBAAgB;AACpB,UAAM,QAAQ;AAAA,MACZ,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA;AAEP,eAAW,QAAQ,OAAO;AACxB,UAAI,eAAe,QAAQ,IAAI,aAAa,KAAK,MAAM;AACrD,aAAK,IAAI,gBAAgB,KAAK;AAC9B,cAAM,KAAK,qBAAqB;AAAA;AAAA;AAAA;AAAA,QAKhC,OAAO;AAGX,UAAM,MAAM,MAAM,+BAAW,EAAE,IAAI;AACnC,QAAI,KAAK;AACP;AAAA;AAEF,UAAM,8BAAU;AAAA,MACd;AAAA,QACE,MAAM;AAAA,QACN,MAAM;AAAA,QACN,YAAY,CAAC;AAAA,QACb,MAAM;AAAA,QACN,IAAI;AAAA;AAAA,MAEN;AAAA,QACE,MAAM;AAAA,QACN,MAAM;AAAA,QACN,MAAM;AAAA;AAAA;AAAA;AAAA,QAKN,SAAS,YAA8B;AAC3C,UAAM,KAAK;AACX,SAAK,UAAU,8BAAS;AACxB,SAAK;AACL,SAAK,aAAa;AAClB,SAAK,IAAI,cAAc,KAAK,WAAW;AACvC,SAAK;AACL,SAAK,IAAI;AACT,UAAM,KAAK;AACX,SAAK;AAAA;AAAA,QAGD,YAAY;AAChB,SAAK;AACL,QAAI,CAAC,KAAK,WAAW,QAAQ,KAAK,WAAW,QAAQ,IAAI;AACvD,yCAAc,wCAAwC;AAAA,QACpD,MAAM;AAAA,UACJ,YAAY,KAAK,WAAW;AAAA;AAAA;AAGhC;AAAA;AAEF,UAAM,KAAK,qBAAqB,KAAK;AACrC,UAAM,cAAc,CAAC,KAAK,cAAc,KAAK;AAC7C,eAAW,cAAc,aAAa;AACpC,WAAK,IAAI,0BAA0B,WAAW;AAC9C,UAAI,eAAe,QAAQ,IAAI,aAAa,WAAW,MAAM;AAC3D,cAAM,KAAK,qBAAqB;AAAA;AAAA;AAGpC,SAAK,IAAI;AACT,UAAM,qCAAiB,KAAK;AAC5B,kBAAc,KAAK;AACnB,SAAK,IAAI,WAAW,KAAK,WAAW;AAAA;AAAA,QAGhC,gBAAgB;AACpB,SAAK,IAAI;AACT,UAAM,qCAAiB,KAAK,YAAY,EAAE,MAAM,CAAC;AACjD,SAAK,QAAQ;AACb,SAAK,IAAI;AACT,UAAM,KAAK,QAAQ;AACnB,SAAK,IAAI;AACT,UAAM,6CAAyB,KAAK,YAAY,KAAK,QAAQ,iBAAiB;AAAA,MAC5E,QAAQ,MAAO;AAAA,MACf,MAAM,CAAC;AAAA;AAET,SAAK,IAAI;AACT,QAAI,KAAK,WAAW,UAAU,GAAG;AAC/B,YAAM,yCAAqB,KAAK;AAAA;AAAA;AAAA,QAI9B,cAAc;AAClB,SAAK,IAAI;AACT,UAAM,KAAK,sBAAsB;AACjC,UAAM,KAAK,sBAAsB;AAAA;AAAA,EAGnC,uBAAuB;AACrB,SAAK,oBAAoB,OAAO,KAAK,KAAK,WAAW,WAAW;AAAA;AAAA,QAG5D,SAAS;AACb,UAAM,KAAK,QAAQ;AAAA;AAAA,QAGf,eAAe;AA1UvB;AA2UI,QAAI,CAAC,YAAK,WAAW,gBAAhB,mBAA6B,SAAS;AAAM;AACjD,QAAI,OAAe;AACnB,YAAQ,KAAK,WAAW;AAAA,WACjB;AACH,eAAO;AACP;AAAA,WACG;AACH,eAAO;AACP;AAAA,WACG;AACH,eAAO;AACP;AAAA,WACG;AACH,eAAO;AACP;AAAA,WACG;AACH,eAAO;AACP;AAAA;AAEJ,QAAI,QAAQ,IAAI;AACd,YAAM,KAAK,QAAQ,cAAc,CAAC,WAAW;AAAA;AAAA;AAAA,QAI3C,oBAAoB;AACxB,UAAM,MAAM,MAAM,KAAK,QAAQ;AAC/B,UAAM,YAAY;AAClB,eAAW,OAAO,KAAK,QAAQ,iBAAiB;AAC9C,YAAM,iBAAiB,MAAM,4BAA4B,KAAK,WAAW,IAAI,IAAI;AACjF,UAAI,SAAS,eAAe,IAAI,CAAC,MAAM,EAAE,MAAM;AAAA;AAAA;AAAA,QAI7C,aAAa;AACjB,UAAM,KAAK,QAAQ;AAAA;AAAA,EAGrB,MAAM,SAAmB;AACvB,UAAM,WAAW,QAAQ,OAAO,CAAC,MAAM,wBAAG,UAAS;AACnD,QAAI,WAAqB;AACzB,aAAS,QAAQ,MAAK,SAAS,WAAW;AACxC,YAAM,UAAU,MAAK,YAAY,KAAK,IAAI,KAAK;AAC/C,UAAI,SAAS;AACX,iBAAS,KAAK;AAAA;AAAA;AAGlB,UAAM,kBAAkB,MAAK,eAAe;AAC5C,UAAM,mBAAmB,MAAK,eAAe;AAC7C,QAAI,iBAAiB,QAAQ;AAC3B,aAAO;AAAA,WACF;AACL,UAAI,gBAAgB,WAAW,GAAG;AAChC,eAAO;AAAA;AAET,aAAO;AAAA;AAAA;AAAA,EAIX,YAAY;AArYd;AAsYI,UAAM,QAAQ;AAAA,MACZ,cAAc,KAAK,MAAM,CAAC,MAAM,EAAE,KAAK;AAAA,MACvC,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK;AAAA,MAC3C,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,2BAA2B;AAAA,MACpE,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK;AAAA,MAC3C,cAAc,KAAK,SAAS,CAAC,MAAM,EAAE,KAAK;AAAA,MAC1C,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK;AAAA,MAC3C,YAAY,UAAU,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,SAAS;AAAA;AAE1E,UAAM,OAAO,KAAK,MAAM;AACxB,QAAI,MAAM;AACR,WAAK,WAAW,OAAO;AAAA;AAEzB,QAAI,YAAY;AACd,WAAK,IAAI,eAAe,OAAO,SAAS;AACxC,UAAI,CAAC,MAAM;AACT,gBAAQ,IAAI,YAAY,MAAM,WAAK,SAAL,mBAAW;AAAA;AAAA;AAAA;AAAA,EAK/C,iBAAiB;AACf,SAAK,WAAW,YAAY,KAAK,MAAM;AAAA,MACrC,cAAc,KAAK,MAAM,CAAC,MAAM,EAAE,KAAK;AAAA,MACvC,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK;AAAA,MAC3C,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,2BAA2B;AAAA,MACpE,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,SAAS,QAAQ;AAAA,MAC1D,cAAc,KAAK,QAAQ,CAAC,MAAM,EAAE;AAAA;AAAA;AAAA,EAIxC,eAAe;AACb,UAAM,YAAY;AAAA,MAChB,cACE,KAAK,MACL,CAAC,MACC;AAAA,QACE,EAAE,KAAK,QAAQ;AAAA,QACf,EAAE,KAAK,QAAQ;AAAA,QACf,EAAE,KAAK,QAAQ;AAAA,QACf,EAAE,KAAK,QAAQ;AAAA,QAGd,OAAO,SACP,KAAK,OACV,CAAC;AAAA,MAEH,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK,SAAS;AAAA,MACpD,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,2BAA2B;AAAA,MACpE,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK;AAAA,MAC3C,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,SAAS,QAAQ;AAAA,MAC1D,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK,SAAS;AAAA;AAEtD,SAAK,WAAW,UAAU,KAAK,MAAM;AACrC,QAAI,YAAY;AACd,WAAK,IAAI,mBAAmB,WAAW,SAAS,KAAK,WAAW;AAAA;AAAA;AAAA,EAIpE,aAAa;AACX,QAAI,UAAU,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,SAAS,QAAQ;AACxE,cAAU,wBAAO,OAAO;AACxB,UAAM,QAAQ,QAAQ,MAAM;AAC5B,UAAM;AACN,UAAM;AACN,SAAK,WAAW,UAAU,MAAM,KAAK;AAErC,QAAI,CAAC,KAAK,WAAW,SAAS;AAC5B,WAAK,WAAW,UAAU,aAAa,cAAc,KAAK,QAAQ,CAAC,MAAM,EAAE;AAAA;AAAA;AAAA,EAI/E,gBAAgB;AA9clB;AA+cI,SAAK,WAAW,cAAc,cAAc,KAAK,QAAQ,CAAC,MAAM,EAAE;AAClE,QAAI,CAAC,YAAK,WAAW,gBAAhB,mBAA6B,SAAS,OAAM;AAC/C,YAAM,OAAO,cACX,KAAK,aACL,CAAC,MAAG;AAndZ;AAmde,sEAAG,aAAH,oBAAa,eAAb,oBAAyB,aAAzB,mBAAmC,eAAnC,mBAA+C,KAAK,OAApD,mBAAwD;AAAA;AAEjE,UAAI,KAAK,SAAS;AAAQ,aAAK,WAAW,cAAc;AACxD,UAAI,KAAK,SAAS;AAAQ,aAAK,WAAW,cAAc;AACxD,UAAI,KAAK,SAAS;AAAS,aAAK,WAAW,cAAc;AAAA;AAG3D,QAAI,CAAC,YAAK,WAAW,gBAAhB,mBAA6B,SAAS,OAAM;AAC/C,WAAK,WAAW,cAAc,cAC5B,KAAK,MACL,CAAC,MAAG;AA7dZ;AA6de,6CAAG,+BAAH,oBAA+B;AAAA;AAAA;AAAA;AAAA,QAKtC,WAAW;AACf,SAAK,WAAW,QAAQ,cACtB,KAAK,MACL,CAAC,MAAG;AAreV;AAqea,6CAAE,YAAF,mBAAW,gBAAX,mBAAwB,UAAxB,mBAA+B,kBAA/B,mBAA8C,YAA9C,mBAAuD;AAAA,OAC9D;AAGF,UAAM,WAAW,KAAK,WAAW;AAGjC,UAAM,UAAU,SAAS,QAAQ,CAAC,OAAY;AAC5C,UAAI,GAAG,cAAc,SAAS,MAAM;AAElC,cAAM,CAAC,OAAO,OAAO,GAAG,cAAc,MAAM;AAC5C,cAAM,SAAS,SAAS,QAAQ;AAChC,YAAI,OAAO,SAAS,QAAQ;AAC5B,YAAI,OAAO,QAAQ;AACjB,iBAAO,SAAS;AAAA;AAElB,cAAM,OAAc;AACpB,iBAAS,IAAI,QAAQ,KAAK,MAAM,KAAK;AACnC,eAAK,KAAK,SAAS,IAAI,SAAS;AAAA;AAElC,eAAO,KAAK,IAAI,CAAC,QAAS;AAAA,UACxB,eAAe;AAAA,UACf,eAAe,GAAG;AAAA;AAAA;AAGtB,aAAO;AAAA,QACL,eAAe,GAAG;AAAA,QAClB,eAAe,GAAG;AAAA;AAAA;AAItB,UAAM,UAAoB;AAC1B,eAAW,OAAO,SAAS;AACzB,YAAM,QAAQ,IAAI,cAAc,MAAM;AACtC,UAAI,CAAC,SAAS,CAAC,MAAM;AAAQ;AAC7B,UAAI,CAAC,UAAU,aAAa,MAAM,IAAI,CAAC,MAAW,EAAE,QAAQ,KAAK,IAAI,OAAO;AAC5E,YAAM,UAAU,IAAI;AACpB,UAAI,WAAW,IAAI;AAEnB,YAAM,wBAAwB,SAAS,SAAS,SAAS,UAAU,SAAS;AAC5E,YAAM,wBACJ,SAAS,SAAS,SAClB,UAAU,SAAS,SAInB,CAAC,SAAS,MAAM,KAAK,KAAK,CAAC,UAAU,MAAM,KAAK;AAElD,UAAI,yBAAyB,uBAAuB;AAClD,cAAM,WAAW,SAAS,QAAQ;AAClC,mBAAW,SAAU,YAAW,KAAK,SAAS;AAAA;AAGhD,YAAM,OAAO,eAAe,SAAS;AACrC,YAAM,QAAQ,eAAe,UAAU;AAEvC,UAAI,CAAC,MAAM,OAAO,KAAK,CAAC,MAAM,MAAM,iBAAiB;AAEnD,gBAAQ,IAAI,0CAAgC,EAAE,MAAM,SAAS,UAAU,OAAO,UAAU;AACxF,gBAAQ,IAAI,UAAU,EAAE,OAAO,KAAK,WAAW,OAAO;AACtD;AAAA;AAGF,cAAQ,KAAK,KAAK,KAAK,WAAW,yBAAyB,qBAAqB;AAAA;AAGlF,QAAI,QAAQ,UAAU,GAAG;AACvB,aAAO;AAAA,QACL,OAAO;AAAA,QACP;AAAA;AAAA;AAIJ,UAAM,SAAQ;AAAA;AAAA;AAAA,mCAGiB,KAAK,WAAW;AAAA;AAAA;AAAA;AAAA,sBAI7B,QAAQ,KAAK;AAAA;AAAA;AAAA;AAK/B,QAAI;AACF,YAAM,SAAS,MAAM,KAAK,QAAQ,MAAM;AACxC,aAAO;AAAA,QACL,OAAO,OAAO,GAAG;AAAA,QACjB;AAAA;AAAA,aAEK,KAAP;AACA,cAAQ,MAAM,uBAAuB,IAAI,SAAS,IAAI;AACtD,cAAQ,IAAI,kBAAkB,QAAQ,KAAK;AAAA;AAAA;AAAA,QAIzC,eAAe;AACnB,UAAM,SAAQ;AAAA;AAAA;AAAA,iCAGe,KAAK,WAAW;AAAA;AAAA;AAG7C,UAAM,SAAS,MAAM,KAAK,QAAQ,MAAM;AACxC,UAAM,gBAAgB,OAAO,KAAK,GAAG;AACrC,SAAK,WAAW,qBAAqB;AAAA;AAAA,EAQvC,iBAAiB;AACf,SAAK,WAAW,gBAAgB,mBAC1B,KAAK,WAAW,iBAAiB;AAEvC,UAAM,QAAQ,wBAAE,UAAU,KAAK,WAAW;AAC1C,UAAM,UAAU;AAAA,MACd,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA;AAEP,eAAW,UAAU,SAAS;AAC5B,UAAI,QAAQ;AACV,aAAK,WAAW,cAAc,OAAO,UAAU,OAAO;AAAA;AAAA;AAG1D,SAAK,uBAAuB;AAAA;AAAA,EAG9B,uBAAuB,OAAiB;AACtC,QAAI,SAAS;AAAM;AACnB,QAAI,qBAAqB;AACzB,eAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,QAAQ;AAChD,YAAM,YAAY,KAAK,WAAW,cAAc;AAChD,UAAI,SAAS,WAAW;AACtB,6BAAqB;AAAA;AAAA;AAGzB,QAAI,CAAC;AAAoB;AACzB,SAAK,+BAA+B;AAAA;AAAA,EAGtC,+BAA+B,OAAiB;AAC9C,UAAM,UAAU;AAChB,UAAM,OAAO;AAAA,MACX,eAAe,KAAK,WAAW;AAAA,MAC/B,eAAe;AAAA,MACf,gBAAgB,KAAK,WAAW;AAAA;AAElC,SAAK,IAAI;AACT,uCAAc,SAAS,EAAE;AAAA;AAAA,EAG3B,aAAa;AACX,QAAI;AACJ,QAAI;AACJ,QAAI;AAEJ,SAAK,WAAW,UAAU,mBACrB,KAAK,WAAW;AAGrB,UAAM,EAAE,QAAQ,YAAY,KAAK,mBAAmB;AAEpD,SAAK,WAAW,SAAS;AAEzB,WAAO,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,SAAS,MAAM;AAC/D,QAAI,QAAQ,IAAI;AACd,cAAQ,KAAK,MAAM;AACnB,YAAM;AACN,aAAM,iCAAiC,MAAM,KAAK;AAClD,WAAK,WAAW,QAAQ,cAAc;AAAA,QACpC;AAAA,QACA,QAAQ,mCAAS;AAAA;AAAA;AAIrB,WAAO,cAAc,KAAK,MAAM,CAAC,MAAM,EAAE,2BAA2B;AACpE,QAAI,QAAQ,IAAI;AACd,WAAK,WAAW,QAAQ,OAAO;AAAA,QAC7B,KAAK,yBAAyB;AAAA,QAC9B,QAAQ,mCAAS;AAAA;AAAA;AAIrB,WAAO,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,2BAA2B,KAAK;AAChF,QAAI,QAAQ,IAAI;AACd,WAAK,WAAW,QAAQ,cAAc;AAAA,QACpC,KAAK,mCAAmC;AAAA,QACxC,QAAQ,mCAAS;AAAA;AAAA;AAIrB,WAAO,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK;AAClD,QAAI,QAAQ,IAAI;AACd,WAAK,WAAW,QAAQ,WAAW;AAAA,QACjC,KAAK,+BAA+B;AAAA,QACpC,QAAQ,mCAAS;AAAA;AAAA;AAIrB,QAAI,UAAU,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK,UAAU;AACnE,QAAI,OAAO,YAAY,UAAU;AAC/B,UAAI;AACF,kBAAU,KAAK,MAAM;AAAA,eACd,KAAP;AACA,gBAAQ,IAAI,sBAAsB;AAAA;AAAA;AAGtC,QAAI,QAAQ,QAAQ;AAClB,WAAK,WAAW,QAAQ,WAAW;AAAA,QACjC,KAAK,QAAQ;AAAA,QACb,QAAQ,mCAAS;AAAA;AAAA;AAIrB,QAAI,UAAU,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,cAAc;AAClE,QAAI,QAAQ,OAAO;AACjB,WAAK,WAAW,QAAQ,WAAW;AAAA,QACjC,KAAK,QAAQ,MAAM,MAAM,KAAK;AAAA,QAC9B,QAAQ,mCAAS;AAAA;AAAA;AAIrB,UAAM,QAAQ,cAAc,KAAK,SAAS,CAAC,MAAM,EAAE,KAAK;AACxD,QAAI,OAAO;AACT,WAAK,WAAW,QAAQ,UAAU;AAAA,QAChC,KAAK,wCAAwC;AAAA,QAC7C,QAAQ,mCAAS;AAAA;AAAA;AAIrB,QAAI,CAAC,KAAK;AAAmB;AAC7B,SAAK,IAAI;AACT,UAAM,KAAK,KAAK,kBAAkB;AAClC,UAAM,MAAM,KAAK,WAAW,SAAS,YAAY;AACjD,UAAM,MAAM,KAAK,WAAW,SAAS,YAAY;AACjD,UAAM,SAAS,gBAAgB,IAAI,KAAK;AAExC,SAAK,WAAW,QAAQ,SAAS;AAAA,MAC/B,KAAK;AAAA,MACL,QAAQ,mCAAS;AAAA;AAAA;AAAA,QAIf,gBAAgB;AAluBxB;AAmuBI,SAAK,IAAI;AACT,QAAI,OAAM,iBAAK,WAAW,YAAhB,mBAAyB,SAAzB,mBAA+B;AACzC,QAAI,CAAC,MAAK;AACR,WAAK,IAAI;AACT;AAAA;AAEF,WAAM,KAAI,QAAQ,aAAa;AAC/B,UAAM,YAAY;AAClB,UAAM,OAAO,MAAM,cAAc,QAAQ;AACzC,QAAI,KAAK,SAAS,YAAY;AAC5B,WAAK,WAAW,qBAAqB;AACrC,WAAK,IAAI;AAAA,WACJ;AACL,WAAK,IAAI;AAAA;AAAA;AAAA,QAIP,aAAa;AACjB,QAAI,OAAO;AAEX,UAAM,QAAQ,cACZ,KAAK,MACL,CAAC,MAAG;AAzvBV;AA0vBQ,sBAAE,KAAK,UAAP,mBAAc,QAAQ,YAAY,iBAClC,QAAQ,MAAM,uCAAuC,EAAE;AAAA;AAE3D,QAAI,OAAO;AACT,aAAO;AAAA;AAET,UAAM,UAAU,cAAc,KAAK,QAAQ,CAAC,MAAM,EAAE;AACpD,QAAI,SAAS;AACX,aAAO;AAAA;AAET,UAAM,eAAe,cACnB,KAAK,aACL,CAAC,MAAM,EAAE,2BAA2B,KAAK;AAE3C,QAAI,cAAc;AAChB,aAAO;AAAA;AAET,UAAM,YAAY,cAAc,KAAK,UAAU,CAAC,MAAM,EAAE,KAAK;AAC7D,QAAI,WAAW;AACb,aAAO;AAAA;AAET,QAAI,QAAQ,IAAI;AACd,YAAM,WAAW,MAAM,gBAAgB,MAAM,KAAK,WAAW;AAC7D,UAAI,UAAU;AACZ,aAAK,WAAW,QAAQ;AAAA;AAAA,WAErB;AACL,WAAK,IAAI;AAAA;AAAA;AAAA,QAIP,gBAAgB;AAzxBxB;AA0xBI,QAAI,CAAC,YAAK,aAAL,mBAAe,KAAI;AACtB;AAAA;AAGF,UAAM,aAAa,iBAAK,aAAL,mBAAe,SAAf,mBAAqB;AACxC,eAAW,QAAQ,YAAY;AAC7B,UAAI,KAAK,OAAO;AACd,aAAK,WAAW,KAAK;AAAA,UACnB,eAAe,KAAK,WAAW;AAAA,UAC/B,MAAM,KAAK;AAAA,UACX,aAAa,KAAK;AAAA,UAClB,OAAO,KAAK;AAAA,UACZ,OAAO,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA,QAMd,oBAAoB;AA5yB5B;AA6yBI,QAAI,CAAC,YAAK,aAAL,mBAAe,KAAI;AACtB;AAAA;AAGF,UAAM,aAAa,iBAAK,aAAL,mBAAe,SAAf,mBAAqB,MAAM,YAAY;AAC1D,eAAW,YAAY,YAAY;AACjC,iBAAW,QAAQ,SAAS,OAAO;AACjC,YAAI,KAAK,MAAM;AACb,eAAK,WAAW,KAAK;AAAA,YACnB,eAAe,KAAK,WAAW;AAAA,YAC/B,MAAM,KAAK;AAAA,YACX,aAAa,KAAK;AAAA,YAClB,OAAO,KAAK;AAAA,YACZ,OAAO,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOhB,mBAAmB;AAj0B3B;AAk0BI,QAAI,CAAC,YAAK,YAAL,mBAAc;AAAI;AACvB,UAAM,aAAa,cAAc,KAAK,SAAS,CAAC,MAAM,EAAE,KAAK;AAC7D,eAAW,YAAY,YAAY;AACjC,iBAAW,QAAQ,SAAS,gBAAgB;AAC1C,YAAI,KAAK,MAAM;AACb,eAAK,WAAW,KAAK;AAAA,YACnB,eAAe,KAAK,WAAW;AAAA,YAC/B,MAAM,KAAK;AAAA,YACX,aAAa,KAAK;AAAA,YAClB,OAAO,KAAK,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOtB,cAAc;AAl1BtB;AAm1BI,QAAI,OAAiB;AAAA,MACnB,GAAG,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,QAAQ;AAAA,MACpD,GAAG,KAAK;AAAA,MACR,GAAG,KAAK,eAAe,WAAK,SAAL,mBAAW;AAAA;AAEpC,QAAI,SAAsB,KAAK,IAAI,CAAC,SAAQ;AAC1C,aAAO;AAAA,QACL,eAAe,KAAK,WAAW;AAAA,QAC/B,OAAO;AAAA,UACL;AAAA;AAAA;AAAA;AAIN,SAAK,IAAI,eAAe,OAAO;AAC/B,UAAM,YAAY;AAClB,UAAM,iBAAkB,MAAM,wBAAwB,KAAK,WAAW,OAAQ;AAC9E,SAAK,WAAW,SAAS,eAAe,IAAI,CAAC,MAAG;AAn2BpD;AAm2BuD,sBAAE,UAAF,oBAAS;AAAA;AAAA;AAAA,EAG9D,eAAe,MAAW;AAt2B5B;AAu2BI,QAAI,CAAC;AAAM,aAAO;AAClB,WAAO,WAAK,6BAA6B,MAAM,cAAxC,mBAAmD,IAAI,CAAC,MAAM,EAAE;AAAA;AAAA,EAGzE,mBAAmB;AACjB,QAAI,OAAiB;AACrB,QAAI,CAAC,KAAK;AAAmB,aAAO;AACpC,UAAM,UAAU,cAAc,KAAK,mBAAmB,CAAC,MAAM,EAAE;AAC/D,QAAI,CAAC;AAAS,aAAO;AACrB,eAAW,UAAU,SAAS;AAC5B,aAAO,CAAC,GAAG,MAAM,GAAG,OAAO;AAAA;AAE7B,WAAO;AAAA;AAAA,EAGT,iBAAgC,MAA0C;AACxE,QAAI,CAAC;AAAM,aAAO;AAClB,WAAO,OAAO,KAAK,MAAM,QAAQ,CAAC,QAAQ,KAAK;AAAA;AAAA,EAGjD,6BAA6B,MAAW,MAA4B;AAClE,QAAI,QAAe;AACnB,QAAI,OAAO;AACX,QAAI;AACJ,QAAI,CAAC,MAAM;AACT,aAAO;AAAA;AAET,WAAO,MAAM;AACX,YAAM,OAAO,OAAO,MAAM;AAC1B,YAAM,aAAa,CAAC,MAAM,KAAK,QAAQ,WAAW;AAClD,YAAM,WAAW,KAAK,CAAC,MAAM,KAAK,eAAe;AACjD,UAAI,KAAK;AACP,gBAAQ,MAAM,OAAO,KAAK;AAAA,aACrB;AAEL,YAAI,OAAO,GAAG;AACZ;AAAA;AAAA;AAGJ;AAAA;AAEF,WAAO;AAAA;AAAA,EAGT,mBAAmB;AAn5BrB;AAo5BI,UAAM,UAAU,cAAc,KAAK,aAAa,CAAC,MAAM,EAAE,SAAS,OAAO,iBAAiB;AAC1F,SAAK,WAAW,iBAAiB;AAAA,MAC/B,MAAO,gBAAQ,KAAK,CAAC,MAAM,EAAE,QAAQ,YAA9B,mBAAuC,WAAU,KAAK;AAAA,MAC7D,SAAU,gBAAQ,KAAK,CAAC,MAAM,EAAE,QAAQ,eAA9B,mBAA0C,WAAU,KAAK;AAAA,MACnE,OAAQ,gBAAQ,KAAK,CAAC,MAAM,EAAE,QAAQ,aAA9B,mBAAwC,WAAU,KAAK;AAAA,MAC/D,UAAW,gBAAQ,KAAK,CAAC,MAAM,EAAE,QAAQ,kBAA9B,mBAA6C,WAAU,KAAK;AAAA;AAAA;AAAA,QAIrE,qBAAqB;AACzB,UAAM,KAAK,KAAK,WAAW;AAC3B,UAAM,SAAS,MAAM,KAAK,QAAQ,MAAM;AAAA;AAAA;AAAA;AAAA,+BAIb;AAAA;AAAA;AAAA;AAI3B,SAAK,WAAW,YAAY,OAAO;AAAA;AAAA,QAG/B,uBAAuB;AAC3B,UAAM,+BAA+B;AAAA;AAAA,QAGjC,qCAAqC;AACzC,UAAM,MAAM,MAAM;AAClB,eAAW,UAAU,KAAK;AACxB,YAAM,KAAK,YAAY,0BAA0B,CAAC,OAAO;AAAA;AAAA;AAAA,QAIvD,uBAAuB,WAAmB;AAC9C,UAAM,uBAAuB;AAAA;AAAA,QAGzB,iBAAiB,YAA8B;AACnD,UAAM,iBAAiB;AAAA;AAAA,QAGnB,kBAAkB;AACtB,UAAM,gBAAgB;AAAA;AAAA,QAGlB,sBAAsB,UAAkB,MAAa;AACzD,UAAM,sBAAsB,UAAU;AAAA;AAAA,QAGlC,kBAAkB;AAr8B1B;AAs8BI,QAAI,QAAQ,IAAI,aAAa,QAAQ;AACnC;AAAA;AAEF,QAAI,CAAC,YAAK,WAAW,oBAAhB,mBAAiC,yBAAwB;AAC5D,YAAM,KAAK,KAAK;AAChB,WAAK,WAAW,kBAAkB,iCAC7B,KAAK,WAAW,kBADa;AAAA,QAEhC,wBAAwB,KAAK;AAAA;AAE/B,UAAI;AACF,cAAM,qCAAiB,KAAK;AAAA,eACrB,KAAP;AACA,gBAAQ,IAAI,yBAAyB,IAAI,SAAS,IAAI;AACtD,gBAAQ,IAAI,kBAAkB,KAAK;AAAA;AAAA;AAAA;AAAA,QAKnC,oBAAoB,IAAY;AACpC,SAAK,gCAAgC;AACrC,UAAM,aAAa,MAAM,6BAA6B;AACtD,QAAI,YAAY;AACd,WAAK,UAAU,8BAAS;AACxB,WAAK,aAAa;AAClB,YAAM,KAAK,KAAK;AAChB,YAAM,qCAAiB,KAAK;AAAA;AAAA;AAAA,SAIjB,eAAe,KAAe;AAC3C,UAAM,IAAI,OAAO,CAAC,OAAO;AACvB,aAAO,MAAM,QAAQ,MAAM;AAAA;AAE7B,QAAI,IAAI,QAAQ;AACd,aAAO,IAAI,OAAO,CAAC,GAAG,MAAO,EAAE,UAAU,EAAE,SAAS,IAAI;AAAA,WACnD;AACL,aAAO;AAAA;AAAA;AAAA,SAII,SAAS,KAAe;AACrC,WAAO,IAAI,IAAI,CAAC,GAAG,MAAM,IAAI,MAAM,IAAI,GAAG,IAAI,CAAC,MAAM,CAAC,GAAG,KAAK;AAAA;AAAA,SAGjD,YAAY,GAAW,GAAW;AAC/C,QAAI,EAAE,SAAS,IAAI;AACjB,aAAO;AAAA;AAET,QAAI,EAAE,SAAS,IAAI;AACjB,aAAO;AAAA;AAET,WAAO;AAAA;AAAA,EAGT,eAAe;AACb,UAAM,KAAK,6BAAM;AACf,WAAK;AACL,WAAK;AAAA,OAFI;AAKX,SAAK,4BAA4B,YAAY,IAAI;AAAA;AAAA,EAGnD,UAAU,QAAiB;AACzB,QAAI,8BAAc,GAAG;AACnB;AAAA;AAEF,UAAM,YAAY,KAAK,MAAM,QAAQ,cAAc,WAAW,OAAO;AACrE,UAAM,MAAM,YAAY;AACxB,UAAM,QAAQ;AACd,QAAI,YAAY,SAAS,CAAC,KAAK,wBAAwB;AACrD,yCAAc,mBAAmB,WAAW;AAAA,QAC1C,MAAM;AAAA,UACJ;AAAA,UACA,YAAY,KAAK;AAAA;AAAA;AAGrB,WAAK,yBAAyB;AAAA;AAEhC,aAAS,SAAS,IAAI,YAAY;AAClC,SAAK,IAAI,oBAAoB,WAAW;AAAA;AAAA,EAG1C,cAAc;AACZ,QAAI,CAAC,KAAK,cAAc,CAAC,KAAK,WAAW,QAAQ,CAAC,KAAK,WAAW,MAAM;AACtE,yCAAc,wBAAwB;AAAA,QACpC,MAAM;AAAA,UACJ,eAAe,KAAK;AAAA;AAAA;AAGxB,cAAQ,KAAK;AAAA;AAAA;AAAA;AAj9BZ;AAAA;AAyBE,AAzBF,KAyBE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AAhCF,KAgCE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;A4BhHd,sBAAO;AAEP,sBAAgC;AAChC,qBAAyE;AAGzE,yBAA4B;AAM5B,IAAM,iBAAgB;AAEtB,IAAM,YAAW;AAEjB,OAAO,UAAU,aAAa,SAAU,QAAQ,aAAa;AAC3D,MAAI,SAAS;AACb,SAAO,OAAO,QAAQ,IAAI,OAAO,QAAQ,MAAM;AAAA;AAG1C,qCAA8B,mBAAmB;AAAA,EAAjD,cArBP;AAqBO;AAOL,uBAAmB;AAAA;AAAA,QAab,WAAW,MAAc;AAC7B,QAAI,cAAc;AAClB,WAAO,MAAM;AACX,YAAM,UAAU,MAAM,wCAAoB,WAAU,aAAa;AACjE,UAAI,QAAQ,UAAU,GAAG;AACvB;AAAA;AAEF,iBAAW,UAAU,SAAS;AAC5B,cAAM,KAAK,YAAY,iBAAiB,CAAC;AACzC,sBAAc,OAAO;AAAA;AAAA;AAAA;AAAA,QAKrB,cAAc,YAAwB;AAvD9C;AAwDI,QAAI,CAAC,KAAK;AAAQ,YAAM,KAAK;AAC7B,SAAK,MAAM,WAAW,SAAS,YAAY;AAC3C,SAAK,MAAM,WAAW,SAAS,YAAY;AAC3C,QAAI,CAAC,WAAW,MAAM;AACpB,YAAM,IAAI,MAAM;AAAA;AAElB,SAAK,OAAO,WAAW;AACvB,SAAK,UAAU,kBAAW,YAAX,mBAAoB,MAAM,KAAK,OAAM;AACpD,UAAM,WAAW,IAAI;AACrB,UAAM,UAAU,yCAAY;AAC5B,QAAI,CAAC,WAAW,QAAQ,WAAW,KAAK,OAAO,IAAI;AACjD,YAAM,IAAI,MAAM;AAAA;AAElB,UAAM,SAAQ,WAAW,OAAO,MAAM;AACtC,SAAK,qBAAqB,MAAM,SAAS,YACvC,QACA,WAAW,SAAS,YAAY,IAChC,WAAW,SAAS,YAAY;AAElC,UAAM,KAAK,WAAW;AACtB,UAAM,aAAa;AAAA,MACjB,eAAe,WAAW;AAAA,MAC1B,QAAQ;AAAA,MACR,gBAAgB,KAAK;AAAA,MACrB,UAAU;AAAA,QACR,KAAK,WAAW,SAAS,YAAY;AAAA,QACrC,KAAK,WAAW,SAAS,YAAY;AAAA;AAAA,MAEvC,MAAM,KAAK;AAAA;AAEb,QAAI,QAAQ,IAAI,YAAY,cAAc;AACxC,WAAK,UAAU;AAAA;AAAA;AAAA,QAIb,WAAW,YAAwB;AACvC,SAAK,YAAY,WAAW,KAAK,UAAU,KAAK;AAChD,UAAM,QAAQ;AAAA,MACZ,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA;AAEP,eAAW,QAAQ,OAAO;AACxB,YAAM,KAAK,cAAc,MAAM;AAAA;AAAA;AAAA,QAI7B,cAAc,MAAgB,YAAwB;AA7G9D;AA8GI,YAAQ,IAAI,2BAA2B,KAAK;AAC5C,QAAI;AACF,YAAM,KAAK,KAAK;AAAA,aACT,GAAP;AACA,cAAQ,IAAI,WAAW;AACvB,UAAI,CAAC,SAAE,YAAF,mBAAW,SAAS,0BAAyB;AAChD,6CAAgB,GAAG;AAAA,UACjB,MAAM,EAAE,UAAU,KAAK,MAAM;AAAA,UAC7B,MAAM,EAAE,QAAQ;AAAA,UAChB,QAAQ,KAAK;AAAA;AAAA,aAEV;AACL,YAAI,QAAQ,IAAI,OAAO;AACrB,kBAAQ,IAAI,cAAc,MAAM,KAAK,UAAU,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA,QAMtD,cAAc;AAClB,QAAI,UAAU;AACd,WAAO,UAAU,GAAG;AAClB,YAAM,OACJ,iBACA,gBAAgB,KAAK,OAAO,KAAK,mCACN,KAAK,4BACtB,KAAK,SAAS,KAAK;AAC/B,cAAQ,IAAI,kBAAkB;AAC9B,UAAI;AACF,cAAM,KAAK,UAAU,KAAK,KAAK,MAAK;AAAA,UAClC,SAAS;AAAA,UACT,WAAW;AAAA;AAEb,eAAO;AAAA,eACA,KAAP;AACA,gBAAQ,MAAM,iBAAiB,IAAI;AACnC,cAAM;AAAA;AAAA;AAGV,UAAM,IAAI,MAAM,iDAAiD,KAAK;AAAA;AAAA,SAGjE,mBAAmB,MAAc;AACtC,QAAI,OAAO,+BAAY,QAAQ,MAAM;AAAA,MACnC,wBAAwB;AAAA,MACxB,UAAU,CAAC,OAAO;AAAA,MAClB,eAAe,CAAC;AAAA,OACf;AACH,QAAI,CAAC,MAAM,QAAQ,OAAO;AACxB,cAAQ,KAAK,gBAAgB,MAAM,aAAa;AAChD,aAAO;AAAA;AAET,WAAO,KAAK,IAAI,CAAC,QAAQ;AACvB,YAAM,QAAQ,IAAI,MAAM,MAAM,MAAM;AACpC,aAAO,EAAE,KAAK,IAAI,KAAK;AAAA;AAAA;AAAA,QAIrB,eAAe;AACnB,UAAM,QAAQ,MAAM,KAAK,UAAU,KAAK,SACtC,MAAG;AA1KT;AA2KQ,6BAAS,cAAc,sCAAvB,mBAA0D,aAAa,WACvE,MAAM,KAAK,SAAS,iBAAiB,6BAClC,IAAI,CAAC,MAAM,wBAAG,aAAa,WAAU,IACrC,OAAO,CAAC,MAAM,EAAE,QAAQ,2BAA2B,GAAG;AAAA;AAE7D,UAAM,OAAO,+BAAO,QAAQ,mBAAmB;AAC/C,SAAK,YAAY,aAAa;AAAA;AAAA,QAG1B,cAAc;AAClB,QAAI;AAEF,WAAK,YAAY,WACf,OAAM,KAAK,UAAU,eAAe,8BACpC;AAAA,aACK,KAAP;AACA,UAAI,6BAAc,GAAG;AACnB,gBAAQ,IAAI,yBAAyB,MAAM,KAAK,UAAU,KAAK;AAAA,aAC1D;AACL,gBAAQ,IAAI;AAAA;AAEd,YAAM;AAAA;AAAA;AAAA,QAIJ,YAAY;AAChB,UAAM,QAAQ,MAAM,KAAK,UAAU,KAAK,SACtC;AAEF,QAAI,OAAO,UAAU,UAAU;AAC7B,WAAK,YAAY,SAAS,MAAM,QAAQ,UAAU,IAAI;AAAA;AAAA;AAAA,QAIpD,aAAa;AACjB,SAAK,YAAY,UACf,OAAM,KAAK,UAAU,eAAe,2BACpC;AAAA;AAAA,QAGE,aAAa;AACjB,SAAK,YAAY,UACf,OAAM,KAAK,UAAU,eAAe,mCACpC;AAAA;AAAA,QAGE,aAAa;AACjB,SAAK,YAAY,UACf,OAAM,KAAK,UAAU,eAAe,mCACpC;AAAA;AAAA,QAGE,WAAW;AACf,SAAK,YAAY,YACf,OAAM,KAAK,UAAU,eAAe,wCACpC;AAAA;AAAA,QAGE,WAAW;AACf,UAAM,KAAK,UAAU,KAAK,MAAM;AAChC,UAAM,OAAO,MAAM,KAAK,UAAU,KAAK,SAAS,MAAM;AAEpD,YAAM,QACJ,SAAS,cAAc,iCACvB,SAAS,cAAc,gCACvB,SAAS,cAAc;AACzB,aAAO,+BAAO;AAAA;AAEhB,SAAK,YAAY,QAAQ,iBAAgB,mBAAmB,QAAQ;AAAA;AAAA;AA1NjE;AAAA;AASE,AATF,gBASE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AAhBF,gBAgBE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;ACtCd,sBAAO;AAEP,sBAA8B;AAC9B,qBAA2D;AAC3D,sBAA0B;AAC1B,oBAAuB;AAEvB,eAAyB;AAKzB,IAAM,iBAAgB,QAAQ,IAAI,oBAAoB;AAEtD,IAAM,SAAQ,sBAAW,OAAO;AAAA,EAC9B,SAAS;AAAA,EACT,SAAS;AAAA,IACP,QAAQ;AAAA,MACN,wBAAwB;AAAA,MACxB,cAAc;AAAA;AAAA;AAAA;AAKpB,IAAM,6BAA6B;AAE5B,oCAA8B,0BAAU;AAAA,MAYzC,UAAU;AACZ,WAAO;AAAA;AAAA,QAGH,WAAW,MAAc;AAC7B,QAAI,cAAc;AAClB,WAAO,MAAM;AACX,YAAM,UAAU,MAAM,6BACpB,4BACA,aACA;AAEF,UAAI,QAAQ,UAAU,GAAG;AACvB;AAAA;AAEF,iBAAW,UAAU,SAAS;AAC5B,cAAM,KAAK,YAAY,iBAAiB,CAAC,OAAO;AAChD,sBAAc,OAAO;AAAA;AAAA;AAAA;AAAA,QAKrB,cAAc,IAAY;AAC9B,UAAM,aAAa,MAAM,sCAAkB,EAAE;AAC7C,QAAI,CAAC,YAAY;AACf,YAAM,IAAI,MAAM,iDAAiD;AAAA;AAEnE,QAAI,CAAC,WAAW,aAAa;AAC3B,YAAM,UAAU;AAChB,yCAAc,SAAS;AAAA,QACrB,MAAM,EAAE,eAAe;AAAA;AAEzB,aAAO;AAAA;AAET,QAAI,UAAiB;AACrB,QAAI,OAAO;AACX,QAAI,YAAY;AAChB,WAAO,MAAM;AACX,WAAK,IAAI,iBAAiB,YAAY,WAAW;AACjD,YAAM,OAAO,MAAM,KAAK,gBAAgB,WAAW,aAAa;AAEhE,YAAM,EAAE,MAAM,kBAAkB,KAAK,gBAAgB;AACrD,kBAAY,iBAAiB;AAC7B,UAAI,KAAK,UAAU;AAAG;AACtB,gBAAU,CAAC,GAAG,SAAS,GAAG;AAC1B;AACA,UAAI,QAAQ,IAAI,YAAY,QAAQ;AAClC;AAAA;AAEF,UAAI,CAAC,eAAe;AAClB,aAAK,IAAI;AACT;AAAA;AAAA;AAGJ,UAAM,KAAK,eAAe,YAAY;AACtC,SAAK,IAAI,iCAAiC,WAAW;AACrD,WAAO;AAAA;AAAA,QAOH,gBAAgB,aAAqB,eAAuB;AAChE,UAAM,6BAA6B;AACnC,UAAM,YAAY;AAClB,UAAM,UAAU;AAAA,MACd,gBAAgB;AAAA,MAChB,iBAAiB;AAAA,MACjB,qBAAqB;AAAA,MACrB;AAAA,MACA;AAAA,MACA;AAAA;AAEF,UAAM,OAAO,YAAY,QAAQ,KAAK;AACtC,YAAQ,IAAI,QAAQ;AACpB,UAAM,WAAW,MAAM,OAAM,IAAI;AACjC,QAAI,CAAC,SAAS;AAAM,YAAM,IAAI,MAAM;AACpC,WAAO,SAAS;AAAA;AAAA,EAGlB,gBAAgB,MAAc;AAC5B,UAAM,IAAI,AAAQ,cAAK;AACvB,UAAM,gBAAgB,EAAE,4CAA4C,KAAK;AACzE,UAAM,UAAU,EAAE;AAClB,QAAI,OAAc;AAClB,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,YAAM,OAAO,EAAE,QAAQ,IAAI,KAAK;AAChC,YAAM,OAAO,EAAE,KAAK,IAAI,KAAK,KAAK,KAAK;AACvC,YAAM,UAAU,KAAK,YAAY;AACjC,YAAM,OAAO,EAAE,KAAK,IAAI;AACxB,YAAM,SAAS,EAAE,KAAK;AACtB,YAAM,aAAa,OAAO,KAAK,yBAAyB,KAAK;AAC7D,YAAM,SAAS,KAAK,kBAAkB;AACtC,YAAM,WAAW,OACd,KAAK,cACL,OAAO,CAAC,OAAM,MAAK,GACnB;AACH,UAAI,OAAO,OAAO,KAAK,gBAAgB;AACvC,YAAM,YAAY,OAAO,KAAK,2BAA2B,UAAU;AACnE,aAAO,KAAK,gBAAgB,MAAM;AAClC,YAAM,SAAS,KAAK,YAAY,EAAE,QAAQ,KAAK;AAC/C,WAAK,KAAK;AAAA,QACR;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA;AAAA;AAGJ,WAAO,EAAE,MAAM;AAAA;AAAA,EAGjB,gBAAgB,MAAc,WAAmB;AAC/C,UAAM,QAAQ,KAAK,MAAM;AACzB,UAAM;AACN,WAAO,MAAM,KAAK;AAClB,UAAM,OAAO;AACb,QAAI,KAAK,SAAS,OAAO;AACvB,aAAO,UAAU,WAAW,QAAQ;AAAA;AAEtC,UAAM,gBAAgB;AACtB,QAAI,KAAK,SAAS,gBAAgB;AAChC,aAAO,KAAK,MAAM,0BAA0B;AAC5C,aAAO,KAAK,MAAM,cAAc,GAAG;AAAA;AAErC,WAAO;AAAA;AAAA,EAGT,kBAAkB,OAA2B;AAC3C,QAAI,CAAC;AAAO,aAAO;AACnB,UAAM,QAAQ,MAAM,MAAM;AAC1B,WAAO,MAAM;AAAA;AAAA,EAGf,YAAY,MAA0B;AACpC,QAAI,CAAC;AAAM,aAAO;AAClB,UAAM,QAAQ,KAAK,MAAM;AACzB,WAAO,MAAM;AAAA;AAAA,EAGf,YAAY,QAAa,GAAQ;AAC/B,QAAI,OAAiB;AACrB,UAAM,UAAU,OAAO,KAAK;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,YAAM,QAAQ,EAAE,QAAQ,IAAI,KAAK,OAAO,KAAK;AAC7C,UAAI,CAAC;AAAO;AACZ,YAAM,WAAW,MAAM,MAAM;AAC7B,UAAI,CAAC;AAAU;AACf,YAAM,SAAS,SAAS,GAAG,MAAM;AACjC,UAAI,CAAC;AAAQ;AACb,YAAM,OAAM,OAAO;AACnB,WAAK,KAAK;AAAA;AAEZ,WAAO;AAAA;AAAA,QAGH,eAAe,YAAwB,MAAkB;AAC7D,UAAM,aAAa;AAAA,MACjB,QAAQ;AAAA,MACR,eAAe,WAAW;AAAA,MAC1B,gBAAgB,WAAW,eAAe;AAAA,MAC1C,UAAU;AAAA,QACR,KAAK,WAAW,SAAS,YAAY;AAAA,QACrC,KAAK,WAAW,SAAS,YAAY;AAAA;AAAA,MAEvC,MAAM;AAAA,QACJ,SAAS;AAAA;AAAA;AAAA;AAAA,SAKR,kBAAkB,QAAoB;AAAA;AAAA;AAzLxC;AACE,AADF,gBACE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AARF,gBAQE,aAAyB;AAAA,EAC9B,UAAU;AAAA;;;ACnCd,sBAAO;AAEP,qBAQO;AACP,sBAA0B;AAC1B,oBAAuB;AAgBvB,IAAI,CAAC,QAAQ,IAAI,qBAAqB;AACpC,QAAM,IAAI,MAAM;AAAA;AAGlB,IAAM,SAAQ,sBAAW,OAAO;AAAA,EAC9B,SAAS,QAAQ,IAAI,sBAAsB;AAAA,EAC3C,SAAS;AAAA,IACP,QAAQ;AAAA,MACN,cAAc;AAAA;AAAA;AAAA;AAKb,iCAA2B,0BAAU;AAAA,EAc1C,cAAc;AACZ;AAdF,sBAAa;AAAA;AAAA,MAiBT,UAAU;AACZ,WAAO;AAAA;AAAA,QAGH,OAAO;AACX,UAAM,aAAa;AACnB,QAAI,OAAO;AACX,UAAM,KAAK;AACX,WAAO,MAAM;AACX,WAAK,IAAI;AACT,YAAM,eAAe,MAAM,gDAA4B,YAAY;AACnE,UAAI,aAAa,UAAU;AAAG;AAC9B,iBAAW,QAAQ,cAAc;AAC/B,cAAM,KAAK,YAAY,iBAAiB,CAAC;AAAA;AAE3C,cAAQ;AAAA;AAAA;AAAA,QAIN,6BAA6B;AACjC,UAAM,aAAa,MAAM,sCAAkB,EAAE,IAAI;AACjD,QAAI;AAAY;AAChB,UAAM,qCAAiB;AAAA,MACrB;AAAA,QACE,IAAI;AAAA,QACJ,MAAM;AAAA,QACN,UAAU,EAAE,MAAM,SAAS,aAAa,CAAC,GAAG;AAAA;AAAA;AAAA;AAAA,QAK5C,cAAc,MAAiB;AA1FvC;AA2FI,UAAM,aAAa,YAAK,WAAL,mBAAa,QAAO,MAAM,KAAK;AAClD,UAAM,SAAS,MAAM,KAAK,gBAAgB;AAC1C,UAAM,cAAc,OAAO,IAAI,CAAC,SAAQ;AACtC,aAAO;AAAA,QACL,QAAQ,KAAK;AAAA,QACb,eAAe;AAAA,QACf,OAAO;AAAA,UACL,QAAQ;AAAA;AAAA;AAAA;AAId,UAAM,gBAAgB;AACtB,UAAM,WAAW;AACjB,UAAM,gCAAgC;AACtC,UAAM,cAAc,MAAM,iBAAiB,KAAK;AAChD,UAAM,iBAAiB,YAAY,IAAI,CAAC,MAAM;AAC5C,UAAI,CAAC,EAAE,SAAS,CAAC,EAAE,MAAM;AAAK,cAAM,IAAI,MAAM;AAC9C,aAAO,EAAE,MAAM;AAAA;AAEjB,UAAM,eAAe;AAAA,MACnB,IAAI,KAAK;AAAA,MACT;AAAA,MACA,eAAe,eAAe;AAAA;AAEhC,UAAM,8BAAU;AAAA;AAAA,QAGZ,gBAAgB,MAAc;AAClC,UAAM,OACJ,QACA,mBAAmB,QACnB;AACF,QAAI,SAAmB;AACvB,UAAM,WAAW,MAAM,OAAM,IAAI;AACjC,UAAM,aACJ;AACF,QAAI,QAAQ,IAAI,OAAO;AACvB,eAAW,QAAQ,SAAS,KAAK,MAAM,OAAO;AAC5C,UAAI,KAAK,WAAW,cAAc,KAAK,iBAAiB,OAAO;AAC7D,eAAO,KAAK,KAAK,MAAM,OAAO;AAC9B,YAAI,OAAO,UAAU,KAAK;AAAY;AAAA;AAAA;AAG1C,WAAO;AAAA;AAAA,EAGT,iBAAiB,MAAc;AAC7B,UAAM,UAAU,KAAK,MAAM;AAC3B,QAAI,CAAC;AAAS,aAAO;AACrB,UAAM,QAAQ,SAAS,QAAQ;AAC/B,WAAO,QAAQ;AAAA;AAAA;AApGZ;AAGE,AAHF,aAGE,eAA6B;AAAA,EAClC,SAAS;AAAA,IACP,KAAK;AAAA,IACL,UAAU;AAAA;AAAA;AAIP,AAVF,aAUE,aAAyB;AAAA,EAC9B,UAAU;AAAA;",
  "names": []
}
